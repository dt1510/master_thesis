\BOOKMARK [0][-]{section*.1}{Abstract}{}
\BOOKMARK [0][-]{section*.1}{Acknowledgements}{}
\BOOKMARK [0][-]{section*.1}{Statement of Originality}{}
\BOOKMARK [0][-]{chapter.1}{Introduction}{}
\BOOKMARK [1][-]{section.1.1}{Inductive inference}{chapter.1}
\BOOKMARK [1][-]{section.1.2}{Inductive logic programming}{chapter.1}
\BOOKMARK [1][-]{section.1.3}{Classification of inductive logic programming systems}{chapter.1}
\BOOKMARK [1][-]{section.1.4}{Motivation and Objectives}{chapter.1}
\BOOKMARK [0][-]{chapter.2}{Background Theory}{}
\BOOKMARK [1][-]{section.2.1}{Prerequisites}{chapter.2}
\BOOKMARK [1][-]{section.2.2}{A logic language}{chapter.2}
\BOOKMARK [1][-]{section.2.3}{Model theorymarker2002model}{chapter.2}
\BOOKMARK [1][-]{section.2.4}{Logicssep-logic-nonmonotonic}{chapter.2}
\BOOKMARK [1][-]{section.2.5}{Logic Programming}{chapter.2}
\BOOKMARK [2][-]{subsection.2.5.1}{Basic concepts and notation of Logic Programminglin2009efficient}{section.2.5}
\BOOKMARK [1][-]{section.2.6}{Machine learning}{chapter.2}
\BOOKMARK [2][-]{subsection.2.6.1}{Types of problem}{section.2.6}
\BOOKMARK [1][-]{section.2.7}{Inductive logic programming}{chapter.2}
\BOOKMARK [2][-]{subsection.2.7.1}{Input and output of ILP system}{section.2.7}
\BOOKMARK [2][-]{subsection.2.7.2}{Language bias}{section.2.7}
\BOOKMARK [1][-]{section.2.8}{ILP systems}{chapter.2}
\BOOKMARK [2][-]{subsection.2.8.1}{Progol}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.2}{Alephaleph2007}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.3}{Toplogsantos2008toplogWebsitemuggleton2008toplog}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.4}{Hailray2003hybridray2005phdHybrid}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.5}{Xhailray2009nonmonotonic}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.6}{Imparo}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.7}{Talcorapi2010inductivecorapi2011tal}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.8}{Other systems}{section.2.8}
\BOOKMARK [2][-]{subsection.2.8.9}{Selecting ILP systems for classification}{section.2.8}
\BOOKMARK [1][-]{section.2.9}{Inverse subsumption for complete explanatory inductionyamamoto2012inverse}{chapter.2}
\BOOKMARK [2][-]{subsection.2.9.1}{Preliminaries}{section.2.9}
\BOOKMARK [2][-]{subsection.2.9.2}{Inverse subsumption with minimal complements}{section.2.9}
\BOOKMARK [0][-]{chapter.3}{Issues in ILP}{}
\BOOKMARK [1][-]{section.3.1}{Properties of logical theory}{chapter.3}
\BOOKMARK [2][-]{subsection.3.1.1}{Properties of predicate and function symbol}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.2}{Properties of a logical formula}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.3}{Properties of a logic theory}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.4}{Expressivity}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.5}{Syntactic properties}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.6}{Conceptual properties}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.7}{Information content of a logical theory}{section.3.1}
\BOOKMARK [1][-]{section.3.2}{ILP task definition}{chapter.3}
\BOOKMARK [2][-]{subsection.3.2.1}{Generalization}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.2}{Explanatory inductionyamamoto2012inverse}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.3}{Examples}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.4}{Expressivity}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.5}{Semantics}{section.3.2}
\BOOKMARK [1][-]{section.3.3}{Completeness by problem classes}{chapter.3}
\BOOKMARK [2][-]{subsection.3.3.1}{Learning concepts}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.2}{Complexity of a learning problem}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.3}{Learning syntactic representations}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.4}{Learning up to logical equivalence}{section.3.3}
\BOOKMARK [1][-]{section.3.4}{Hypothesis selection}{chapter.3}
\BOOKMARK [2][-]{subsection.3.4.1}{Hypothesis properties}{section.3.4}
\BOOKMARK [2][-]{subsection.3.4.2}{Inducing preferences over hypotheses space}{section.3.4}
\BOOKMARK [2][-]{subsection.3.4.3}{Hypothesis sufficiency}{section.3.4}
\BOOKMARK [2][-]{subsection.3.4.4}{Hypothesis approximation}{section.3.4}
\BOOKMARK [1][-]{section.3.5}{Hypothesis search}{chapter.3}
\BOOKMARK [2][-]{subsection.3.5.1}{Postulates of inductive inference}{section.3.5}
\BOOKMARK [2][-]{subsection.3.5.2}{Inductive inference rules}{section.3.5}
\BOOKMARK [2][-]{subsection.3.5.3}{Control}{section.3.5}
\BOOKMARK [2][-]{subsection.3.5.4}{Automation}{section.3.5}
\BOOKMARK [0][-]{chapter.4}{Classification of ILP systems}{}
\BOOKMARK [1][-]{section.4.1}{ILP task definition}{chapter.4}
\BOOKMARK [2][-]{subsection.4.1.1}{Importance of complete definitions}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.2}{Buildings blocks of ILP task definition}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.3}{Classification ILP systems by an ILP task definition}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.4}{A unified definition of ILP task}{section.4.1}
\BOOKMARK [1][-]{section.4.2}{Hypothesis selection}{chapter.4}
\BOOKMARK [1][-]{section.4.3}{Hypothesis search}{chapter.4}
\BOOKMARK [2][-]{subsection.4.3.1}{Search direction}{section.4.3}
\BOOKMARK [2][-]{subsection.4.3.2}{Algorithms in ILP systems}{section.4.3}
\BOOKMARK [2][-]{subsection.4.3.3}{Summary}{section.4.3}
\BOOKMARK [1][-]{section.4.4}{Bias}{chapter.4}
\BOOKMARK [2][-]{subsection.4.4.1}{Language bias}{section.4.4}
\BOOKMARK [2][-]{subsection.4.4.2}{Search bias}{section.4.4}
\BOOKMARK [1][-]{section.4.5}{Inverse Subsumption for Complete Explanatory Induction}{chapter.4}
\BOOKMARK [2][-]{subsection.4.5.1}{Imparo is complete in inverse subsumption}{section.4.5}
\BOOKMARK [1][-]{section.4.6}{Completeness by problem classes}{chapter.4}
\BOOKMARK [1][-]{section.4.7}{Summary}{chapter.4}
\BOOKMARK [2][-]{subsection.4.7.1}{Completeness in generalizationyamamoto2012inverse}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.2}{Example learning}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.3}{Hypotheses space}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.4}{Completeness}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.5}{Argument Specialization}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.6}{Non-observational concepts}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.7}{Biases}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.8}{Violations}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.9}{Robustness}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.10}{Completeness of theoretical frameworks}{section.4.7}
\BOOKMARK [2][-]{subsection.4.7.11}{Other}{section.4.7}
\BOOKMARK [0][-]{chapter.5}{Advancing solutions to issues in ILP}{}
\BOOKMARK [1][-]{section.5.1}{Inverse Subsumption for Complete Explanatory Induction}{chapter.5}
\BOOKMARK [2][-]{subsection.5.1.1}{Extension to first-order theories}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.2}{Relaxation of minimal complements to a maximal bridge theory}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.3}{Inverse subsumption with minimal complements and connected theory}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.4}{Negative examples}{section.5.1}
\BOOKMARK [0][-]{chapter.6}{Rationale ILP system}{}
\BOOKMARK [1][-]{section.6.1}{ILP task definition}{chapter.6}
\BOOKMARK [1][-]{section.6.2}{Algorithm}{chapter.6}
\BOOKMARK [2][-]{subsection.6.2.1}{Maximal hypothesis antisubsumer}{section.6.2}
\BOOKMARK [2][-]{subsection.6.2.2}{Computing the antisubsumed hypotheses}{section.6.2}
\BOOKMARK [2][-]{subsection.6.2.3}{Pruning hypotheses by negative examples}{section.6.2}
\BOOKMARK [1][-]{section.6.3}{Bias}{chapter.6}
\BOOKMARK [1][-]{section.6.4}{Completeness}{chapter.6}
\BOOKMARK [1][-]{section.6.5}{Other considerations}{chapter.6}
\BOOKMARK [2][-]{subsection.6.5.1}{Hypothesis selection}{section.6.5}
\BOOKMARK [2][-]{subsection.6.5.2}{Hypothesis search}{section.6.5}
\BOOKMARK [2][-]{subsection.6.5.3}{Implementation details}{section.6.5}
\BOOKMARK [1][-]{section.6.6}{Comparison of Rationale with other ILP systems}{chapter.6}
\BOOKMARK [0][-]{chapter.7}{Evaluation}{}
\BOOKMARK [1][-]{section.7.1}{Self-critique}{chapter.7}
\BOOKMARK [1][-]{section.7.2}{Measuring the success}{chapter.7}
\BOOKMARK [2][-]{subsection.7.2.1}{Work nature}{section.7.2}
\BOOKMARK [2][-]{subsection.7.2.2}{Work relevance}{section.7.2}
\BOOKMARK [2][-]{subsection.7.2.3}{Size of contribution}{section.7.2}
\BOOKMARK [2][-]{subsection.7.2.4}{Work impact}{section.7.2}
\BOOKMARK [0][-]{chapter.8}{Conclusion}{}
\BOOKMARK [1][-]{section.8.1}{Summary of Thesis Achievements}{chapter.8}
\BOOKMARK [1][-]{section.8.2}{Applications}{chapter.8}
\BOOKMARK [1][-]{section.8.3}{Future Work}{chapter.8}
\BOOKMARK [0][-]{chapter.1}{Appendix - evaluation of Progol on examples}{}
\BOOKMARK [1][-]{section.1.1}{Progol's capabilities}{chapter.1}
\BOOKMARK [2][-]{subsection.1.1.1}{Specialization in arguments}{section.1.1}
\BOOKMARK [2][-]{subsection.1.1.2}{Multi-clausal learning}{section.1.1}
\BOOKMARK [2][-]{subsection.1.1.3}{Term structure learnability}{section.1.1}
\BOOKMARK [2][-]{subsection.1.1.4}{Learnability of multi-clausal concepts}{section.1.1}
\BOOKMARK [2][-]{subsection.1.1.5}{Clausal examples}{section.1.1}
\BOOKMARK [2][-]{subsection.1.1.6}{Other capabilities}{section.1.1}
\BOOKMARK [1][-]{section.1.2}{Progol's assumed limitations}{chapter.1}
\BOOKMARK [2][-]{subsection.1.2.1}{Other limitations}{section.1.2}
\BOOKMARK [1][-]{section.1.3}{Progol's violations and biases}{chapter.1}
\BOOKMARK [2][-]{subsection.1.3.1}{No generalization downwards}{section.1.3}
\BOOKMARK [2][-]{subsection.1.3.2}{Unlearnability of regular languages}{section.1.3}
\BOOKMARK [2][-]{subsection.1.3.3}{Preference over earlier mode declarations}{section.1.3}
\BOOKMARK [2][-]{subsection.1.3.4}{Background knowledge hypotheses}{section.1.3}
\BOOKMARK [2][-]{subsection.1.3.5}{Other violations and biases}{section.1.3}
\BOOKMARK [0][-]{chapter.2}{Appendix - evaluation of Aleph on examples}{}
\BOOKMARK [1][-]{section.2.1}{Aleph's capabilities}{chapter.2}
\BOOKMARK [2][-]{subsection.2.1.1}{Multi-clausal learning}{section.2.1}
\BOOKMARK [2][-]{subsection.2.1.2}{Learnability of predicates of greater arity}{section.2.1}
\BOOKMARK [2][-]{subsection.2.1.3}{Term structure learnability}{section.2.1}
\BOOKMARK [2][-]{subsection.2.1.4}{Generalization downwards}{section.2.1}
\BOOKMARK [1][-]{section.2.2}{Aleph's assumed limitations}{chapter.2}
\BOOKMARK [2][-]{subsection.2.2.1}{Unlearnability of negative examples}{section.2.2}
\BOOKMARK [2][-]{subsection.2.2.2}{Determination declaration requirement}{section.2.2}
\BOOKMARK [2][-]{subsection.2.2.3}{Assumption of consistency}{section.2.2}
\BOOKMARK [2][-]{subsection.2.2.4}{Unlearnability of regular languages}{section.2.2}
\BOOKMARK [2][-]{subsection.2.2.5}{Unlearnability of multi-clausal concepts}{section.2.2}
\BOOKMARK [2][-]{subsection.2.2.6}{Other assumed limitations}{section.2.2}
\BOOKMARK [1][-]{section.2.3}{Aleph's violations and biases}{chapter.2}
\BOOKMARK [2][-]{subsection.2.3.1}{Default Example Bias}{section.2.3}
\BOOKMARK [2][-]{subsection.2.3.2}{Weak head mode declaration}{section.2.3}
\BOOKMARK [2][-]{subsection.2.3.3}{Literal observation bias}{section.2.3}
\BOOKMARK [2][-]{subsection.2.3.4}{Preference over earlier determinations}{section.2.3}
\BOOKMARK [0][-]{chapter.3}{Appendix - evaluation of Toplog on examples}{}
\BOOKMARK [1][-]{section.3.1}{Toplog's capabilities}{chapter.3}
\BOOKMARK [1][-]{section.3.2}{Toplog's assumed limitations}{chapter.3}
\BOOKMARK [2][-]{subsection.3.2.1}{Inability to make deductions from observations}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.2}{Predicate generalization impossible}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.3}{Ground atom example}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.4}{Unlearnability of the term structure}{section.3.2}
\BOOKMARK [1][-]{section.3.3}{Toplog's violations and biases}{chapter.3}
\BOOKMARK [2][-]{subsection.3.3.1}{Mode declarations order bias}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.2}{Learning inconsistent hypothesis}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.3}{One head predicate bias}{section.3.3}
\BOOKMARK [2][-]{subsection.3.3.4}{Clausal bias}{section.3.3}
\BOOKMARK [0][-]{chapter.4}{Appendix - evaluation of Xhail on examples}{}
\BOOKMARK [1][-]{section.4.1}{Xhail's capabilities}{chapter.4}
\BOOKMARK [2][-]{subsection.4.1.1}{Background knowledge generalization}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.2}{Multiple hypotheses}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.3}{Multi-clausal hypotheses}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.4}{Fine search space control}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.5}{Learning by integrity constrains}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.6}{Term structure learnability}{section.4.1}
\BOOKMARK [2][-]{subsection.4.1.7}{Other capabilities}{section.4.1}
\BOOKMARK [1][-]{section.4.2}{Xhail's assumed limitations}{chapter.4}
\BOOKMARK [2][-]{subsection.4.2.1}{Partial explanations impossible}{section.4.2}
\BOOKMARK [2][-]{subsection.4.2.2}{Learning from clausal examples}{section.4.2}
\BOOKMARK [2][-]{subsection.4.2.3}{Inability to learn from unrestricted clauses}{section.4.2}
\BOOKMARK [1][-]{section.4.3}{Xhail's violations and biases}{chapter.4}
\BOOKMARK [2][-]{subsection.4.3.1}{Implicit consistency check}{section.4.3}
\BOOKMARK [2][-]{subsection.4.3.2}{Redundant hypotheses}{section.4.3}
\BOOKMARK [2][-]{subsection.4.3.3}{Other violations and biases}{section.4.3}
\BOOKMARK [0][-]{chapter.5}{Appendix - evaluation of Imparo on examples}{}
\BOOKMARK [1][-]{section.5.1}{Imparo's capabilities}{chapter.5}
\BOOKMARK [2][-]{subsection.5.1.1}{A multiclausal learning}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.2}{Learnability of a nested term structure}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.3}{Learnability of multi-clausal concepts}{section.5.1}
\BOOKMARK [1][-]{section.5.2}{Imparo's assumed limitations}{chapter.5}
\BOOKMARK [2][-]{subsection.5.2.1}{Unlearnability of negative examples}{section.5.2}
\BOOKMARK [2][-]{subsection.5.2.2}{Assumption of consistency}{section.5.2}
\BOOKMARK [1][-]{section.5.3}{Imparo's violations and biases}{chapter.5}
\BOOKMARK [2][-]{subsection.5.3.1}{Default examples bias}{section.5.3}
\BOOKMARK [2][-]{subsection.5.3.2}{Weak head mode declaration}{section.5.3}
\BOOKMARK [2][-]{subsection.5.3.3}{No generalization downwards}{section.5.3}
\BOOKMARK [2][-]{subsection.5.3.4}{Literal observational bias}{section.5.3}
\BOOKMARK [2][-]{subsection.5.3.5}{Preference over the later mode declarations}{section.5.3}
\BOOKMARK [2][-]{subsection.5.3.6}{Other biases}{section.5.3}
\BOOKMARK [0][-]{chapter.6}{Appendix - evaluation of Tal on examples}{}
\BOOKMARK [1][-]{section.6.1}{Tal's capabilities}{chapter.6}
\BOOKMARK [2][-]{subsection.6.1.1}{Multiple solutions}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.2}{Multi-clausal hypothesis}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.3}{Term structure learnability}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.4}{Multi-clausal concepts}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.5}{Specialization in arguments}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.6}{Other capabilities}{section.6.1}
\BOOKMARK [1][-]{section.6.2}{Tal's assumed limitations}{chapter.6}
\BOOKMARK [2][-]{subsection.6.2.1}{Correct example bias}{section.6.2}
\BOOKMARK [2][-]{subsection.6.2.2}{Other assumed limitations}{section.6.2}
\BOOKMARK [1][-]{section.6.3}{Tal's violations and biases}{chapter.6}
\BOOKMARK [2][-]{subsection.6.3.1}{Solution redundancy}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.2}{No generalization downwards}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.3}{Loop on learning regular languages}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.4}{Weak head mode declaration}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.5}{Alphabetical term bias}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.6}{Other violations and biases}{section.6.3}
\BOOKMARK [0][-]{subsection.6.3.6}{Bibliography}{}
