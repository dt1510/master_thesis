
\chapter{Background Theory}

%\label{•}el{ch:background}

\section{Introduction}
Inductive Logic Programming (ILP) systems consist of software and algorithms that take a set of positive and negative examples represented as sentences in a logic programming language, then they output a set of sentences called a theory which is a finite axiomatization of the theory of the model of the environment that produced the examples. In recent years there has been an expansion in ILP field, researchers have need to compare these systems based on certain criteria, however only a limited formalism has been developed providing the basis of comparison.
We start with the definitions formalizing the problem of Inductive Logic Programming and defining an ILP system keeping in the definition the properties on which the comparison could be based.

\section{Prerequisities}
We assume the reader is familiar with basic concepts in several areas and consider the following references to be potentially useful:
\begin{enumerate}
\item Foundations of Inductive Logic Programming by Cheng and Wolf \cite{cheng1997}
\item Model theory: An introduction by David Marker \cite{marker2002}
\item An introduction to Kolmogorov complexity and its applications by Li and Vitanyi \cite{li1997}
\end{enumerate}
However, the usage of the concepts does not exceed its rudimentary application and the reader is encouraged to proceed further even if one may not be familiar with all the areas outlined, we suggest to use the literature when the need arises.
\section{Definitions}

\subsection{A logic language}
\begin{defn}
An \emph{alphabet} is a set $\mathcal{A}$ of elements called \emph{letters} of an alphabet.
\end{defn}

\begin{defn}
A word over an alphabet $\mathcal{A}$ is a finite sequence (a string) of letters of the alphabet $\mathcal{A}$.
\end{defn}

\begin{defn}
A formal language $L$ is a set of words over the specified alphabet $\mathcal{A}$, i.e. $L \subseteq 2^\mathcal{A}$.
\end{defn}

\begin{exmp}
Let $R$ be a regular expression $0001*$.
\begin{itemize}
\item The alphabet is the set $\mathcal{A}={\epsilon, 0,1,*}$. $0$, $1$, $*$ are called letters of $\mathcal{A}$.
\item The words over $A$ are $000$.
\end{itemize}
\end{exmp}

Formal languages we are going to use are first-order languages:
\begin{defn}
A \emph{language} $L$ is a formal language given by the grammar of the first-order logic and the additional data $\mathcal{L}$ called the signature of $L$:
\begin{enumerate}
\item a set $\mathcal{C}$ of letters called constant symbols,
\item a set $\mathcal{R}$ of letters called relation symbols and a positive integer (an arity) $n_R$ for each $R \in \mathcal{R}$,
\item a set $\mathcal{F}$ of letters called function symbols and a positive integer (an arity) $n_f$ for each $f \in \mathcal{F}$.
\end{enumerate}
\end{defn}

\begin{remark}
We will often talk about the language $L$ by referring to its signature $\mathcal{L}$. This should not cause a confusion as the signature $\mathcal{L}$ and the grammar of the first order logic uniquelly determine the language $L$.
\end{remark}

\begin{exmp}
The language $\mathcal{L}_{EST}$ of elementary set theory is given by one constant symbol called an empty set, $\mathcal{C}=\{\emptyset\}$, one relation symbol called a set membership $\mathcal{R}=\{\in\}$ with a positive integer (arity) $n_{\in}=2$. The set of function symbols $\mathcal{F}$ are the set operations of a union, an intersection, each with an arity $2$.
\end{exmp}

\begin{defn}
Given a language $L$, $\phi$ is an $L$-formula iff $\phi \in L$.
\end{defn}

\subsection{Languages in the theory of inductive inference}
\begin{defn}
Fix languages $L$, $L'$ such that $L \subseteq L'$. We say that $L$ is \emph{a sublanguage} of $L'$, $L'$ is \emph{a superlanguage} of $L$.
\end{defn}

\begin{exmp}
Let a language $L$ be given by its signature $\mathcal{L}$=$\mathcal{C} \union \mathcal{R} \union \mathcal{F}$ and a language $L'$ by its signature $\mathcal{L}'=\mathcal{C}' \union \mathcal{R}' \union \mathcal{F}'$.
If $\mathcal{C} \subseteq \mathcal{C}'$, $\mathcal{R} \subseteq \mathcal{R}'$, $\mathcal{F} \subseteq \mathcal{F}'$, then $L \subseteq L'$. $L$ is a sublanguage of $L'$, $L'$ is a superlanguage of $L$.
\end{exmp}

\begin{defn}
Given two languages $L_o$ called \emph{an observational language}, $L_h$ called a \emph{hypothesis language}, \emph{a language of enquiry} $L$ is a language that is a superlanguage of a hypothesis language and a superlanguage of an observational language, i.e. $L_h \union L_o \subseteq L$.
\end{defn}

\begin{remark}
The language of enquiry is a model-theoretic language by our definition. We will apply model theory with the first-order logic since many ILP systems are based on Prolog - the logic programming language with its roots in first-order logic. Therefore the boolean connectives $\neg$, $\land$, $\lor$, $\implies$ are implicitly added to the language of enquiry $L$ and the formation rules of first-order logic are assumed. In generality one could devise a theory working in any formal language.
\end{remark}

\begin{exmp}
\begin{itemize}
\item The language of enquiry $L$ is given by $\mathcal{C}_o=\{milk, curry, rice\}$,$\mathcal{R}_o=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$, $\mathcal{F}_o=\{\}$.
\item Let the observational language $L_o$ be $\mathcal{C}_o=\{milk, curry, rice\}$,\\ $\mathcal{R}_o=\{TastesHot, IsWhite\}$, $\mathcal{F}_o=\{\}$
\item Let the hypothesis language $L_h$ be $\mathcal{C}_h=\{milk, curry, rice\}$,\\ $\mathcal{R}_h=\{TastesHot, IsWhite, ContainsSpice\}$, $\mathcal{F}_h=\{\}$.
\item $L_h$-sentences are $\forall x. TastesHot(x) \implies ContainsSpice(x)$,\\ $\forall x. IsWhite(x) \lor TastesHot(x)$.
\end{itemize}
\end{exmp}

\subsection{Model theory\cite{marker2002}}
\begin{defn}
A theory $T$ is a conjunction of logical sentences of a set $T$ (an abuse of notation).
\end{defn}

\begin{exmp}
$T=\{\forall x. Q(x)\}$ is a theory.
\end{exmp}

\begin{remark}
We will reason about the first-order predicate logic theories. This is different from the theories in non-monotonic logics with a negation on failure where $\phi \not\in T \wedge T \not\models \phi \implies T \models \neg\phi$.
In a first-order predicate logic theory, it is possible to have $\phi$ such that $T \not\models \phi$ and $T \not\models \neg\phi$.
\end{remark}

\begin{defn}
An \emph{$\mathcal{L}$-structure} (\emph{a model}) $\mathcal{M}$ is given by the following data:
\begin{enumerate}
\item a nonempty set $M$ called the universe, domain, or underlying set of $\mathcal{M}$;
\item a function $f^{\mathcal{M}} : M^{n_f} \to M$ for each $f \in F$;
\item a set $\mathcal{R}^{\mathcal{M}} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$;
\item an element $c^\mathcal{M} \in M$ for each $c \in C$.
\end{enumerate}
We refer to $f^\mathcal{M}, R^\mathcal{M}, c^\mathcal{M}$ as the interpretations of the symbols $f ,R, c$.
\end{defn}

\begin{remark}
An $L$-structure is an $\mathcal{L}$-structure iff $\mathcal{L}$ is a signature of a language $L$.
\end{remark}

\begin{defn}
Given a set $T$ of logic sentences and a model $\mathcal{M}$. If $\forall \phi \in T. \mathcal{M} \models \phi$, then $\mathcal{M}$ is \emph{a model of $T$} and $T$ is \emph{a theory of $\mathcal{M}$}.
\end{defn}

\begin{defn}
$A$ is an axiomatization of the theory $T$ iff $M(A)=M(T)$.
\end{defn}

\begin{remark}
Typically we put further restrictions on the properties of the axiomatization $A$ that do not hold for $T$. E.g. $A$ must have finitely many axioms for $T$ with infinitely many axioms.
\end{remark}

\subsubsection{Logics\cite{stanford2010}}

We will reason about the models in the first-order logic since this is the language of the model theory. However, there are other logics, notably non-monotonic logics that are used in ILP. The statements about the ILP systems using a non-monotonic logics will have to be translated to a model theoretic language with a care.

\begin{defn}
A logic satisfies a \emph{monotony} property iff
if $\Gamma \models \phi$ and $\Gamma \subseteq \Delta$ then $\Delta \models \phi$. A logic that satisfies a monotony property is called monotonic, otherwise non-monotonic.
\end{defn}

\begin{exmp}
A first-order logic is monotonic.
\end{exmp}

\subsection{Inductive inference}
\begin{defn}
\emph{An environment} $\mathcal{E}$ is a quadruple $\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ where $L$ is a language of enquiry, $L_o$ its observational language, $\mathtt{O}:L_o \to \{true, false\}$ \emph{an environment oracle}, $\mathcal{M}$ an $\mathcal{L}$-structure called \emph{the reality of $L$} satisfying:
$\forall \phi \in L_o. \mathcal{M} \models \phi \iff \mathtt{O}(\phi)=true$.
\end{defn}

\begin{exmp}
\begin{itemize}
\item In an environment England, the reality $\mathcal{M}_E$ is a model of the sentences\\ $\Sigma_E=\{TastesHot(curry), \neg TastesHot(milk)\}$.
\item In India, the reality $\mathcal{M}_I$ is a model of the sentences\\ $\Sigma_I=\{TastesHot(curry), TastesHot(milk)\}$.
\item Both $\mathcal{M}_E$, $\mathcal{•}l{M}_I$ are models of $L$.
\item $\mathcal{E}_E=\langle L, L_o, \mathtt{O}_E, \mathcal{M}_E \rangle$ and
$\mathcal{E}_I=\langle L_, L_o, \mathtt{O}_I, \mathcal{E}_I \rangle$ are two environments distinguished by their reality, consequently by their environment oracle function as well.
\end{itemize}
\end{exmp}

\begin{remark}
In generality one may develop a theory in which an environment may have multiple or none realities and an environment oracle returns a probability of $\phi$ being true in a possible reality or randomly chooses a reality $\mathcal{M}$ between the realities, then acts as an environment oracle with a single reality $\mathcal{M}$. This may be useful when the language of enquiry has a limited expressivity as demonstrated later.
\end{remark}

\begin{defn}
The set of \emph{observations} $O$ is any set of $L_o$-formulas.
\end{defn}

\begin{exmp}
\begin{itemize}
\item The set $O_E=\{TastesHot(curry), \neg TastesHot(milk), IsWhite(milk)\}$ is the set of observations.
\item The set $O_I=\{TastesHot(milk)\}$ is the set of observations.
\item The set $O_{world}=\{TastesHot(curry), \neg TastesHot(milk), TastesHot(milk), \\
IsWhite(milk)\}$ is the set of observations.
\end{itemize}
\end{exmp}

\begin{remark}
\begin{itemize}
\item The language of enquiry $L$ is not powerful enough to express $O_{world}=\{\neg TastesHot(milk) \land InEngland(milk), TastesHot(milk) \land InIndia(milk)\}$
 as it does not have predicate symbols $InEngland$ and $InIndia$ in its signature $\mathcal{L}$.
\item The inconsistency in the observations implies that there is no $\mathcal{L}$-structure $\mathcal{M}$ of $O_{world}$.
\item One of the central problems in ILP is the predicate invention - adding symbols $InEngland$ and $InIndia$ to the signature $\mathcal{L}$ of the language of enquiry.
\end{itemize}
\end{remark}

\begin{defn}
The \emph{background knowledge} or a current induced theory is a set $B$ of formulas in the language of enquiry $L$.
\end{defn}

\begin{remark}
In the definition \ref{scientific_method} of a scientific method, a special case of the background knowledge is considered where $B$ can consist only the previously made hypotheses, thus $B \subseteq L_h$.
\end{remark}

\begin{note}
Given a set of observations $O$, an $L$-formula $Q$ \emph{divides} the models of $O$ into models of $O \wedge \{Q\}$ denoted $M(O \union \{Q\})$ and the models of $\{\neg Q\} \wedge O$ denoted $M(O \union \{Q\})$. That is $\forall \mathcal{M} \in M(O \union \{Q\}). \mathcal{M} \models O \union \{Q\}$,
$\forall \mathcal{M} \in M(O \union \{\neg Q\}). \mathcal{M} \models O \union \{\neg Q\}$.
\end{note}

\begin{defn}
\emph{A hypotheses space} or a search space is the set $\mathcal{H}$ of all consistent subsets of a hypothesis language $L_h$. A formula $H \in \mathcal{H}$ is called \emph{a hypothesis}.
\end{defn}

\subsection{Approximation and error}
\begin{defn}
A theory $\Sigma$ \emph{approximates a theory $\Gamma$ by model} within the error measure $\epsilon$ iff $\mu(M(\Sigma) \triangle M(\Gamma)) < \epsilon$ where $\mu:\{\mathcal{M}:\}\to \mathbb{R}$ is a measure over the models.
\end{defn}

\iffalse
%There is a problem with the definition that phi not in the theory then not phi assumed to be in the theory.
\begin{defn}
\emph{An approximation by a theory}.
A theory $\Sigma$ approximates a theory $\Gamma$ with a \emph{recall} $r \defeq \mu(\{\phi \in \Gamma:\phi \in \Sigma\})$,
with a \emph{precision} $p \defeq \mu(\{\phi \in \Sigma:\phi \in \Gamma\})$,
with an accuracy $a \defeq \mu(\Sigma \cap \Gamma)$
where $\mu:\Sigma \union \Gamma \to \mathbb{R}$ is a measure.
\end{defn}

\begin{exmp}
%Let $\Sigma=\{Milk(cup_1), Milk(cup_1)\}$
\end{exmp}
\fi

\subsection{Ultimate problem of scientific discovery}
Statement: Given an environment oracle $\mathtt{O}$ of an environment $\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ find the reality $\mathcal{M}$.

We do not consider the situation in which we may desire to learn approximate models of the reality. In general, depending on an environment, the reality may not exist, however our definition considers only the environments with exactly one reality. Some realities, e.g. (regular expression) are learnable, others may be not. The ultimate problem consists of numerous incremental problems.

\subsection{Incremental problem of scientific discovery}
We would like to find the reality most efficiently, where the efficiency may be measured by some criteria - e.g. time and resources. The following simplified definition does not take into the account that some questions may be found more efficiently than others.

Set a probability measure $\mu:M(\emptyset) \to [0,1] \subset \mathcal{R}$ over models of a language of enquiry $L$. Given a background knowledge $B$, find a question $Q$ that minimizes the following equation: $|M(B \union {Q})-M(B \union {\neg Q})|$, i.e. a question that divides the models of $B$ most evenly.

\subsection{Definition of a problem of an induction}
\subsubsection{A general problem of an induction}
A problem of induction is a functional problem whose input is a pentuple $P=\langle L, L_o, L_h, O, B\rangle$ where $L$ is a language of enquiry with its sublanguages $L_o$, $L_h$, observations $O$ and the background knowledge $B$. A solution to a problem of induction (the output) is a theory $A$ (meeting certain criteria) called \emph{an induced theory} from the background knowledge $B$ and the observations $O$, or an axiomatization of a theory $T=B \union O$.

\subsubsection{Axiomatization by score}
Define an equivalence relation over the hypotheses space $\mathcal{H}$: $\Sigma \sim \Gamma \iff s(\Sigma)=s(\Gamma)$ where $s$ is the \emph{score function} $s:\mathcal{H} \to \mathbb{R}$. Find an axiomatization $A$ of the theory $T$ with the greatest score $s$.

\subsubsection{Approximation by models}
Find a theory $\Sigma$ that approximates a theory $T$ by model within a given error measure $\epsilon$.

\subsubsection{Axiomatization of an approximation by score}
Find a theory $A$ that approximates a theory $T$ by model within a given error measure $\epsilon$ that maximizes the score function $s$.

\begin{note}
A score function is any total function taking into the consideration various criteria, e.g. minimum description length of the theory, finiteness of the theory, computational resources required to compute the theory. What a good score function is will be of our interest later.
\end{note}

\begin{exmp}
A Kolmogorov complexity with respect to the description language $L$ is a score function $K:L \to \mathbb{N}_0 \subseteq \mathbb{R}$.
\end{exmp}

\begin{note}
A Kolmogorov complexity $K$ can be thought of as a minimul description length with respect to the description language.
\end{note}
\begin{exmp}
Fix a description language to be a language of regular expressions. Let $L_1$ be a regular language given by its shortest description $0000000000$, $L_2$ given by its shortest description $10*$. Then $K(L_1)=10<K(L_2)=3$.
\end{exmp}

\subsubsection{Theory generalization}
TODO

\subsection{Definition of a scientific method}
\label{scientific_method}
A scientific method is an algorithm used to solve the ultimate problem of the scientific discovery:

0. Start with the emty theory $B_i=\emptyset$, set $i=0$.

1. If $B_i$ has the only model, then terminate, $B_i$ is a complete axiomatization of the reality of an environment.

2. Solve an incremental problem of scientific discovery by finding a question $Q$ given the current induced theory $B_i$.

3. Make an observation - ask an environment oracle $\mathtt{O}$ a question $Q$.

4. Induce a more precise theory $B_{i+1}:=B \union \{Q\}$ if the oracle says that $Q$ is true, $B_{i+1}:=B \union \{\neg Q\}$ if the oracle says that $\neg Q$ is true.

5. Increment $i$ and start from step 1 again.

\subsection{Definition of an ILP problem}
Inductive logic programming problem is a problem of an induction where the language of enquiry $L$ is the logic programming language (e.g. Prolog). A constructed $L$-formula in Prolog is a definite clause. The background knowledge and induced theory are finite.

In the context of ILP one divides the observations into positive examples $E^+$ where the reality is a model of instances of $E^+$, and negative examples $E^-$ - where the reality is a model of negated instances of $E^-$. The division is conceptually important as the clause that is not provable from the axioms is false as opposed to the monotonic logics whose theories can be incomplete.

\subsection{Definition of an ILP system}
An ILP system is any function $f:\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle \mapsto \Sigma \in \mathcal{H}$ where the language of enquiry $L$ is the logic programming language, $O$ is a set of formulas called observations, the background theory $B$ and induced theories of $H \in \mathcal{H}$ are finite.

\subsection{A correct ILP system}
\begin{defn}
An ILP system is correct if it solves an ILP problem, i.e. its output is a solution to an ILP problem.
\end{defn}

\begin{remark}
Consider an ILP problem with the score function to be a Kolmogorov complexity $K:T\to\mathbb{N}^+$. Since the Kolmogorov complexity is uncomputable, there does not exist a correct ILP system that would solve the ILP problem. Therefore a care should be taken to design an ILP problem with a computable solution (possibly an approximation of an uncomputable one) and possibly other properties.
\end{remark}

\begin{exmp}
$f:\{ \langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle : O \subseteq L_o, B \subseteq L \} \to \mathcal{H}$, $f:\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle \mapsto \emptyset$ is an ILP system, however it is not correct since $M(O \union B) \not= M(\emptyset)$ for all sets of observations and the background knowledge.
\end{exmp}

\section{Language bias}
\begin{defn}
Given a language $L$, the \emph{language bias} is a property (a boolean valued function) $P$ defined on all words of $L$.
\end{defn}

\begin{exmp}
Define a property $P$ by $\forall w \in L. P(w) \iff w \in L_h$. Then $P$ is a language bias of the hypothetical language $L_h$ in its superlanguage of enquiry $L$.
\end{exmp}

\begin{exmp}
The signature of $L$ is
$\mathcal{L}=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$,
the signature of $L_h$ is
$\mathcal{L}_h=\{TastesHot, IsWhite, ContainsSpice\}$.
Let $P(w) \iff w$ does not contain $ContainsSugar$. $P$ is the language bias of $L_h$ in $L$.
\end{exmp}

\begin{remark}
We will often think of a bias on $L$ as a subset $P$ of $L$ rather than a property on $L$ and use the notation interchangeably:
$P=\{w \in L : P(w)\} \subseteq L$.
\end{remark}

\begin{defn}
A bias $P$ of the language $L$ is \emph{sufficiently weak} with respect to the theory $T$ iff there exists an axiomatization $A$ of the theory $T$ such that $A \subseteq P$. If $P$ is not sufficiently weak with respect to the theory $T$ we say that $P$ is \emph{too strong} with respect to the theory $T$.
\end{defn}

\begin{defn}
Let $P_1$, $P_2$ be biases on the language $L$. $P_1$ is \emph{weaker} than $P_2$ and $P_2$ is \emph{stronger} than $P_1$ iff $P_2 \subseteq P_1$.
\end{defn}

\begin{exmp}
Define biases $P_k$ for $k \in \mathbb{Z}_{\ge 0}$ by $P_k(\phi)$ iff $\phi$ consists of at most $k$ distinct characters. Let $T$ be the theory of the elementary class of the partial orders. Let $A=\{\phi_1, \phi_2, \phi_3\}$ where

$\phi_1=\forall a. a \le a$,

$\phi_2=\forall a \forall b. a \le b \wedge b \le a \implies a=b$,

$\phi_3=\forall a \forall b. a \le b \wedge b \le c \implies a \le c$.

$A$ is an axiomatization of the theory $T$. Note $\forall \phi \in A. P_8(\phi)$ as every axiom of $A$ consists of less than $8$ distinct characters. Therefore $P_8$ is a sufficiently weak bias of the language $L$ with respect to the theory $T$. However there does not exist an axiomatization of the theory $T$ where every axiom consists of at most $3$ distinct characters, therefore $P_3$ is a too strong bias with respect to the theory $T$. The set of the biases is ordered by their strength:
$P_0 \subseteq P_1 \subseteq P_2 \subseteq P_3 \subseteq ... \subseteq P_8 \subseteq ...$. Thus $P_3$ is stronger than $P_8$.
\end{exmp}

\begin{remark}
Let $L$ be the language, $\mathcal{P}$ be the set of all the biases on $L$. Then $\mathcal{P}$ is a lattice ordered by the subset inclusion $\subseteq$ with its join operator the set union $\union$ and its meet operator the set intersection $\cap$.
\end{remark}

\subsection{Language bias problems}
\subsubsection{Axiomatization by score}
Consider a hypotheses space $\mathcal{H} \subseteq L$. An ILP problem is to find the axiomatization $A \in \mathcal{H}$ of the maximal score $s$ of the theory of the elementary class of the models $\mathcal{M}$ satisfying $\mathcal{M} \models O \union B$ where $O$ is a set of the observations, $B$ is the background knowledge.
A simple brute force algorithm may go over all $H \in \mathcal{H}$ and check if $H=A$. This poses problems:
1. $\mathcal{H}$ may not be finite,
2. determining if $M(O \union B)=M(A)$ may not be decidable,
3. determining if $H=A$ may not be decidable.

\subsection{}


\subsection{Syntactic biases}
\begin{defn}
A formula $\phi$ is $k$-adic iff its all predicate symbols (including an equals sign) and function symbols translated to predicate symbols are of the arity at most $k$. A formula $\phi$ is monadic iff $\phi$ is $1$-adic. A set or a theory is $k$-adic iff all its formulas are $k$-adic.
\end{defn}

\begin{itemize}
\item Horn theory bias. A theory produced by an ILP system has to consist of Horn clauses.
\item Mode declaration bias. Let $M$ be a set of a mode declarations.\cite{muggleton1995} Restrict the search space to the clauses whose head atom is an atom of modeh declaration in $M$, whose body atoms are the atoms of modeb declarations in $M$.
\item $k$-adic bias. All formulas in the induced theory are $k$-adic.
\end{itemize}

\subsubsection{Semantic biases}
\begin{itemize}
\item Bottom theory bias. An ILP system constructs a most specific hypothesis $\bot$ according to the bias criteria, then every possible hypothesis $H$ must entail $\bot$: $H \models \bot$.
\item Bottom theory subsumption bias. Every hypothesis must subsume the bottom theory.
\item Top theory subsumption bias. Every hypothesis must be subsumed by the top theory.
\item Solo-generalization bias. The hypotheses space $\mathcal{H}$ is restricted to the generalization of a single example. \cite{muggleton2012}
TODO: provide a formula of the restriction.
\item Solo-explanation bias. Every clause $h$ in a hypothesis $H$ has to explain at least \emph{one} example.
$\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$
\item Inverse entailment bias.
$B \union H \models E \iff B \union \neg H \models \neg E$.
\item Negation on failure bias. The lack of an observation $example(x)$
causes an illusion that $\neg example(x)$ is true as $example(x)$ not provable.

\subsubsection{Heuristic biases}
\item Score function bias. Having two correct hypotheses $H_1$, $H_2$ such that $B \union H_1 \models E$ and $B \union H_2 \models E$ choose the hypothesis with the greater score by the function $s:\mathcal{H} \to \mathbb{R}$.
\item Search algorithm bias. A search algorithm uses heauristics to navigate via the search space $\mathcal{H}$ in addition to the score function applied after the algorithmic hypotheses generation.
\end{itemize}

\section{Inductive Logic Programming systems}
We give an overview of ILP systems taking different approaches to an ILP problem. The definition of an ILP system we gave is not sufficient for making meaningful comparisons based on the usefulness of these systems in real applications nor from a theoretic viewpoint. The aim of familiarizing with these systems is to find the intuition on the key properties of ILP systems that should be formalized in order to benefit from the mathematical rigour required for reasoning about ILP systems.

\iffalse
\subsection{Progol}
\begin{itemize}
\item Inverse Entailment,
\item a bias provided by mode declaration,
\end{itemize}
\fi

\subsection{Toplog\cite{muggleton2008}}
\begin{defn}
$B$ a Horn theory, $E$ a Horn clause. The bottom clause of $B$ and $E$ is $\bot(B,E)$=$\vee\{L | L $ a ground literal, $B \union {\neg E} \models \neg L\}$.
\end{defn}
An ILP system implementation Toplog is based on the theoretical framework Top Directed Hypothesis Derivation (TDHD) with the hypothesis space bias called top theory $\top$:
\begin{itemize}
\item Horn theory bias,
\item Bottom theory bias $\bot = \bot(B,E)$,
\item Solo-generalization bias,
\item Score function bias,
\item top theory $\top$ is specified in the input to an ILP system,
\item top theory $\top$ can be constructed from the mode declarations,
\item not every top theory bias can be expressed with the mode declarations,
\item a top theory consists of literals: terminals (in hypothesis language) and non-terminals (not allowed in hypothesis language and background knowledge)
\item a hypothesis clause in a hypothesis space consists of terminals and is derivable from the top theory by SLD-resolution and substitution, $\top \models h$
\item restriction on the predicates in the head/body of a hypothesis clause,
\item every constructed hypothesis must be subsumed by a top theory $\top$. If $H$ is a set of candidate hypotheses, then: $\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$.
\item inverse entailment bias.
\end{itemize}
The algorithm used to construct the final theory uses Mode Directed Inverse Entailment and follows the steps:
\begin{itemize}
\item construct the top theory $\top$,
\item hypothesis derivation: derive refutations of $\neg e$ from $B$ and $\top$, derive a clause $h$ from the refutations, add $h$ to $H$.
\item coverage computation: which examples $E^+$ and $E^-$ are entailed by $h \in H$.
\item final theory construction: select $H' \subseteq H$ maximizing the score function - e.g. compression, coverage, accuracy,
\end{itemize}
Toplog violates the properties in our first definition of an ILP system:
\begin{itemize}
\item a produced theory may not be complete due to too strong default bias:
\begin{itemize}
\item only what is defined by mode declarations can be in theory,
\item theory can contain only one clause,
\item only one head clause definable with mode declarations unlike two clauses
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeh(man(+person)).
\end{lstlisting}

\item restrictions on the top theory related to $NT$ (non-terminals), $B$, $E$; what literals can occur where. Details in TopLog: ILP Using a Logic Program Declarative Bias by Muggleton etal.
\end{itemize}
\item a produced theory need not be consistent with the observations: given observations $human(susan)$ and $human(jack)$ a final theory can contain the hypothesis $woman(X) :- human(X)$. The accuracy of a theory is computed, a score function allows a degree of inaccuracy.
\end{itemize}

\subsection{MC-Toplog}
\begin{itemize}
\item Derives hypotheses like Toplog, allows multiple clauses in a hypothesis.
\item Restricting hypotheses space to spaces entailing generalization of multiple examples (co-generalization).
\item Correctness: $\top$DTD algorithm returns all candidates hypotheses $H$ satisfying $B \wedge H \models e$ where $e \in E^+$ and the hypothesis space is restricted by the $\top$.
\end{itemize}

\iffalse
\subsection{ProGolem}
\begin{itemize}
\item Inverse Entailment,
\item co-generalization, 
\end{itemize}
\fi

\subsection{Imparo\cite{kimber2009}}
\begin{defn}
A connected theory $T$ for a ground Horn clause $e$ and a Horn theory $B$ is a set of clauses that can be partitioned into sets $T_1, ..., T_n$ so that
(i) $B \union T_1^+ \models e_{head}$,
(ii) $\forall i \in \{1, ..., n-1\}. B \union e_{body} \union T_{i+1}^+ \models T_i^-$,
(iii) $B \union e_{body} \models T_n^-$,
(iv) $B \union T \not\models \square$.

\end{defn}
Bias:
\begin{itemize}
\item Horn theory bias,
\item Bottom theory bias, $\bot=$ a connected theory for $B$ and $e$,
\item Solo-generalization bias,
\item Score-function bias,
\item Mode declaration bias,
\item a bias specifiable in an input program:
\begin{lstlisting}
%a restriction on the length of a clause in a theory
:-set_max_clause_length(N1).
%a restriction on the number of clauses in a theory
:-set_max_clauses(N2).
%TODO - explain further two
:-set_connected(N3).
:-set_max_var_depth(N41).
\end{lstlisting}
\end{itemize}
Algorithm:
\begin{itemize}
\item 1: select an example $E$ from the set of positive examples $E_{pos}$,
\item compute the most specific connected theory for an example $E$ and the background knowledge $B$,
\item search the lattice of sets of clauses subsuming the connected theory and choose the hypothesis $H$ with the highest score according to the score function such that $H \models E$,
\item add $H$ to $B$,
\item remove all $E' \in E_{pos}$ implied by new $B$, $B \models E'$.
\item if $E_{pos} = \emptyset$ finish, otherwise go to 1.
\end{itemize}
TODO: an algorithm for a connected theory generation.

\subsection{Metagol}
TODO

%Bias:
%Algorithm:
%Violations:

\subsection{Comparison of biases in ILP systems}
$\mathcal{H}_{Toplog} \subseteq \mathcal{H}_{Imparo}$

$\mathcal{H}_{bottom\_clause} \subseteq \mathcal{H}_{kernel_set} \subseteq \mathcal{H}_{connected_theory}$

\chapter{Problems in ILP}

\iffalse
\chapter{Learning the reality}
It is important to understand how powerful our ILP systems are - what models they are capable of learning and what models they are never going to learn from the given data.
\section{Philosophical discussion}
In order to learn the reality, do we want to induce questions or theories of the models of the observations and the background knowledge? We could use all the observations to reason about the world, but the observations may be too numerous, hence a more compact theory axiomatization would be useful.
Why do we ask a question $Q$? That is so that we would find out what observation we should make. It is in the case that an environment oracle is available.
\fi
\section{Problems of research in ILP}
1. No clear objective of research. The results in the ILP field research consist of new ILP system frameworks, their implementation and philosophical argumentation of their contribution.

2. Philosophical foundations on the induction are not complete. Stove \cite{stove1986} resolves some questions on the problem of induction, however the solution is not universaly accepted.

3. No mathematical foundations, no axioms for the theory of inductive logic programming. No model of an ILP system to reason about.

4. No means of mutual comparison of ILP systems.
\iffalse
\section{Mathematical Foundations of ILP}
We would like to describe an ILP system with the axioms in order to study ILP systems with the mathematical rigour, to make logic statements about such systems.
I would like to have mappings (e.g. homomorphisms) between these ILP systems so that I may reason about the sub-ILP-systems. It seems Category theory to help me with the foundations. The class of the ILP systems is a category.
\subsection{An ILP system is a category}
What are objects and arrows?
\subsection{Category of ILP systems}

\subsection{Properties of ILP systems}

\subsection{}
\subsection{}
\section{Completeness of ILP systems}
Often ILP systems are complete as a result of using a strong bias rather than a sophisticated induction system.
\fi
\section{Generalization}
\subsection{Incoherence of the generalization - Sawin-Demski paradox}
Consider the observations $P(0), \neg P(1), P(2)$ which are generalized by the rule $R1=\forall x. P(x)$ iff $x$ is even.
By inducing the $\Pi_1$ statement into the theory, it may be impossible for some true $\Pi_2$ statements to be part of the theory\cite{sawin2013}.
Therefore we limit ourselves to studying only the models where $\Pi_1$ statement true, $\Pi_2$ statement false.
\iffalse
\subsection{Consequences of the generalization}
1. A theory $T_g$ with a general statement $\forall x.P(x)$ entails more statements $P(a_i)$ then a theory $T$ with $\Pi_0$ statements $P(a_1), ..., P(a_n)$. Therefore $\#M(T_g) \leq \#M(T)$.
2. 
\fi
\subsection{The reasons to generalize}
1. A general statement may be a more compact representation than specific multiple statements.
2. A general theory $T_g$ entailing some of the statements in a theory $T$ and contradicting other statements in a theory $T$ (usually fewer) is an approximation of a theory $T$. A precision is the percentage of the models of $T_g$ that are models of $T$. A recall is the percentage of the models of $T$ that are models of $T_g$. An approximated theory may be simpler to reason about and to represent.
\iffalse
\subsection{How do the models of a theory and their number change during generalization and specialization?}
\fi
\section{The role of a language in learning the models}
Consider an empty language. It has one possible interpretation and one model up to an isomorphism.
By extending the language we can distinguish the models further. The problem of the predicate invention is to invent a predicate so that the right distinction between the models is made based on the language.
Questions:
1. How can we measure an expessivity and a complexity of a language?
2. How much information can be captured by a $\mathcal{L}$-theory given a language $\mathcal{L}$?
3. What is the maximal complexity of the language $\mathcal{L}$ for which the $\mathcal{L}$-theory is decidable?
4. Complexity of learning the equivalence class of the reality given a language.
5. Is there a language for which the task of learning the equivalence class of the reality is undecidable?
6. What percentage of the reality can we recover from observing and reasoning only with the statements in the restricted language?
7. Can a language be partitioned (or expressed as posets of sublanguages) into sublanguages and the theories of the sublanguages be learnt, then joint into a theory of the original language?
\iffalse
\section{Models with an empty language}
\fi

\iffalse
\section{Counting the number of the models of monadic theories}
Define a probability measure of the models $\mu:M(\emptyset) \to [0,1] \subset \mathcal{R}$. Let $M_0$ be the set of all models, $\mu(M_0)=0$. Let $\mathcal{•}l{L}=\{c_1, ..., c_n, P\}$ be the language with the $n$ constant symbols $c_i$ and with a unary predicate symbol $P(.)$. If $T=\{P(c_1\}$, then what is greater $\mu(M(T))$ or $\mu(M(\{\neg P(c_1)\}))$? We can define the default probability for the first atomic statement: $p(\mathcal{M} \models P(c_1))=1/2$, consequently $\mu(M(T))=1/2=\mu(M(\{\neg P(c_1)\}))$. The next statement $P(c_i)$ is independent of the first, so define the probability $P(c_i)=1/2$ for $i \in \{1, ..., n\}$.
\begin{defn}
A theory (or a set) $T$ is maximally $k$-adically consistent iff $T$ is consistent and for every formula $\phi$ if $\phi$ is $k$-adic, then $\phi \in T$ or $\neg \phi \in T$.
\end{defn}
\begin{remark}
Let $\mathcal{L}$ be the language with $n$ constant symbols and $m$ unary predicate symbols. Then there are exactly $2^{mn}$ maximally monadically consistent monadic theories $T$ (equivalence classes of models of $T$).
\end{remark}
\begin{remark}
Let $\mathcal{L}$ be the language with countably many constant symbols and $m$ unary predicate symbols. Then there are uncountably many maximally monadically consistent monadic theories.
\end{remark}
\subsection{Asking an environment oracle a question}
\subsection{}

\section{Learning the theories from the probabilistic oracle}
The correctness of our observations may be distributed over the probability distribution of the environment.
\section{Approximations to learning}
\section{Which models are more probable?}
\section{Predicate Invention}
Consider the language $\mathcal{L}=\{father\}$ with a binary predicate symbol. A predicate invention is a problem of adding to the language a predicate $grandfather$ and an axiom to all the theories: $\forall x. \forall y. \forall z. father(x,y) \wedge father(y,z) \implies grandfather(x,z)$.
TODO: Is that right? In that case $grandfather$ is definable in terms of $father$ and therefore redundant.
\fi

\iffalse
\section{Foundations of inductive reasoning}
Let $A$ be a set of objects on which the observations can be applied, $\mathcal{P}$ be a set of the properties that can be observed on $a \in A$. Then an observation $O$ of an element $a \in A$ is a minimal set of the literals such that
$\forall P \in \mathcal{P}. P(a) \in O \vee \neg P(a) \in O$.
\fi