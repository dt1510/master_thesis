
\chapter{Background Theory}

\section{Prerequisites}
We assume the reader is familiar with basic concepts in several areas and consider the following references to be potentially useful:
\begin{enumerate}
\item Foundations of Inductive Logic Programming by Cheng and Wolf \cite{nienhuys1997foundations}
\item Model theory: An introduction by David Marker \cite{marker2002model}
\item An introduction to Kolmogorov complexity and its applications by Li and Vitanyi \cite{li2009introduction}
\item Real Analysis by H.L.Royden  \cite{royden1988real}, a reference on measure theory
\end{enumerate}
However, the usage of the concepts does not exceed its rudimentary application and the reader is encouraged to proceed further even if one may not be familiar with all the areas outlined, we suggest to use the literature when the need arises.
\section{A logic language}
\begin{defn}
An \emph{alphabet} is a set $\mathcal{A}$ of elements called \emph{letters} of an alphabet.
\end{defn}

\begin{defn}
A word over an alphabet $\mathcal{A}$ is a finite sequence (a string) of letters of the alphabet $\mathcal{A}$.
\end{defn}

\begin{defn}
A formal language $L$ is a set of words over the specified alphabet $\mathcal{A}$, i.e. $L \subseteq \powerset{\mathcal{A}}$.
\end{defn}

\begin{exmp}
Let $R$ be a regular expression $0001*$.
\begin{itemize}
\item The alphabet is the set $\mathcal{A}={\epsilon, 0,1,*}$. $0$, $1$, $*$ are called letters of $\mathcal{A}$.
\item The words over $\mathcal{A}$ are $000$.
\end{itemize}
\end{exmp}

Formal languages we are going to use are first-order languages:
\begin{defn}
A \emph{language} $L$ is a formal language given by the grammar of first-order logic and the additional data $\mathcal{L}$ called the signature of $L$:
\begin{enumerate}
\item a set $\mathcal{C}$ of letters called constant symbols,
\item a set $\mathcal{R}$ of letters called relation symbols and a positive integer (an arity) $n_R$ for each $R \in \mathcal{R}$,
\item a set $\mathcal{F}$ of letters called function symbols and a positive integer (an arity) $n_f$ for each $f \in \mathcal{F}$.
\end{enumerate}
\end{defn}

\begin{remark}
We will often talk about the language $L$ by referring to its signature $\mathcal{L}$. This should not cause a confusion as the signature $\mathcal{L}$ and the grammar of the first order logic uniquely determine the language $L$.
\end{remark}

\begin{exmp}
The language $\mathcal{L}_{EST}$ of elementary set theory is given by one constant symbol called an empty set, $\mathcal{C}=\{\emptyset\}$, one relation symbol called a set membership $\mathcal{R}=\{\in\}$ with a positive integer (arity) $n_{\in}=2$. The set of function symbols $\mathcal{F}$ are the set operations of a union, an intersection, each with an arity $2$.
\end{exmp}

\begin{defn}
Given a language $L$, $\phi$ is an $L$-formula iff $\phi \in L$.
\end{defn}

\section{Model theory\cite{marker2002model}}
Since the author to best of his knowledge considers the first-order model theory more developed as well as having better learning resources than model theory  of other logics, he will reason in first-order model-theory and will use the first-order definitions from Model Theory by Marker\cite{marker2002model}.

\begin{defn}
An \emph{$\mathcal{L}$-structure} (\emph{a model}) $\mathcal{M}$ is given by the following data:
\begin{enumerate}
\item a nonempty set $M$ called the universe, domain, or underlying set of $\mathcal{M}$;
\item a function $f^{\mathcal{M}} : M^{n_f} \to M$ for each $f \in F$;
\item a set $\mathcal{R}^{\mathcal{M}} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$;
\item an element $c^\mathcal{M} \in M$ for each $c \in C$.
\end{enumerate}
We refer to $f^\mathcal{M}, R^\mathcal{M}, c^\mathcal{M}$ as the interpretations of the symbols $f ,R, c$.
\end{defn}

\begin{exmp}
$\mathcal{M}_{India}$ is a model given by
$M=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$TastesHot=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$IsWhite=\{milk^\mathcal{M}\}$ with a canonical mapping of constants from
 $C=\{milk, curry\}$ to $M$. Therefore $\mathcal{M}$ is a model of a formula
$\phi=TastesHot(milk) \wedge \neg IsWhite(curry)$ denoting by
$\mathcal{M} \models \phi$ reading "a model $\mathcal{M}$ entails a formula $\phi$".
\end{exmp}

\begin{remark}
An $L$-structure is an $\mathcal{L}$-structure iff $\mathcal{L}$ is a signature of a language $L$.
\end{remark}

\begin{defn}
Given a set $T$ of logic sentences and a model $\mathcal{M}$. If $\forall \phi \in T. \mathcal{M} \models \phi$, then $\mathcal{M}$ is \emph{a model of $T$} and $T$ is \emph{a theory of $\mathcal{M}$}.
\end{defn}

\begin{defn}
$A$ is an axiomatization of the theory $T$ iff $M(A)=M(T)$.
\end{defn}

\begin{remark}
Typically we put further restrictions on the properties of the axiomatization $A$ that do not hold for $T$. E.g. $A$ must have finitely many axioms for $T$ with infinitely many axioms.
\end{remark}

\begin{defn}
$A$ is an axiomatization of the theory $O$ from the theory $B$ iff $M(A \union B)=M(O)$.
\end{defn}

\section{Logics\cite{sep-logic-nonmonotonic}}
\begin{defn}
A (monotone) \emph{consequence operator}\cite{sergot2005knowledgeRepresentationLectureNotes} on a set $S$ is a function $cl:\powerset{S} \to \powerset{S}$ satisfying the following conditions for all sets $X, Y \subseteq S$:
\begin{enumerate}
\item $X \subseteq cl(X)$ inclusion,
\item $cl(cl(X))=cl(X)$ idempotence,
\item $X \subseteq{Y} \implies cl(X) \subseteq{Y}$ monotony.
\end{enumerate}
\end{defn}

\begin{defn}
A \emph{non-monotone consequence operator} on a set $S$ is a function
$cl:\powerset{S} \to \powerset{S}$ satisfying the condition of extensivity, idempotence and not satisfying the condition of monotony.
\end{defn}

We will reason about the models in the first-order logic since this is the language of the model theory. However, there are other logics, notably non-monotonic logics that are used in ILP.

\begin{defn}
A logic satisfies a \emph{monotony} property iff its consequence operator $\models$ is monotone, i.e.
if $\Gamma \models \phi$ and $\Gamma \subseteq \Delta$ then $\Delta \models \phi$. A logic that satisfies a monotony property is called monotonic, otherwise non-monotonic.
\end{defn}

\begin{exmp}
First-order logic is monotonic.
\end{exmp}

\section{Measure theory}
The following definition of a measure is adapted from Mathworld, Wolfram Web Resource\cite{wolframMathworldMeasure}.

\begin{defn}
A \emph{measure} is a real-valued function $\mu$ on a powerset $\powerset{S}$ of a set $S$ satisfying the following properties:
\begin{enumerate}
\item $\mu(\emptyset)=0$ and $\mu(S)=1$,
\item if $X \subseteq Y$ then $\mu(X) \le \mu(Y)$,
\item if $X_n, n=0, 1, 2, ...$ are pairwise disjoint, then
$\mu(\cup^\infty_{n=0} X_n)=\Sigma^\infty_{n=0}\mu(X_n)$
\end{enumerate}
\end{defn}

\begin{exmp}
Let $S$ be the set of possible throws of a die, $S=\{1, 2, 3, 4, 5, 6\}$. Define a measure $\mu:\powerset{S} \to \mathbb{R}$ over $\powerset{S}$ by $\mu(\{i\})=1/6, i \in S$. Then from the axioms of a measure it follows that $\mu(\emptyset)=0$, $\mu(S)=1$ and $\mu(\{1,2,5\})=1/2 \le \mu(\{1,2,3,4,5\})=5/6$. Such $\mu$ is called a probability measure and a triple $\langle \powerset{S}, S, \mu \rangle$ is called a probability space.
\end{exmp}

\begin{exmp}
Let $S$ be a real line $S=\mathbb{R}$, define function $\mu|_J$ on the set of intervals $J \subseteq \powerset{S}$ on the real line by $\mu|_J: (a, b) \mapsto b-a$, then $\mu|_J$ has a unique extension $\mu:S \to \mathbb{R}$ which is a measure function.
\end{exmp}

\section{Logic Programming}

\begin{defn}
A logic programming language has a \emph{negation on failure}\cite{clark1978negation} NoF property iff $\forall \phi, \forall \psi. \phi \not\vdash \psi \implies \phi \vdash \neg\psi$ where the $\vdash$ is a consequence operator.
\end{defn}

\begin{exmp}
In a logic programming language Prolog in a program $P$ with a single sentence:

$spicy(X) :- curry(X).$

the atom $spicy(X)$ is not provable, therefore $P \vdash \neg spicy(X)$ since Prolog has a NoF property.
\end{exmp}

Notice that NoF property on the consequence operator directly implies its monotony. Unless indicated the logic programming language we will reason will will have a NoF property.

The following definitions and concepts are adaptations from Dianhuan Lin's Master thesis\cite{lin2009efficient}.

\subsection{Basic concepts and notation of Logic Programming\cite{lin2009efficient}}

\begin{defn}
A term is a constant, variable, or the application of a function symbol to the appropriate number of terms. A ground term is a term not containing variables.
An atom is the application of a predicate symbol to the appropriate number of terms. A literal is an atom or the negation of an atom.
\end{defn}

\begin{defn}
A definite goal is a clause of the form
$\leftObjectImplies B_1 , ..., B_n$.
where $n > 0$ and each $B_i$ is an atom.
Each $B_i$ is called a subgoal of the goal.
\end{defn}

\begin{defn}
A definite clause is a clause of the form
$A \leftObjectImplies B_1 , ..., B_n$
which contains precisely one positive literal $A$.
$A$ is called the head and $B_1$ , ..., $B_n$ is called the body of the clause.
A Horn clause is either a definite clause or a definite goal.
A unit clause consists of a single literal.
\end{defn}

\begin{defn}
A logic program is a finite set of clauses representing their conjunction.
\end{defn}

\subsubsection{Resolution\cite{kimber2012learning}}
The resolution inference rule for a literal $\phi$ and clauses $\psi, \chi$ is
$(\phi \vee \psi) \wedge (\neg \phi \wedge \chi) \models \phi \vee \chi$.

\subsection{SLD-resolution\cite{lin2009efficient}}

\begin{defn}
A \emph{substitution} $\theta$ is a finite set of the form
$\{v_1\/t_1 , .., v_n \/t_n \}$,
where each $v_i$ is a variable, each $t_i$ is a
term distinct from $v_i$ and the variables $v_1 , .., v_n$ are distinct. Each element $v_i \/t_i$ is called a binding
for $v_i$. $\theta$ is called a ground substitution if the $t_i$ are all ground terms.
\end{defn}

\begin{defn}
An expression is either a term, a literal, or a conjunction or disjunction of literals.
A simple expression is a term or a literal.
\end{defn}

\begin{defn}
\emph{Unification.}
Let $\Sigma$ be a finite set of expressions. A substitution $\theta$ is called a unifier for $\Sigma$ if $\Sigma \theta$ is a singleton (a
set containing exactly one element). A unifier $\theta$ for $\Sigma$ is called a most general unifier (mgu) for $\Sigma$
if, for each unifier $\theta$ of $\Sigma$ , there exists a substitution $\Gamma$ such that $\theta = \Sigma \Gamma$
\end{defn}
Details about unification algorithm can be found in \cite{lloyd1987foundations}.

\begin{defn}
Let $G$ be $\leftObjectImplies A_1 , ..., A_m , ..., A_k$ and
$C$ be $A \leftObjectImplies B_1 , ..., B_q$.
Then $G'$ is derived from $G$ and
$C$ using mgu $\theta$ if the following conditions hold:
i) $A_m$ is an atom, called the selected atom, in $G$.
ii) $\theta$ is an mgu of $A_m$ and $A$.
iii) $G'$ is the goal $\leftObjectImplies (A_1 , ..., A_{m−1} , B_1, ..., B_q , A_{m+1} , ..., A_k )\theta$, $G'$ is
called a resolvent of $G$ and $C$.
\end{defn}
SLD-resolution stands for SL-resolution for Definite clauses. SL stands for Linear resolution with Selected function.

\begin{defn}
\emph{SLD-derivation}.
Let $\Sigma$ be a set of clauses and $C$ a clause. A derivation of $C$ from $\Sigma$ is a finite sequence of clauses
$R_1 , .., R_k = C$, such that each $R_i$ is either in $\Sigma$, or a resolvent of two clauses in $\{R_1 , ..., R_{i−1} \}$. If
such a derivation exists, $\Sigma \vdash_r C$. Thus $C$ can be derived from $\Sigma$.
\end{defn}

SLD-refutation is a special case of SLD-derivation which derives empty clause $\emptyclause$.

\section{Inductive inference}
\subsection{Languages in the theory of inductive inference}
\begin{defn}
Fix languages $L$, $L'$ such that $L \subseteq L'$. We say that $L$ is \emph{a sublanguage} of $L'$, $L'$ is \emph{a superlanguage} of $L$.
\end{defn}

\begin{exmp}
Let a language $L$ be given by its signature $\mathcal{L}$=$\mathcal{C} \union \mathcal{R} \union \mathcal{F}$ and a language $L'$ by its signature $\mathcal{L}'=\mathcal{C}' \union \mathcal{R}' \union \mathcal{F}'$.
If $\mathcal{C} \subseteq \mathcal{C}'$, $\mathcal{R} \subseteq \mathcal{R}'$, $\mathcal{F} \subseteq \mathcal{F}'$, then $L \subseteq L'$. $L$ is a sublanguage of $L'$, $L'$ is a superlanguage of $L$.
\end{exmp}

\begin{defn}
Given two languages $L_o$ called \emph{an observational language}, $L_h$ called a \emph{hypothesis language}, \emph{a language of enquiry} $L$ is a language that is a superlanguage of a hypothesis language and a superlanguage of an observational language, i.e. $L_h \union L_o \subseteq L$.
\end{defn}

\begin{remark}
The language of enquiry is a model-theoretic language by our definition. We will apply model theory with the first-order logic since many ILP systems are based on Prolog - the logic programming language with its roots in first-order logic. Therefore the boolean connectives $\neg$, $\land$, $\lor$, $\implies$ are implicitly added to the language of enquiry $L$ and the formation rules of first-order logic are assumed. In generality one could devise a theory working in any formal language.
\end{remark}

\begin{exmp}
\begin{itemize}
\item The language of enquiry $L$ is given by $\mathcal{C}_o=\{milk, curry, rice\}$,$\mathcal{R}_o=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$, $\mathcal{F}_o=\{\}$.
\item Let the observational language $L_o$ be $\mathcal{C}_o=\{milk, curry, rice\}$,\\ $\mathcal{R}_o=\{TastesHot, IsWhite\}$, $\mathcal{F}_o=\{\}$
\item Let the hypothesis language $L_h$ be $\mathcal{C}_h=\{milk, curry, rice\}$,\\ $\mathcal{R}_h=\{TastesHot, IsWhite, ContainsSpice\}$, $\mathcal{F}_h=\{\}$.
\item $L_h$-sentences are $\forall x. TastesHot(x) \implies ContainsSpice(x)$,\\ $\forall x. IsWhite(x) \lor TastesHot(x)$.
\end{itemize}
\end{exmp}

\subsection{Inductive inference concepts}

\begin{defn}
\emph{An environment} $\mathcal{E}$ is a quadruple $\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ where $L$ is a language of enquiry, $L_o$ its observational language, $\mathtt{O}:L_o \to \{true, false\}$ \emph{an environment oracle}, $\mathcal{M}$ an $\mathcal{L}$-structure called \emph{the reality of $L$} satisfying:
$\forall \phi \in L_o. \mathcal{M} \models \phi \iff \mathtt{O}(\phi)=true$.
\end{defn}

\begin{exmp}
\begin{itemize}
\item In an environment England, the reality $\mathcal{M}_E$ is a model of the sentences\\ $\Sigma_E=\{TastesHot(curry), \neg TastesHot(milk)\}$.
\item In India, the reality $\mathcal{M}_I$ is a model of the sentences\\ $\Sigma_I=\{TastesHot(curry), TastesHot(milk)\}$.
\item Both $\mathcal{M}_E$, $\mathcal{•}l{M}_I$ are models of $L$.
\item $\mathcal{E}_E=\langle L, L_o, \mathtt{O}_E, \mathcal{M}_E \rangle$ and
$\mathcal{E}_I=\langle L_, L_o, \mathtt{O}_I, \mathcal{E}_I \rangle$ are two environments distinguished by their reality, consequently by their environment oracle function as well.
\end{itemize}
\end{exmp}

\begin{remark}
In generality one may develop a theory in which an environment may have multiple or no realities and an environment oracle returns a probability of $\phi$ being true in a possible reality or randomly chooses a reality $\mathcal{M}$ between the realities, then acts as an environment oracle with a single reality $\mathcal{M}$. This may be useful when the language of enquiry has a limited expressivity as demonstrated later.
\end{remark}

\begin{defn}
The set of \emph{observations} $O$ with respect to an observational language $L_o$ is any set of $L_o$-formulas.
\end{defn}

\begin{exmp}
\begin{itemize}
\item The set $O_E=\{TastesHot(curry), \neg TastesHot(milk), IsWhite(milk)\}$ is the set of observations.
\item The set $O_I=\{TastesHot(milk)\}$ is the set of observations.
\item The set $O_{world}=\{TastesHot(curry), \neg TastesHot(milk), TastesHot(milk), \\
IsWhite(milk)\}$ is the set of observations.
\end{itemize}
\end{exmp}

\begin{remark}
\begin{itemize}
\item The language of enquiry $L$ is not powerful enough to express $O_{world}=\{\neg TastesHot(milk) \land InEngland(milk), TastesHot(milk) \land InIndia(milk)\}$
 as it does not have predicate symbols $InEngland$ and $InIndia$ in its signature $\mathcal{L}$.
\item The inconsistency in the observations implies that there is no $\mathcal{L}$-structure $\mathcal{M}$ of $O_{world}$.
\item One of the central problems in ILP is the predicate invention - adding symbols $InEngland$ and $InIndia$ to the signature $\mathcal{L}$ of the language of enquiry.
\end{itemize}
\end{remark}

\begin{defn}
The \emph{background knowledge} or a current induced theory is a set $B$ of formulas in the language of enquiry $L$.
\end{defn}

\begin{remark}
In the definition \ref{scientific_method} of a scientific method, a special case of the background knowledge is considered where $B$ can consist of only the previously made hypotheses, thus $B \subseteq L_h$.
\end{remark}

\begin{note}
Given a set of observations $O$, an $L$-formula $Q$ \emph{divides} the models of $O$ into models of $O \wedge \{Q\}$ denoted $M(O \union \{Q\})$ and the models of $\{\neg Q\} \wedge O$ denoted $M(O \union \{Q\})$. That is $\forall \mathcal{M} \in M(O \union \{Q\}). \mathcal{M} \models O \union \{Q\}$,
$\forall \mathcal{M} \in M(O \union \{\neg Q\}). \mathcal{M} \models O \union \{\neg Q\}$.
\end{note}

\begin{defn}
\emph{A hypotheses space} or a search space is the set $\mathcal{H}$ of all consistent subsets of a hypothesis language $L_h$. A formula $H \in \mathcal{H}$ is called \emph{a hypothesis}.
\end{defn}

\subsection{Ultimate problem of scientific discovery}
Statement: Given an environment oracle $\mathtt{O}$ of an environment $\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ find the reality $\mathcal{M}$.

We do not yet consider the situation in which we may desire to learn approximate models of the reality. In general, depending on an environment, the reality may not exist, however our definition considers only the environments with exactly one reality. Some realities, e.g. (regular expression) are learnable, others may be not. The ultimate problem consists of numerous incremental problems.

\subsection{Incremental problem of scientific discovery}
We would like to find the reality most efficiently, where the efficiency may be measured by some criteria - e.g. time and resources. The following simplified definition does not take into account that some questions may be found more efficiently than others.

Set a probability measure $\mu:M(\emptyset) \to [0,1] \subset \mathbb{R}$ over models of a language of enquiry $L$. Given a background knowledge $B$, find a question $Q$ that minimizes the following equation: $|M(B \union {Q})-M(B \union {\neg Q})|$, i.e. a question that divides the models of $B$ most evenly.

\subsubsection{Postulates of inductive inference}
\begin{defn}
The first postulate of inductive inference (Church-Turing thesis). The reality
$\mathcal{M}$ of the environment
$\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$
is Turing-machine computable.
\end{defn}

\begin{defn}
The second postulate of inductive inference (Determinism). The oracle $\mathtt{O}$ of the environment $\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$
is deterministic, i.e. $\forall x \in L_o. \#\mathtt{O}(x)=1$.
\end{defn}

\begin{defn}
The third postulate of inductive inference (Occam's Razor). The reality with its full axiomatization of less Kolmogorov complexity is more probable than a reality with its full axiomatization of greater Kolmogorov complexity.
\end{defn}

\subsection{Problem of induction - model theoretic setting}
A problem of induction is a functional problem whose input is a pentuple $P=\langle L, L_o, L_h, O, B\rangle$ where $L$ is a language of enquiry with its sublanguages $L_o$, $L_h$, observations $O$ and the background knowledge $B$. A solution to a problem of induction (the output) is a theory $A$ meeting the entailment criterion
$O \subseteq cl(A \union B )$ where the consequence operator $cl$ is specified  in a more specific version of a problem.
$A$ is called \emph{an induced theory} from the background knowledge $B$ and the observations $O$, or an axiomatization of a theory $O$ given $B$.

\subsection{Scientific method}
\label{scientific_method}
A scientific method is an algorithm used to solve the ultimate problem of the scientific discovery:

0. Start with the empty theory $B_i=\emptyset$, set $i=0$.

1. If $B_i$ has the only model, then terminate, $B_i$ is a complete axiomatization of the reality of an environment.

2. Solve an incremental problem of scientific discovery by finding a question $Q$ given the current induced theory $B_i$.

3. Make an observation - ask an environment oracle $\mathtt{O}$ a question $Q$.

4. Induce a more precise theory $B_{i+1}:=B \union \{Q\}$ if the oracle says that $Q$ is true, $B_{i+1}:=B \union \{\neg Q\}$ if the oracle says that $\neg Q$ is true.

5. Increment $i$ and start from step 1 again.