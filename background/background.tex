
\chapter{Background Theory}

\section{Prerequisities}
We assume the reader is familiar with basic concepts in several areas and consider the following references to be potentially useful:
\begin{enumerate}
\item Foundations of Inductive Logic Programming by Cheng and Wolf \cite{cheng1997}
\item Model theory: An introduction by David Marker \cite{marker2002}
\item An introduction to Kolmogorov complexity and its applications by Li and Vitanyi \cite{li1997}
\item Real Analysis by H.L.Royden  \cite{royden1988}, a reference on measure theory
\end{enumerate}
However, the usage of the concepts does not exceed its rudimentary application and the reader is encouraged to proceed further even if one may not be familiar with all the areas outlined, we suggest to use the literature when the need arises.
\section{A logic language}
\begin{defn}
An \emph{alphabet} is a set $\mathcal{A}$ of elements called \emph{letters} of an alphabet.
\end{defn}

\begin{defn}
A word over an alphabet $\mathcal{A}$ is a finite sequence (a string) of letters of the alphabet $\mathcal{A}$.
\end{defn}

\begin{defn}
A formal language $L$ is a set of words over the specified alphabet $\mathcal{A}$, i.e. $L \subseteq \powerset{A}$.
\end{defn}

\begin{exmp}
Let $R$ be a regular expression $0001*$.
\begin{itemize}
\item The alphabet is the set $\mathcal{A}={\epsilon, 0,1,*}$. $0$, $1$, $*$ are called letters of $\mathcal{A}$.
\item The words over $A$ are $000$.
\end{itemize}
\end{exmp}

Formal languages we are going to use are first-order languages:
\begin{defn}
A \emph{language} $L$ is a formal language given by the grammar of the first-order logic and the additional data $\mathcal{L}$ called the signature of $L$:
\begin{enumerate}
\item a set $\mathcal{C}$ of letters called constant symbols,
\item a set $\mathcal{R}$ of letters called relation symbols and a positive integer (an arity) $n_R$ for each $R \in \mathcal{R}$,
\item a set $\mathcal{F}$ of letters called function symbols and a positive integer (an arity) $n_f$ for each $f \in \mathcal{F}$.
\end{enumerate}
\end{defn}

\begin{remark}
We will often talk about the language $L$ by referring to its signature $\mathcal{L}$. This should not cause a confusion as the signature $\mathcal{L}$ and the grammar of the first order logic uniquelly determine the language $L$.
\end{remark}

\begin{exmp}
The language $\mathcal{L}_{EST}$ of elementary set theory is given by one constant symbol called an empty set, $\mathcal{C}=\{\emptyset\}$, one relation symbol called a set membership $\mathcal{R}=\{\in\}$ with a positive integer (arity) $n_{\in}=2$. The set of function symbols $\mathcal{F}$ are the set operations of a union, an intersection, each with an arity $2$.
\end{exmp}

\begin{defn}
Given a language $L$, $\phi$ is an $L$-formula iff $\phi \in L$.
\end{defn}

\section{Model theory\cite{marker2002}}
Since the author to best of his knowledge considers the first-order model theory more developed as well as having better learning resources than model theory  of other logics, he will reason in first-order model-theory and will use the first-order definitions from Model Theory by Marker\cite{marker2002}.

\begin{defn}
An \emph{$\mathcal{L}$-structure} (\emph{a model}) $\mathcal{M}$ is given by the following data:
\begin{enumerate}
\item a nonempty set $M$ called the universe, domain, or underlying set of $\mathcal{M}$;
\item a function $f^{\mathcal{M}} : M^{n_f} \to M$ for each $f \in F$;
\item a set $\mathcal{R}^{\mathcal{M}} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$;
\item an element $c^\mathcal{M} \in M$ for each $c \in C$.
\end{enumerate}
We refer to $f^\mathcal{M}, R^\mathcal{M}, c^\mathcal{M}$ as the interpretations of the symbols $f ,R, c$.
\end{defn}

\begin{exmp}
$\mathcal{M}_{India}$ is a model given by
$M=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$TastesHot=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$IsWhite=\{milk^\mathcal{M}\}$ with a canonical mapping of constants from
 $C=\{milk, curry\}$ to $M$. Therefore $\mathcal{M}$ is a model of a formula
$\phi=TastesHot(milk) \wedge \neg IsWhite(curry)$ denoting by
$\mathcal{M} \models \phi$ reading "a model $\mathcal{M}$ entails a formula $\phi$".
\end{exmp}

\begin{remark}
An $L$-structure is an $\mathcal{L}$-structure iff $\mathcal{L}$ is a signature of a language $L$.
\end{remark}

\begin{defn}
Given a set $T$ of logic sentences and a model $\mathcal{M}$. If $\forall \phi \in T. \mathcal{M} \models \phi$, then $\mathcal{M}$ is \emph{a model of $T$} and $T$ is \emph{a theory of $\mathcal{M}$}.
\end{defn}

\begin{defn}
$A$ is an axiomatization of the theory $T$ iff $M(A)=M(T)$.
\end{defn}

\begin{remark}
Typically we put further restrictions on the properties of the axiomatization $A$ that do not hold for $T$. E.g. $A$ must have finitely many axioms for $T$ with infinitely many axioms.
\end{remark}

\begin{defn}
$A$ is an axiomatization of the theory $O$ from the theory $B$ iff $M(A \union B)=M(O)$.
\end{defn}

\section{Logics\cite{stanford2010}}
\begin{defn}
A (monotone) \emph{consequence operator}\cite{wikipedieClosureOperator} on a set $S$ is a function $cl:\powerset{S} \to \powerset{S}$ satisflying the following conditions for all sets $X, Y \subseteq S$:
\begin{enumerate}
\item $X \subseteq cl(X)$ inclusion,
\item $cl(cl(X))=cl(X)$ idempotence,
\item $X \subseteq{Y} \implies cl(X) \subseteq{Y}$ monotony.
\end{enumerate}
\end{defn}

\begin{defn}
A \emph{non-monotone consequence operator} on a set $S$ is a function
$cl:\powerset{S} \to \powerset{S}$ satisflying the condition of extensivity, idempotence and not satisflying the condition of monotony.
\end{defn}

We will reason about the models in the first-order logic since this is the language of the model theory. However, there are other logics, notably non-monotonic logics that are used in ILP.

\begin{defn}
A logic satisfies a \emph{monotony} property iff its consequence operator $\models$ is monotone, i.e.
if $\Gamma \models \phi$ and $\Gamma \subseteq \Delta$ then $\Delta \models \phi$. A logic that satisfies a monotony property is called monotonic, otherwise non-monotonic.
\end{defn}

\begin{exmp}
A first-order logic is monotonic.
\end{exmp}

\section{Measure theory}
The following definition of a measure is adapted from Mathworld, Wolfram Web Resource\cite{wolframMathworldMeasure}.

\begin{defn}
A \emph{measure} is a real-valued function $\mu$ on a powerset $\powerset{S}$ of a set $S$ satisfying the following properties:
\begin{enumerate}
\item $\mu(\emptyset)=0$ and $\mu(S)=1$,
\item if $X \subseteq Y$ then $\mu(X) \le \mu(Y)$,
\item if $X_n, n=0, 1, 2, ...$ are pairwise disjoint, then
$\mu(\cup^\infty_{n=0} X_n)=\Sigma^\infty_{n=0}\mu(X_n)$
\end{enumerate}
\end{defn}

\begin{exmp}
Let $S$ be the set of possible throws of a die, $S=\{1, 2, 3, 4, 5, 6\}$. Define a measure $\mu:\powerset{S} \to \mathbb{R}$ over $\powerset{S}$ by $\mu(\{i\})=1/6, i \in S$. Then from the axioms of a measure it follows that $\mu(\emptyset)=0$, $\mu(S)=1$ and $\mu(\{1,2,5\})=1/2 \le \mu(\{1,2,3,4,5\})=5/6$. Such $\mu$ is called a probability measure and a triple $\langle \powerset{S}, S, \mu \rangle$ is called a probability space.
\end{exmp}

\begin{exmp}
Let $S$ be a real line $S=\mathbb{R}$, define function $\mu|_J$ on the set of intervals $J \subseteq \powerset{S}$ on the real line by $\mu|_J: (a, b) \mapsto b-a$, then $\mu|_J$ has a unique extension $\mu:S \to \mathbb{R}$ which is a measure function.
\end{exmp}

\section{Logic Programming}

\begin{defn}
A logic programming language has a \emph{negation on failure}\cite{clark1978} NoF property iff $\forall \phi, \forall \psi. \phi \not\vdash \psi \implies \phi \vdash \neg\psi$ where the $\vdash$ is a consequence operator.
\end{defn}

\begin{exmp}
In a logic programming language Prolog in a program $P$ with a single sentence:

$spicy(X) :- curry(X).$

the atom $spicy(X)$ is not provable, therefore $P \vdash \neg spicy(X)$ since Prolog has a NoF property.
\end{exmp}

Notice that NoF property on the consequence operator directly implies its monotony. Unless indicated the logic programming language we will reason will will have a NoF property.

The following definitions and concepts are an adaptations from the Dianhuan Lin's Master thesis\cite{lin2009}.

\subsection{Basic concepts and notation\cite{lin2009}}

\begin{defn}
A term is a constant, variable, or the application of a function symbol to the appropriate number of terms. A ground term is a term not containing variables.
An atom is the application of a predicate symbol to the appropriate number of terms. A literal is an atom or the negation of an atom.
\end{defn}

\begin{defn}
A definite goal is a clause of the form
$\leftObjectImplies B_1 , ..., B_n$.
where $n > 0$ and each $B_i$ is an atom.
Each $B_i$ is called a subgoal of the goal.
\end{defn}

\begin{defn}
A definite clause is a clause of the form
$A \leftObjectImplies B_1 , ..., B_n$
which contains precisely one positive literal $A$.
$A$ is called the head and $B_1$ , ..., $B_n$ is called the body of the clause.
A Horn clause is either a definite clause or a definite goal.
A unit clause consists of a single literal.
\end{defn}

\begin{defn}
A logic program is a finite set of clauses representing their conjunction.
\end{defn}

\subsubsection{Resolution\cite{kimber2011}}
The resolution inference rule for a literal $\phi$ and clauses $\psi, \chi$ is
$(\phi \vee \psi) \wedge (\neg \phi \wedge \chi) \models \phi \vee \chi$.

\subsection{SLD-resolution\cite{lin2009}}

\begin{defn}
A \emph{substitution} $\theta$ is a finite set of the form
$\{v_1\/t_1 , .., v_n \/t_n \}$,
where each $v_i$ is a variable, each $t_i$ is a
term distinct from $v_i$ and the variables $v_1 , .., v_n$ are distinct. Each element $v_i \/t_i$ is called a binding
for $v_i . \theta$ is called a ground substitution if the $t_i$ are all ground terms.
\end{defn}

\begin{defn}
An expression is either a term, a literal, or a conjunction or disjunction of literals.
A simple expression is a term or a literal.
\end{defn}

\begin{defn}
\emph{Unification.}
Let $\Sigma$ be a finite set of expressions. A substitution $\theta$ is called a unifier for $\Sigma$ if $\Sigma \theta$ is a singleton (a
set containing exactly one element). A unifier $\theta$ for $\Sigma$ is called a most general unifier (mgu) for $\Sigma$
if, for each unifier $\theta$ of $\Sigma$ , there exists a substitution $\Gamma$ such that $\theta = \Sigma \Gamma$
\end{defn}
Details about unification algorithm can be found in \cite{lloyd1987}.

\begin{defn}
Let $G$ be $\leftObjectImplies A_1 , ..., A_m , ..., A_k$ and
$C$ be $A \leftObjectImplies B_1 , ..., B_q$.
Then $G’$ is derived from $G$ and
$C$ using mgu $\theta$ if the following conditions hold:
i) $A_m$ is an atom, called the selected atom, in $G$.
ii) $\theta$ is an mgu of $A_m$ and $A$.
iii) $G’$ is the goal $\leftObjectImplies (A_1 , ..., A_{m−1} , B_1, ..., B_q , A_{m+1} , ..., A_k )\theta G’$ is
called a resolvent of $G$ and $C$.
\end{defn}
SLD-resolution stands for SL-resolution for Definite clauses. SL stands for Linear resolution with Selected function.

\begin{defn}
\emph{SLD-derivation}.
Let $\Sigma$ be a set of clauses and $C$ a clause. A derivation of $C$ from $\Sigma$ is a finite sequence of clauses
$R_1 , .., R_k = C$, such that each $R_i$ is either in $\Sigma$, or a resolvent of two clauses in $\{R_1 , ..., R_{i−1} \}$. If
such a derivation exists, $\Sigma \vdash_r C$. Thus $C$ can be derived from $\Sigma$.
\end{defn}

SLD-refutation is a special case of SLD-derivation which derives empty clause $\emptyclause$.

\section{Inductive inference}
\subsection{Languages in the theory of inductive inference}
\begin{defn}
Fix languages $L$, $L'$ such that $L \subseteq L'$. We say that $L$ is \emph{a sublanguage} of $L'$, $L'$ is \emph{a superlanguage} of $L$.
\end{defn}

\begin{exmp}
Let a language $L$ be given by its signature $\mathcal{L}$=$\mathcal{C} \union \mathcal{R} \union \mathcal{F}$ and a language $L'$ by its signature $\mathcal{L}'=\mathcal{C}' \union \mathcal{R}' \union \mathcal{F}'$.
If $\mathcal{C} \subseteq \mathcal{C}'$, $\mathcal{R} \subseteq \mathcal{R}'$, $\mathcal{F} \subseteq \mathcal{F}'$, then $L \subseteq L'$. $L$ is a sublanguage of $L'$, $L'$ is a superlanguage of $L$.
\end{exmp}

\begin{defn}
Given two languages $L_o$ called \emph{an observational language}, $L_h$ called a \emph{hypothesis language}, \emph{a language of enquiry} $L$ is a language that is a superlanguage of a hypothesis language and a superlanguage of an observational language, i.e. $L_h \union L_o \subseteq L$.
\end{defn}

\begin{remark}
The language of enquiry is a model-theoretic language by our definition. We will apply model theory with the first-order logic since many ILP systems are based on Prolog - the logic programming language with its roots in first-order logic. Therefore the boolean connectives $\neg$, $\land$, $\lor$, $\implies$ are implicitly added to the language of enquiry $L$ and the formation rules of first-order logic are assumed. In generality one could devise a theory working in any formal language.
\end{remark}

\begin{exmp}
\begin{itemize}
\item The language of enquiry $L$ is given by $\mathcal{C}_o=\{milk, curry, rice\}$,$\mathcal{R}_o=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$, $\mathcal{F}_o=\{\}$.
\item Let the observational language $L_o$ be $\mathcal{C}_o=\{milk, curry, rice\}$,\\ $\mathcal{R}_o=\{TastesHot, IsWhite\}$, $\mathcal{F}_o=\{\}$
\item Let the hypothesis language $L_h$ be $\mathcal{C}_h=\{milk, curry, rice\}$,\\ $\mathcal{R}_h=\{TastesHot, IsWhite, ContainsSpice\}$, $\mathcal{F}_h=\{\}$.
\item $L_h$-sentences are $\forall x. TastesHot(x) \implies ContainsSpice(x)$,\\ $\forall x. IsWhite(x) \lor TastesHot(x)$.
\end{itemize}
\end{exmp}

\subsection{Inductive inference concepts}

\begin{defn}
\emph{An environment} $\mathcal{E}$ is a quadruple $\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ where $L$ is a language of enquiry, $L_o$ its observational language, $\mathtt{O}:L_o \to \{true, false\}$ \emph{an environment oracle}, $\mathcal{M}$ an $\mathcal{L}$-structure called \emph{the reality of $L$} satisfying:
$\forall \phi \in L_o. \mathcal{M} \models \phi \iff \mathtt{O}(\phi)=true$.
\end{defn}

\begin{exmp}
\begin{itemize}
\item In an environment England, the reality $\mathcal{M}_E$ is a model of the sentences\\ $\Sigma_E=\{TastesHot(curry), \neg TastesHot(milk)\}$.
\item In India, the reality $\mathcal{M}_I$ is a model of the sentences\\ $\Sigma_I=\{TastesHot(curry), TastesHot(milk)\}$.
\item Both $\mathcal{M}_E$, $\mathcal{•}l{M}_I$ are models of $L$.
\item $\mathcal{E}_E=\langle L, L_o, \mathtt{O}_E, \mathcal{M}_E \rangle$ and
$\mathcal{E}_I=\langle L_, L_o, \mathtt{O}_I, \mathcal{E}_I \rangle$ are two environments distinguished by their reality, consequently by their environment oracle function as well.
\end{itemize}
\end{exmp}

\begin{remark}
In generality one may develop a theory in which an environment may have multiple or none realities and an environment oracle returns a probability of $\phi$ being true in a possible reality or randomly chooses a reality $\mathcal{M}$ between the realities, then acts as an environment oracle with a single reality $\mathcal{M}$. This may be useful when the language of enquiry has a limited expressivity as demonstrated later.
\end{remark}

\begin{defn}
The set of \emph{observations} $O$ with respect to an observational language $L_o$ is any set of $L_o$-formulas.
\end{defn}

\begin{exmp}
\begin{itemize}
\item The set $O_E=\{TastesHot(curry), \neg TastesHot(milk), IsWhite(milk)\}$ is the set of observations.
\item The set $O_I=\{TastesHot(milk)\}$ is the set of observations.
\item The set $O_{world}=\{TastesHot(curry), \neg TastesHot(milk), TastesHot(milk), \\
IsWhite(milk)\}$ is the set of observations.
\end{itemize}
\end{exmp}

\begin{remark}
\begin{itemize}
\item The language of enquiry $L$ is not powerful enough to express $O_{world}=\{\neg TastesHot(milk) \land InEngland(milk), TastesHot(milk) \land InIndia(milk)\}$
 as it does not have predicate symbols $InEngland$ and $InIndia$ in its signature $\mathcal{L}$.
\item The inconsistency in the observations implies that there is no $\mathcal{L}$-structure $\mathcal{M}$ of $O_{world}$.
\item One of the central problems in ILP is the predicate invention - adding symbols $InEngland$ and $InIndia$ to the signature $\mathcal{L}$ of the language of enquiry.
\end{itemize}
\end{remark}

\begin{defn}
The \emph{background knowledge} or a current induced theory is a set $B$ of formulas in the language of enquiry $L$.
\end{defn}

\begin{remark}
In the definition \ref{scientific_method} of a scientific method, a special case of the background knowledge is considered where $B$ can consist of only the previously made hypotheses, thus $B \subseteq L_h$.
\end{remark}

\begin{note}
Given a set of observations $O$, an $L$-formula $Q$ \emph{divides} the models of $O$ into models of $O \wedge \{Q\}$ denoted $M(O \union \{Q\})$ and the models of $\{\neg Q\} \wedge O$ denoted $M(O \union \{Q\})$. That is $\forall \mathcal{M} \in M(O \union \{Q\}). \mathcal{M} \models O \union \{Q\}$,
$\forall \mathcal{M} \in M(O \union \{\neg Q\}). \mathcal{M} \models O \union \{\neg Q\}$.
\end{note}

\begin{defn}
\emph{A hypotheses space} or a search space is the set $\mathcal{H}$ of all consistent subsets of a hypothesis language $L_h$. A formula $H \in \mathcal{H}$ is called \emph{a hypothesis}.
\end{defn}

\subsection{Ultimate problem of scientific discovery}
Statement: Given an environment oracle $\mathtt{O}$ of an environment $\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$ find the reality $\mathcal{M}$.

We do not yet consider the situation in which we may desire to learn approximate models of the reality. In general, depending on an environment, the reality may not exist, however our definition considers only the environments with exactly one reality. Some realities, e.g. (regular expression) are learnable, others may be not. The ultimate problem consists of numerous incremental problems.

\subsection{Incremental problem of scientific discovery}
We would like to find the reality most efficiently, where the efficiency may be measured by some criteria - e.g. time and resources. The following simplified definition does not take into the account that some questions may be found more efficiently than others.

Set a probability measure $\mu:M(\emptyset) \to [0,1] \subset \mathbb{R}$ over models of a language of enquiry $L$. Given a background knowledge $B$, find a question $Q$ that minimizes the following equation: $|M(B \union {Q})-M(B \union {\neg Q})|$, i.e. a question that divides the models of $B$ most evenly.

\subsubsection{Postulates of inductive inference}
\begin{defn}
The first postulate of inductive inference (Church-Turing thesis). The reality
$\mathcal{M}$ of the environment
$\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$
is Turing-machine computable.
\end{defn}

\begin{defn}
The second postulate of inductive inference (Determinism). The oracle $\mathtt{O}$ of the environment $\mathcal{E}=\langle L, L_o, \mathtt{O}, \mathcal{M} \rangle$
is deterministic, i.e. $\forall x \in L_o. \#\mathtt{O}(x)=1$.
\end{defn}

\begin{defn}
The third postulate of inductive inference (Occam's Razor). The reality with its full axiomatization of less Kolmogorov complexity is more probable than a reality with its full axiomatization of greater Kolmogorov complexity.
\end{defn}

\subsection{Problem of induction - model theoretic setting}
A problem of induction is a functional problem whose input is a pentuple $P=\langle L, L_o, L_h, O, B\rangle$ where $L$ is a language of enquiry with its sublanguages $L_o$, $L_h$, observations $O$ and the background knowledge $B$. A solution to a problem of induction (the output) is a theory $A$ meeting the entailment criterion
$O \subseteq cl(A \union B )$ where the consequence operator $cl$ is specified  in a more specific version of a problem.
$A$ is called \emph{an induced theory} from the background knowledge $B$ and the observations $O$, or an axiomatization of a theory $O$ given $B$.

\subsection{Scientific method}
\label{scientific_method}
A scientific method is an algorithm used to solve the ultimate problem of the scientific discovery:

0. Start with the empty theory $B_i=\emptyset$, set $i=0$.

1. If $B_i$ has the only model, then terminate, $B_i$ is a complete axiomatization of the reality of an environment.

2. Solve an incremental problem of scientific discovery by finding a question $Q$ given the current induced theory $B_i$.

3. Make an observation - ask an environment oracle $\mathtt{O}$ a question $Q$.

4. Induce a more precise theory $B_{i+1}:=B \union \{Q\}$ if the oracle says that $Q$ is true, $B_{i+1}:=B \union \{\neg Q\}$ if the oracle says that $\neg Q$ is true.

5. Increment $i$ and start from step 1 again.

\chapter{Inductive logic programming}
The following definitions are inspired from Inductive Logic Programming as Abductive Search paper by Corapi et al.\cite{corapi2010}

\subsection{ILP problem}

\begin{defn}\cite{corapi2010}
An \emph{inductive logic programming problem} is a pentuple $\langle O, B, \mathcal{O}, \mathcal{B}, \mathcal{H} \rangle$ where $O$ is a set of sentences called observations, $\mathcal{O} \subseteq L_o$ a subset of an implicit language $L_o$ called an observational language, $B$ is a set of sentences called the background knowledge, $\mathcal{B} \subseteq L$ is a subset of an implicit language $L$ called the language of enquiry, and $\mathcal{H}$ called a bias is a subset of an implicit language $L_h$ called the hypotheses language such that $L_h \subseteq L$, $L_o \subseteq L$, $O \in \mathcal{O}$, $B \in \mathcal{B}$.

A \emph{solution to an ILP problem} is a set of sentences $H \in \mathcal{H}$ called a hypothesis satisflying the conditions
i) consistency $false \not \in cl(O \union B \union H)$,
ii) sufficiency $O \subseteq cl(B \union H)$.
\end{defn}

In ILP often the language of enquiry $L$ is the logic programming language (e.g. Prolog). A constructed $L$-formula in Prolog is a definite clause. The background knowledge and induced theory are finite.

In the context of ILP one divides the observations into positive examples $E^+$ where the reality is a model of instances of $E^+$, and negative examples $E^-$ - where the reality is a model of negated instances of $E^-$. If the logic programming language is non-monotone, then the consequence operator $cl$ does not satisfly the monotone condition and the division of the examples is conceptually important. The clause that is not provable from the axioms is false as opposed to the monotonic logics whose theories can be incomplete.

\subsection{ILP concepts}

\subsubsection{Duce's rules for inductive inference\cite{muggleton1995}}
Duce had six inductive inference rules. Four of these were concerned with definite clause propositional logic. In the following description of the inference rules
lower-case letters represent propositional variables and upper-case letters represent conjunctions of propositional variables.

Absortion: $A \wedge B \objectImplies p, A \objectImplies q \models B \wedge q \objectImplies p, A \objectImplies q$,

Identification: $A \wedge B \objectImplies p, q \wedge A \objectImplies p
\models B \objectImplies q, A \wedge q \objectImplies p$,

Intra-construction: $A \wedge B \objectImplies p, A \wedge C \objectImplies p
\models B \objectImplies q, A \wedge q \objectImplies p, C \objectImplies q$

Inter-construction: $A \wedge B \objectImplies p, A \wedge C \objectImplies p
\models r \wedge B \objectImplies p, A \objectImplies r, r \wedge C \objectImplies q$

\subsubsection{Inverse Entailment}
Inverse Entailment is a correspondence between an induction and a deduction:
\begin{thm}\cite{kimber2011}
Let $B$ be a Horn program, and let $h$ and $e$ be
Horn clauses. Then $B \wedge h \models e \iff B \wedge \neg e |= \neg h$.
\end{thm}

\section{ILP systems}

\subsection{ILP system definition}
An ILP system is a function
$f:\langle O, B, \mathcal{O}, \mathcal{B}, \mathcal{H}\rangle \mapsto H$ where the pentuple $\langle O, B, \mathcal{O}, \mathcal{B}, \mathcal{H}\rangle$
is an inductive logic programming problem and a hypothesis $H \in \mathcal{H}$ is a solution to an ILP problem.

We give an overview of ILP systems taking different approaches to an ILP problem. The definition of an ILP system we gave is not sufficient for making meaningful comparisons based on the usefulness of these systems in real applications nor from a theoretic viewpoint. The aim of familiarizing with these systems is to find the intuition on the key properties of ILP systems that should be formalized in order to benefit from the mathematical rigour required for reasoning about ILP systems.

\subsection{TDHD framework\cite{muggleton2008}}
A set of clauses $\top$ called a top theory is required on the input in addition to observations and the background knowledge by the systems solving the problem of induction with a TDHD framework. Consequently the search space is restricted by requiring that each hypothetised clause of a hypothesis $H$ must be entailed by the top theory $\top$.

\subsubsection{Toplog\cite{muggleton2008}}
A toplog is an ILP system implementing TDHD framework. The algorithm used to construct the hypothesis uses Mode Directed Inverse Entailment and follows the steps:
\begin{itemize}
\item construct the top theory $\top$,
\item hypothesis derivation: derive refutations of $\neg e$ from $B$ and $\top$, derive a clause $h$ from the refutations, add $h$ to $H$.
\item coverage computation: which examples $E^+$ and $E^-$ are entailed by $h \in H$.
\item hypothesis construction: select $H' \subseteq H$ maximizing the score function - e.g. compression, coverage, accuracy,
\end{itemize}

\subsubsection{MC-Toplog\cite{muggleton2012}}
MC-Toplog is a Toplog's sequel, derives hypotheses like Toplog, in addition allows multiple clauses in a hypothesis. Its extended framework TDTcD restricts a hypotheses space to clauses entailing generalization of multiple examples (co-generalization) as opposesed to Toplog that could generalizing only a single example.

\subsection{Induction on Failure framework\cite{kimber2011}}
Induction on Failure framework (IoF) is a method for deriving a hypothesis $H$ where a single clause $h \in H$ does not necessarily need to explain an example $e \in E$, but an example can be explained by multiple clauses. Such a search space is called a connected theory.
\begin{defn}
A connected theory $T$ for a ground Horn clause $e$ and a Horn theory $B$ is a set of clauses that can be partitioned into sets $T_1, ..., T_n$ so that
(i) $B \union T_1^+ \models e_{head}$,
(ii) $\forall i \in \{1, ..., n-1\}. B \union e_{body} \union T_{i+1}^+ \models T_i^-$,
(iii) $B \union e_{body} \models T_n^-$,
(iv) $B \union T \not\models \square$.
\end{defn}

\subsubsection{Imparo\cite{kimber2011}}
Imparo is an ILP system based on a general IoF theoretical framework with the following algorithm:
\begin{itemize}
\item 1: select an example $E$ from the set of positive examples $E_{pos}$,
\item compute the most specific connected theory for an example $E$ and the background knowledge $B$,
\item search the lattice of sets of clauses subsuming the connected theory and choose the hypothesis $H$ with the highest score according to the score function such that $H \models E$,
\item add $H$ to $B$,
\item remove all $E' \in E_{pos}$ implied by new $B$, $B \models E'$.
\item if $E_{pos} = \emptyset$ finish, otherwise go to 1.
\end{itemize}

\subsection{Meta-Interpretive Learning framework\cite{muggleton2013}}
Meta-Interpretive Learning (MIL) framework solves a problem of induction in a variant of the normal setting for ILP.

\begin{defn}
\emph{(Meta-Interpretive Learning setting)} A Meta-Interpretive Learning (MIL)
problem consists of $Input = \langle B, E \rangle$ and $Output =H$ where the background knowledge
$B = B_M \union B_A$ . $B_M$ is a definite logic program representing a meta-interpreter and $B_A$ and
$H$ are ground definite Higher-Order Datalog programs consisting of positive unit clauses.
The predicate symbol constants in $B_A$ and $H$ are represented by Skolem constants. The examples are $E = E^+ , E^−$ where $E^+$ is a ground logic program consisting of positive unit
clauses and $E^−$ is a ground logic program consisting of negative unit clauses. The $Input$ and
$Output$ are such that $B, H \models E^+$ and for all $e^-$ in $E^-$, $B, H \not\models e^-$.
\end{defn}

\begin{defn}
\emph{(Meta-interpretive learner)} Let $\mathcal{H}_{B,E}$ represent the complete set of abductive
hypotheses $H$ for the MIL setting of the previous definition. Algorithm $A$ is said to be a Meta-interpretive learner iff for all $B$, $E$ such that $H$ is the output of Algorithm $A$ given $B$ and $E$
as inputs, it is the case that $H \in \mathcal{H}_{B,E}$.
\end{defn}

Capability of predicate invention.
Based on T-directed framework. Unique T element. Unique bottom element.

\subsubsection{Metagol}
Metagol is an implementation of an MIL framework that finds the hypothesis of a minimal length within its search space.

\subsection{Aleph}
In the Aleph's manual\cite{aleph2007} a reader would find the description of the basic algorithm:
\begin{enumerate}
\item \emph{Select example.} Select an example to be generalised. If none exist, stop, otherwise proceed to the next step.
\item \emph{Build most-specific-clause.} Construct the most specific clause that entails the example selected, and is within language restrictions provided. This is usually a definite clause with many literals, and is called the "bottom clause." This step is sometimes called the "saturation" step. Details of constructing the bottom clause can be found in Stephen Muggleton's 1995 paper: Inverse Entailment and Progol\cite{muggleton1995}.
\item \emph{Search.} Find a clause more general than the bottom clause. This is done by searching for some subset of the literals in the bottom clause that has the "best" score. Two points should be noted. First, confining the search to subsets of the bottom clause does not produce all the clauses more general than it, but is good enough for this thumbnail sketch. Second, the exact nature of the score of a clause is not really important here. This step is sometimes called the "reduction" step.
\item \emph{Remove redundant.} The clause with the best score is added to the current theory, and all examples made redundant are removed. This step is sometimes called the "cover removal" step. Note here that the best clause may make clauses other than the examples redundant. Again, this is ignored here. Return to Step 1.
\end{enumerate}

\subsection{Other systems}
Some other ILP systems include Aleph, Golem, Progol,
Spectre, EBG, Alecto, FOIL, Linus, Marvin, Mis, Confucius, Quinlan, ASPAL, Hyper, Tal, Tilde, Hail, CF-induction method.

\section{The role of a language in learning the models}
Consider an empty language. It has one possible interpretation and one model up to an isomorphism.
By extending the language we can distinguish the models further. The problem of the predicate invention is to invent a predicate so that the right distinction between the models is made based on the language.
Questions:
1. How can we measure an expessivity and a complexity of a language?
2. How much information can be captured by a $\mathcal{L}$-theory given a language $\mathcal{L}$?
3. What is the maximal complexity of the language $\mathcal{L}$ for which the $\mathcal{L}$-theory is decidable?
4. Complexity of learning the equivalence class of the reality given a language.
5. Is there a language for which the task of learning the equivalence class of the reality is undecidable?
6. What percentage of the reality can we recover from observing and reasoning only with the statements in the restricted language?
7. Can a language be partitioned (or expressed as posets of sublanguages) into sublanguages and the theories of the sublanguages be learnt, then joint into a theory of the original language?

\section{Language bias}
\begin{defn}
Given a language $L$, the \emph{language bias} is a property (a boolean valued function) $P$ defined on all words of $L$.
\end{defn}

\begin{exmp}
Define the property $P$ by $\forall w \in L. P(w) \iff w \in L_h$. Then $P$ is a language bias of the hypotheses language $L_h$ in its superlanguage of enquiry $L$.
\end{exmp}

\begin{exmp}
The signature of $L$ is
$\mathcal{L}=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$,
the signature of $L_h$ is
$\mathcal{L}_h=\{TastesHot, IsWhite, ContainsSpice\}$.
Let $P(w) \iff w$ does not contain $ContainsSugar$. $P$ is the language bias of $L_h$ in $L$.
\end{exmp}

\begin{remark}
We will often think of a bias on $L$ as a subset $P$ of $L$ rather than a property on $L$ and use the notation interchangeably:
$P=\{w \in L : P(w)\} \subseteq L$.
\end{remark}

\begin{defn}
A bias $P$ of the language $L$ is \emph{sufficiently weak} with respect to the theory $T$ iff there exists an axiomatization $A$ of the theory $T$ such that $A \subseteq P$. If $P$ is not sufficiently weak with respect to the theory $T$ we say that $P$ is \emph{too strong} with respect to the theory $T$.
\end{defn}

\begin{defn}
Let $P_1$, $P_2$ be biases on the language $L$. $P_1$ is \emph{weaker} than $P_2$ and $P_2$ is \emph{stronger} than $P_1$ iff $P_2 \subseteq P_1$.
\end{defn}

\begin{exmp}
Define biases $P_k$ for $k \in \mathbb{Z}_{\ge 0}$ by $P_k(\phi)$ iff $\phi$ consists of at most $k$ distinct characters. Let $T$ be the theory of the elementary class of the partial orders. Let $A=\{\phi_1, \phi_2, \phi_3\}$ where

$\phi_1=\forall a. a \le a$,

$\phi_2=\forall a \forall b. a \le b \wedge b \le a \objectImplies a=b$,

$\phi_3=\forall a \forall b. a \le b \wedge b \le c \objectImplies a \le c$.

$A$ is an axiomatization of the theory $T$. Note $\forall \phi \in A. P_8(\phi)$ as every axiom of $A$ consists of less than $8$ distinct characters. Therefore $P_8$ is a sufficiently weak bias of the language $L$ with respect to the theory $T$. However there does not exist an axiomatization of the theory $T$ where every axiom consists of at most $3$ distinct characters, therefore $P_3$ is a too strong bias with respect to the theory $T$. The set of the biases is ordered by their strength:
$P_0 \subseteq P_1 \subseteq P_2 \subseteq P_3 \subseteq ... \subseteq P_8 \subseteq ...$. Thus $P_3$ is stronger than $P_8$.
\end{exmp}

\begin{remark}
Let $L$ be the language, $\mathcal{P}$ be the set of all the biases on $L$. Then $\mathcal{P}$ is a lattice ordered by the subset inclusion $\subseteq$ with its join operator the set union $\union$ and its meet operator the set intersection $\cap$.
\end{remark}

\subsection{Language bias benefits}
\begin{itemize}
\item Biases reduce the hypotheses space to focus on the relevant hypotheses,
\item the problem of finding the hypothesis $H$ can be solved by applying successively a stronger and stronger bias.
\end{itemize}
We want our hypothesis to have a specific syntactic form:
\begin{itemize}
\item If a hypothesis is a clause with a head $h$ we learn sufficient conditions for $h$ to be implied,
\item by specifying conditions in a body of a clause of a hypothesis we learn what concepts can be implied,
\item restricting a head $h$ of an implication $b \objectImplies h$ not to be a disjunction but only a conjuction, we avoid learning the rules implying uncertain facts.
\end{itemize}

\subsection{Language bias problems}
Consider the hypotheses space $\mathcal{H} \subseteq \powerset{L}$. An ILP problem is to find the axiomatization $A \in \mathcal{H}$ of $O$ given $B$ of the maximal score $s(A,B,O)$ where $O$ is a set of the observations, $B$ is the background knowledge.
A simple brute force algorithm may go over all $H \in \mathcal{H}$ and check if $H=A$. This poses problems:
1. $\mathcal{H}$ may not be finite,
2. determining if $H=A$ may not be decidable.
In order to disect the problem more closesly the score function will need to be given a more specific form.

\subsection{Language bias in ILP}
Different biases may be applied to each of the languages $L, L_o, L_h$. 

\subsection{Syntactic biases}

\begin{defn}
A bias $P$ on $L$ is syntactic iff there exists a computable function $f:L \to \{0,1\}$ such that $\forall x \in L.P(x) \iff f(x)=1$.
\end{defn}

\begin{remark}
A syntactic bias is computable from the language $L$ alone, no other information available on its input.
\end{remark}

\begin{defn}
$P$ is a \emph{size bound bias} iff there exist numbers $min, max \in \mathbb{Z}$ such that $\forall \phi \in L. P(\phi) \iff min \le size(\phi) \le max$ where $size(\phi)$ is a length of a word $\phi \in L$.
\end{defn}

\begin{remark}
ILP systems with a score function involving a minimum compression length have size bound bias since they do not consider hypotheses of size greater than $\#B \union O$.
\end{remark}

\begin{remark}
Similarly, with a syntactic bias we could bound the number of the clauses in their conjunction $\phi \in L$ if necessary.
\end{remark}

\begin{defn}
A formula $\phi$ is $k$-adic iff its all predicate symbols (including an equals sign) and function symbols translated to predicate symbols are of the arity at most $k$. A formula $\phi$ is monadic iff $\phi$ is $1$-adic. A set or a theory is $k$-adic iff all its formulas are $k$-adic. The property of a formula $\phi$ being $k-adic$ is computable from $\phi$ and therefore it is a \emph{$k-adic$ bias}.
\end{defn}

\begin{defn}
A formula $\phi$ is a Horn formula iff $\phi$ is a clause with at most one positive literal. The property of a formula $\phi$ being a Horn formula is computable from $\phi$ and therefore it is a \emph{Horn bias}.
\end{defn}

\begin{defn}
A formula $\phi$ is a definite clause iff $\phi$ is a clause with exactly one positive literal. The property of a formula $\phi$ being a definite clause is computable from $\phi$ and therefore it is a \emph{definite clause bias}.
\end{defn}

The following definitions, an example and a remark of a mode declaration are due to Muggleton, Inverse Entailment and Progol\cite{muggleton1995}.
\begin{defn}\cite{muggleton1995}
A \emph{mode declaration} has either the form
$modeh(n,atom)$ or $modeb(n,atom)$ where $n$, the recall, is either an integer, $n > 1$,
or `*' and atom is a ground atom. Terms in the atom are either normal or placemarker. A normal term is either a constant or a function symbol followed by a
bracketed tuple of terms. A place-marker is either $+type$, $-type$ or $\#type$, where
type is a constant. If $m$ is a mode declaration then $a(m)$ denotes the atom of $m$
with place-markers replaced by distinct variables. The sign of $m$ is positive if $m$ is a modeh and negative if $m$ is a modeb.
\end{defn}

\begin{exmp}
\cite{muggleton1995}
\begin{lstlisting}
modeh(1,plus(+int,+int,-int))
modeb(*,append(-list,+list,+list)
modeb(1,append(+list,[+any],-list))
modeb(4,(+int > \#int))
\end{lstlisting}
\end{exmp}

\begin{remark}
\cite{muggleton1995}
The recall is used to bound the number of alternative solutions for instantiating
the atom. For simplicity, we assume in the following that all the modes have the
recall `*', meaning all solutions. The following defines when a clause is within
Progol's definite mode language $L$.
\end{remark}

\begin{defn}
\cite{muggleton1995}
\emph{Definite mode language}. Let $C$ be a definite clause with a
defined total ordering over the literals and $M$ be a set of mode declarations. $C = b_1, ..., b_n \objectImplies h$ is in the definite mode language $L_{mode}$ (a \emph{mode declaration bias}) if and only if
1) h is the atom
of a modeh declaration in $M$ with every place-marker $+type$ and $-type$ replaced by
variables and every place-marker $\#type$ replaced by a ground term and 2) every
atom $b_i$ in the body of $C$ is the atom of a modeb declaration in $M$ with every
place-marker $+type$ and $-type$ replaced by variables and every place-marker $\#type$
replaced by a ground term and 3) every variable of $+type$ in any atom $b_i$ is either
of $+type$ in $h$ or of $-type$ in some atom $b_1, ..., b_{i-1}$.
\end{defn}

\begin{remark}
A mode declaration bias is syntactic since there exists a computable function $g:L \times \mathfrak{M} \to \{0, 1\}$ (e.g. implemented in Progol\cite{muggleton1995}) such that given a mode declaration $M$, then
$\forall \phi \in L. g(\phi, M)=1 \iff \phi \in L_{mode}$.
\end{remark}

\subsubsection{Syntactic biases list}
\begin{itemize}
\item Size bound bias.
\item $k$-adic bias.
\item Horn bias.
\item Definite clause bias.
\item Mode declaration bias.
\end{itemize}

\subsection{Semantic biases}

\begin{defn}
A bias $P$ is semantic iff $\forall \phi, \psi \in L. \phi \equiv \psi \implies (P(\phi) \iff P(\psi))$, i.e. $P$ is independent of a syntax of a formula $\phi \in L$.
\end{defn}

\subsubsection{Toplog top theory bias\cite{muggleton2008}}
A top theory $\top$ is an extension of the background knowledge $B$. One could convert any ILP system to a TDHD(top-directed hypothesis derivation) ILP system by providing the input background knowledge $B \union \top$ instead of $B$ with the assumptions that the input satisfies the conditions of a quadruple $\langle NT, \top, B, E \rangle$ stated later.

A top theory bias is a mixture of a syntactic bias - e.g. $\top$ has to consist of Horn clauses and semantic bias which is of our interest.
\begin{defn}
A predicate symbol is \emph{non-terminal} iff TODO
\end{defn}

\begin{defn}
A predicate symbol is a \emph{target} iff TODO
\end{defn}

The input to an TDHD system is the quadruple $\langle NT, \top, B, E \rangle$ where $NT$ is a set of non-terminal  predicate symbols. Therefore a top theory $\top$ is not constructed from the input but already is a part of an input. $\top$ satisflies the conditions:
1. $\top$ consists of Horn clauses,
2. each clause in $\top$
must contain at least one occurrence of an element of $NT$ while clauses in $B$
and $E$ must not contain any occurrences of elements of $NT$,
3. any predicate appearing in the head of some clause in $\top$ must not occur in th	e body of any clause in $B$,
4. the head of the first clause in $\top$ is the target predicate and
the head predicates for other clauses in must be in $NT$.

\subsubsection{Construction of a top theory from the mode declarations\cite{muggleton2008}}
TODO - explain a construction of a top theory from an arbitrary set of mode declarations.
A top theory bias is more expressive than a mode declaration bias.
In a simplified way, given the mode declarations

$modeh(mammal(+animal)).$

$modeb(has milk(+animal)).$

$modeb(has eggs(+animal)).$

a top theory can be constructed to be $\top=\{\top_1, \top_2, \top_3, \top_4\}$:

$\top_1=mammal(X) \leftObjectImplies \$body(X).$

$\top_2=body(X) \leftObjectImplies .\%emptybody$

$\top_3=\$body(X) \leftObjectImplies has\_milk(X), \$body(X).$

$\top_4=\$body(X) \leftObjectImplies has\_eggs(X), \$body(X).$

The actual construction of a $\top$ theory has stricter control rules like: variables may only bind with others of the same type, a newly added literal must have its input variables already bound.

Both top theory bias and a mode declaration bias are specified at the input to an ILP system, for some input specifications as one above the biases are equal. Therefore one should distinguish further between a bias and a bias specification.

One could argue that a specification of a bias consists of an algorithm $A$ and an input $i$ where $A$ computes a bias $P$ from the given input $i$. As the input $i$ independent of an ILP system input $\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle$ may vary, an algorithm $A$ may compute (specify) multiple possible biases $P$. This can be seen from the ability to specify a mode declaration independent of the input
$\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle$.

\begin{exmp}
For the following sentence can be entailed by a top theory but there does not exist a mode declaration biased space that includes it:
TODO
\end{exmp}

\begin{itemize}
\item Bottom theory bias. An ILP system constructs a most specific hypothesis $\bot$ according to the bias criteria, then every possible hypothesis $H$ must entail $\bot$: $H \models \bot$.
\item Bottom theory subsumption bias. Every hypothesis must subsume the bottom theory.
\item Top theory subsumption bias. Every hypothesis must be subsumed by the top theory.
\item Solo-generalization bias. The hypotheses space $\mathcal{H}$ is restricted to the generalization of a single example. \cite{muggleton2012}
TODO: provide a formula of the restriction.
\item Solo-explanation bias. Every clause $h$ in a hypothesis $H$ has to explain at least \emph{one} example.
$\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$
\item Inverse entailment bias.
$B \union H \models E \iff B \union \neg H \models \neg E$.
\item Negation on failure bias. The lack of an observation $example(x)$
causes an illusion that $\neg example(x)$ is true as $example(x)$ not provable.

\subsubsection{Heuristic biases}
\begin{defn}
A boolean property $P$ is a heuristic bias iff $P$ is computable from $\mathcal{H}, B, O$.
\end{defn}
\item Score function bias. Having two correct hypotheses $H_1$, $H_2$ such that $B \union H_1 \models E$ and $B \union H_2 \models E$ choose the hypothesis with the greater score by the (computable) function $s:\mathcal{H} \to \mathbb{R}$.
\item Search algorithm bias. A search algorithm uses heauristics to navigate via the search space $\mathcal{H}$ in addition to the score function applied after the algorithmic hypotheses generation.
\end{itemize}

\section{Biases in ILP systems}

\iffalse
\subsection{Progol}
\begin{itemize}
\item Inverse Entailment,
\item a bias provided by mode declaration,
\end{itemize}
\fi

\subsection{Toplog\cite{muggleton2008}}
\begin{defn}
$B$ a Horn theory, $E$ a Horn clause. The bottom clause of $B$ and $E$ is $\bot(B,E)$=$\vee\{L | L $ a ground literal, $B \union {\neg E} \models \neg L\}$.
\end{defn}
An ILP system implementation Toplog is based on the theoretical framework Top Directed Hypothesis Derivation (TDHD) with the hypothesis space bias called top theory $\top$:
\begin{itemize}
\item Horn theory bias,
\item Bottom theory bias $\bot = \bot(B,E)$,
\item Solo-generalization bias,
\item Score function bias,
\item top theory $\top$ is specified in the input to an ILP system,
\item top theory $\top$ can be constructed from the mode declarations,
\item not every top theory bias can be expressed with the mode declarations,
\item a top theory consists of literals: terminals (in hypothesis language) and non-terminals (not allowed in hypothesis language and background knowledge)
\item a hypothesis clause in a hypothesis space consists of terminals and is derivable from the top theory by SLD-resolution and substitution, $\top \models h$
\item restriction on the predicates in the head/body of a hypothesis clause,
\item every constructed hypothesis must be subsumed by a top theory $\top$. If $H$ is a set of candidate hypotheses, then: $\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$.
\item inverse entailment bias.
\end{itemize}
Toplog violates the properties in our first definition of an ILP system:
\begin{itemize}
\item a produced theory may not be complete due to too strong default bias:
\begin{itemize}
\item only what is defined by mode declarations can be in theory,
\item theory can contain only one clause,
\item only one head clause definable with mode declarations unlike two clauses
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeh(man(+person)).
\end{lstlisting}

\item restrictions on the top theory related to $NT$ (non-terminals), $B$, $E$; what literals can occur where. Details in TopLog: ILP Using a Logic Program Declarative Bias by Muggleton etal.
\end{itemize}
\item a produced theory need not be consistent with the observations: given observations $human(susan)$ and $human(jack)$ a final theory can contain the hypothesis $woman(X) :- human(X)$. The accuracy of a theory is computed, a score function allows a degree of inaccuracy.
\end{itemize}

\iffalse
\subsection{ProGolem}
\begin{itemize}
\item Inverse Entailment,
\item co-generalization, 
\end{itemize}
\fi

\subsection{Imparo\cite{kimber2009}}
Bias:
\begin{itemize}
\item Horn theory bias (not present in a IoF framework),
\item Bottom theory bias, $\bot=$ a connected theory for $B$ and $e$,
\item Solo-generalization bias,
\item Score-function bias,
\item Mode declaration bias,
\item a bias specifiable in an input program:
\begin{lstlisting}
%a restriction on the length of a clause in a theory
:-set_max_clause_length(N1).
%a restriction on the number of clauses in a theory
:-set_max_clauses(N2).
%TODO - explain further two
:-set_connected(N3).
:-set_max_var_depth(N41).
\end{lstlisting}
\end{itemize}
TODO: an algorithm for a connected theory generation.

\subsection{Metagol}
TODO

%Bias:
%Algorithm:
%Violations:

\subsection{Comparison of biases in ILP systems}
$\mathcal{H}_{Toplog} \subseteq \mathcal{H}_{Imparo}$

$\mathcal{H}_{bottom\_clause} \subseteq \mathcal{H}_{kernel_set} \subseteq \mathcal{H}_{connected_theory}$

\chapter{Top-down framework}

\section{Toplog}
\subsection{Mode declarations order bias}
Consider the Toplog program:
\begin{lstlisting}
:-modeh(r(+type)).
:-modeb(1, p1(+type)).
:-modeb(1, p2(+type)).

:-set(maximum_literals_in_hypothesis, 10).

p1(a1).
p1(a2).
p1(a3).

p2(a1).
p2(a2).
p2(a3).

example(r(a1),1).
example(r(a2),1).
example(r(a3),1).
\end{lstlisting}

Then Toplog learns a hypothesis $r(A) :- p1(A).$ however if we change the mode declaration to the following:
\begin{lstlisting}
:-modeh(r(+type)).
:-modeb(1, p2(+type)).
:-modeb(1, p1(+type)).
\end{lstlisting}
then Toplog learns a hypothesis $r(A) :- p2(A).$ instead. This experiment therefore shows that Toplog's bias depends on the order of the mode declaration statements.

\subsection{Learning inconsistent hypothesis}
Toplog can learn inconsistent hypotheses:

\begin{lstlisting}
:-modeh(woman(+person)).
:-modeb(1, student(+person)).

student(ann).
student(tom).

example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}

gives an output hypothesis $woman(A) :- student(A)$ although $tom$ is not a woman as indicated by a negative example $example(woman(tom),-1)$.
But this is intentional, furthermore Toplog provides the information that the default accuracy of its hypothesis is 90\% as $example(woman(ann,9)$ corresponds to 9 positive examples correctly classified out of 10.

\subsection{One head predicate bias}
All the clauses in the hypotheses space of Toplog have to have the same predicate symbol in its head.

\begin{lstlisting}
:-modeh(woman(+person)).
:-modeb(1, female(+person)).
:-modeb(1, male(+person)).

male(tom).
female(ann).

example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}
produces a hypothesis $woman(A) :- female(A)$ but adding a second
head mode declaration $:-modeh(man(+person)).$ after $:-modeh(woman(+person)).$ overwrites the first one.

\begin{lstlisting}
:-modeh(woman(+person)).
:-modeh(man(+person)).
:-modeb(1, female(+person)).
:-modeb(1, male(+person)).

male(tom).
female(ann).

example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}
produces no hypotheses.

\subsection{Unlearnability of the term structure}
Consider one would like to learn a concept of a Kleene star operator on the terms evident from the following examples:
\begin{lstlisting}
%target concept: in_language(s(A)) :- in_language(A).
:-modeh(in_language(s(+word))).
:-modeb(1, in_language(+word)).

example(in_language(s(epsilon)),1).
example(in_language(s(s(epsilon))),1).
example(in_language(s(s(s(epsilon)))),1).
example(in_language(s(s(s(s(epsilon))))),1).
\end{lstlisting}

However, this is not learnable since Toplog's mode declarations do not allow to specify $in_language(s(A))$ in a head neither in a body. Toplog outputs:
"Couldn't start model. (no problem defined?)".

\subsection{Clausal bias}
Since Toplog's hypotheses space consists of clauses, it cannot learn two concepts at one time.

\begin{lstlisting}
:-modeh(object(+type)).
:-modeb(10, blue(+type)).
:-modeb(10, green(+type)).

:-set(maximum_literals_in_hypothesis, 10).

blue(ball).
blue(pen).
blue(bag).
green(shirt).
green(grass).
green(tree).

example(object(ball),1).
example(object(pen),1).
example(object(bag),1).
example(object(shirt),1).
example(object(grass),1).
example(object(tree),1).
\end{lstlisting}

will produce a hypothesis $object(A) :- blue(A)$ since 
$:-modeb(10, blue(+type)).$ was defined first instead of learning both
concepts in a hypothesis:
$object(A) :- blue(A); green(A)$ where the $;$ represents a disjunction.

\subsection{Inability to make deductions from observations}
Toplog does not learn any hypothesis from the following program:

\begin{lstlisting}
:-modeh(t(+type)).
:-modeb(1, p(+type)).

:-set(maximum_literals_in_hypothesis, 10).

p(a1).
p(a2).
p(a3).

t(A) :- r(A).

example(r(a1),1).
example(r(a2),1).
example(r(a3),1).
\end{lstlisting}
Although from the positive examples and the background knowledge included one may deduce examples:
\begin{lstlisting}
example(t(a1),1).
example(t(a2),1).
example(t(a3),1).
\end{lstlisting}
which if included in the Toplog program, then a hypothesis
$t(A) :- p(A)$ would be learnt.
Therefore the application of the background knowledge to the observations in Toplog is limited.

Nevertheless, Toplog can still learn by making deductions from its background knowledge.

\begin{lstlisting}
:-modeh(t(+type)).
:-modeb(1, r(+type)).

:-set(maximum_literals_in_hypothesis, 10).

p(a1).
p(a2).
p(a3).

r(A) :- p(A).

example(t(a1),1).
example(t(a2),1).
example(t(a3),1).
\end{lstlisting}
would give a hypothesis $t(A) :- r(A).$

\subsection{Predicate generalization impossible}
Toplog cannot generalize over the predicates as this cannot be expressed in the mode declarations bias, consider the illustrative example.
\begin{lstlisting}
example(swims(magician),1).
example(flies(magician),1).
example(cooks(magician),1).
example(makes_fire(magician),1).
\end{lstlisting}
The hypothesis $\forall x. x(magician)$ cannot be induced. Depending on our language and the predicates it contains and the context of the problem, we may need to express hypotheses as second-order logic formulas.

\subsection{Ground atom example}
Toplog has a limitation that every example can be only a ground atom.

\section{MC-Toplog}


\chapter{Bottom-up framework}

\section{Imparo's capabilities}
\subsection{A multiclausal learning}
Imparo is capable to learn a multi-clausal hypothesis at one time.

\begin{lstlisting}
head_modes([
   woman(+person),
   man(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).

person(jane).
person(susan).
person(jack).
person(sam).

% Gender, Background knowledge
female(jane).
female(susan).

male(jack).
male(sam).

% Gender, Examples
woman(jane).
woman(susan).
man(jack).
man(sam).

:- woman(jack).
:- man(susan).
\end{lstlisting}
produces a hypothesis
\begin{lstlisting}
woman(A):-female(A)
man(A):-male(A)
\end{lstlisting}

Learning multiple hypotheses is not possible in all systems, e.g. Toplog. Nevertheless the clauses have to be Horn, the ones with at most one positive literal and therefore hypotheses of the form $s \vee p \leftObjectImplies r$ cannot be learnt.

\subsection{Learnability of a nested term structure}
Imparo is capable of learning a language constructed from the alphabetical symbols and a Kleene star operation. Observations below correspond to the language defined by the regular expression \tc{(sr)*}.

\begin{lstlisting}
head_modes([
   in_language(+word),
   in_language(s(+word)),  
   in_language(s(s(+word))),
   in_language(r(s(+word))),
   in_language(s(r(+word))),
   in_language(r(+word)),
   in_language(r(r(+word)))
]).

body_modes([
    in_language(+word),
    in_language(s(+word)),
    in_language(r(+word))
]).

word(e).
word(s(X)).
word(r(X)).

%Examples

in_language(e).
in_language(r(s(e))).
in_language(r(s(r(s(e))))).
in_language(r(s(r(s(r(s(e))))))).

:- in_language(r(e)).
:- in_language(r(r(e))).
:- in_language(s(s(r(e)))).
:- in_language(s(s(s(e)))).
\end{lstlisting}
returns a hypothesis
\begin{lstlisting}
in_language(e):-true
in_language(r(s(A))):-true
\end{lstlisting}

Note, this was not possible in Toplog.

\subsection{Learnability of multi-clausal concepts}
Imparo can explain observations for which there does not exist a one-clausal explanation by inducing a multi-clausal hypothesis.
\begin{lstlisting}
head_modes([
   man(+person),
   woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).

person(jane).
person(susan).
person(eugenia).
person(jack).
person(sam).
person(martin).

% Gender, Background knowledge
female(jane).
female(susan).
female(eugenia).

couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).

male(X) :- couple(X,Y), woman(Y).

% Gender, Examples
man(jack).
man(martin).

woman(jane).
woman(susan).

:-man(jane).
:-woman(sam).
\end{lstlisting}

produces the hypothesis
\begin{lstlisting}
man(A):-male(A)
woman(A):-female(A)
\end{lstlisting}.

To learn the hypothesis \tc{man(A):-male(A)} from the background knowledge and the observations we have to use the predicate \tc{male(X) :- couple(X,Y), woman(Y).}, but this requires the knowledge of who is a woman, which can be only acquired by inducing a second hypothesis \tc{woman(A):-female(A)}. Therefore, the concept learnt by Imparo requires at least two clauses.

\section{Imparo's assumed limitations}
Observations demonstrating the limits of the concept learnability from the system design assuptions are presented.

\subsection{Unlearnability of negative examples}
Note: Imparo uses a completion semantics.
In cases when a hypothesis could explain the negative examples, Imparo cannot learn such a clause.

\begin{lstlisting}
head_modes([
   woman(+person)
]).

body_modes([
    woman(+person),
    female(+person),
    male(+person)
]).

person(jane).
person(susan).
person(jack).
person(sam).

% Gender, Background knowledge

female(jane).
female(susan).

male(jack).
male(sam).

% Gender, Examples

:- woman(jack).
:- woman(sam).
\end{lstlisting}

The hypothesis of the form $\neg male(x) \vee \neg woman(x)$ would explain the examples, however Imparo in this case outputs no hypothesis.

Adding further information to the background knowledge does not remove the limits:

\begin{lstlisting}
not_man(X) :- woman(X).
not_woman(X) :- man(X).
:- woman(X), man(X).
:- not_woman(X), not_man(X).
\end{lstlisting}
The background knowledge says that everybody has to be either a woman or a man. From our observations negative examples are not learnable by Imparo, however a hypothesis produced is consistent with the all the examples and the background knowledge.

This may be related to the existence of a definition of an ILP system where the produced hypothesis $H$ has to explain positive examples, but it is sufficient if negative examples are only consistent with the hypothesis, notationally the necessity condition says:
$H, B \models E^+$ and $H, B \not \models E^-$.

Favouring this definition results in a bias in which hypotheses space is biased towards positive examples.

\subsection{Assumption of consistency}
Imparo assumes that the set of observations is consistent.

\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   male(+person)
]).

person(jack).
person(sam).
person(john).
person(glory).

%Background knowledge
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).

%Examples
:- man(glory).

man(glory).
\end{lstlisting}

produces a hypothesis
\begin{lstlisting}
man(glory):-true
\end{lstlisting}
although it is inconsistent with the observation
\begin{lstlisting}
:- man(glory).
\end{lstlisting}

Imparo still learns
\begin{lstlisting}
man(glory):- true
\end{lstlisting}
even if we move the negative observation
\begin{lstlisting}
:- man(glory).
\end{lstlisting}
to the background knowledge.

Systems like Progol check for inconsistencies before learning is started. However, in some definitions of an ILP problem, an assumption that the background knowledge is consistent with the observations is made.

\section{Imparo's violations and biases}
Limits of the learnability violating the system specification and not stated as assumptions are presented as observations.

\subsection{Default examples bias}
Imparo has examples in its default bias even if these are not declared in the mode declarations.

\begin{lstlisting}
head_modes([
   %woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).

person(jane).
person(susan).
person(jack).

% Gender, Background knowledge
female(jane).
female(susan).

male(jack).

% Gender, Examples
woman(jane).
woman(susan).

:- woman(jack).
\end{lstlisting}

produces a hypothesis 
\begin{lstlisting}
woman(jane):-true
woman(susan):-true
\end{lstlisting}

in which a predicate \tc{woman} is a head symbol although it was not specified in the mode declaration. Once it is specified in a declaration as
\begin{lstlisting}    
head_modes([
   woman(+person)
]).
\end{lstlisting}

a more general hypothesis is learnt

\begin{lstlisting}
woman(A):-female(A)
\end{lstlisting}.

This demonstrates that in some cases mode declaration bias does not correspond to the actual bias of Imparo.

\subsection{Weak head mode declaration}
A head mode declaration in Imparo allows only definitions with specific term structure as opposed to the ability to substitute a variable for any term.

\begin{lstlisting}
head_modes([
   woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).

person(jane).
person(susan).
person(eugenia).
person(jack).
person(sam).

% Gender, Background knowledge
female(jane).
female(susan).
female(eugenia).

% Gender, Examples
woman(sister(jane)).
woman(sister(eugenia)).
:- woman(jack).
\end{lstlisting}

produces a hypothesis 
\begin{lstlisting}
woman(sister(jane)):-true
woman(sister(eugenia)):-true
\end{lstlisting}.

If we would like generalize on the terms, we have to add them explicitly to the mode declaration, i.e.
\begin{lstlisting}
head_modes([
   woman(+person),
   woman(sister(+person))
]).
\end{lstlisting}
produces a more general hypothesis
\begin{lstlisting}
woman(sister(A)):-true
\end{lstlisting}

In this regard, Imparo treats function symbols as a syntactic sugar - a predicate with a function symbol is treated as a predicate symbol, one could simply replace \tc{woman(sister(x))} by \tc{woman\_sister(x)} in examples and mode declarations and add the following to the background knowledge:
\begin{lstlisting}
woman_sister(X) :- woman(sister(X)).
woman(sister(X)) :- woman_sister(X).
\end{lstlisting}
The advantage of a support of a term structure is a matter of convenience rather than an added expressivity of the problem description and produced hypotheses.

\subsection{No generalization downwards}
Imparo cannot learn the hypotheses of the form $P(s(x)) \objectImplies P(x)$ for all classes of applicable observations.

\begin{lstlisting}
head_modes([
   even(+number)
]).

body_modes([
    even(+number),
    even(s(+number)),
    even(s(s(+number)))
]).

number(0).
number(s(X)).

%Background knowledge
even(s(s(s(s(s(s(s(s(0))))))))).

%Examples
even(0).
even(s(s(0))).
even(s(s(s(s(0))))).
even(s(s(s(s(s(s(0))))))).
:-even(s(0)).
:-even(s(s(s(0)))).
\end{lstlisting}

only learn the examples

\begin{lstlisting}
even(0):-true
even(s(s(s(s(s(s(0))))))):-true
even(s(s(0))):-true
even(s(s(s(s(0))))):-true
\end{lstlisting}

where we may expect a more general shorter hypothesis

\begin{lstlisting}
even(A) :- even(s(s(A)).
\end{lstlisting}
This may be related to the mentioned limitation of how Imparo treats the terms. A translated instance of \tc{even(s(s(s(s(0)))))} would be
\tc{even\_s\_s\_s\_s\_s\_s(0)}, but in fact we want \tc{even\_s\_s(s(s(s(s(0))))} in order to be able to learn
\tc{even(A) :- even\_s\_s(A)}.

However, the generalization downwards does not work with a hypothesis having an argument with one function symbol in its body either.

\begin{lstlisting}
head_modes([
   numeral(+number)
]).

body_modes([
    numeral(+number),
    numberal(s(+number)),
    numeral(s(s(+number)))
]).
number(0).
number(s(X)).

%Background knowledge
numeral(s(s(s(s(0))))).

%Examples
numeral(0).
numeral(s(0)).
numeral(s(s(0))).
numeral(s(s(s(0)))).
:-numeral(s(not_number)).
:-numeral(s(s(s(not_number)))).                                   
\end{lstlisting}

returns a hypothesis

\begin{lstlisting}
numeral(0):-true
numeral(s(s(s(0)))):-true
numeral(s(0)):-true
numeral(s(s(0))):-true
\end{lstlisting}

however, a more general hypothesis \tc{numeral(A) :- numeral(s(A)).} would explain the examples.

\subsection{Literal observational bias}
Imparo can accept only the examples in the form of literals. If presented with other clauses in the example file, it will not run.

\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   male(+person)
]).

person(jack).
person(sam).
person(john).
person(glory).

%Background knowledge
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).

%Examples
man(jack) :- male(jack).
man(sam) :- male(sam).
man(john) :- male(john).

:- man(glory).
\end{lstlisting}

Expected hypothesis explaining the examples:

\begin{lstlisting}
man(X) :- male(X).
\end{lstlisting}

To the author's knowledge, other ILP systems do not deal with the case of non-literal observations, however the works by Plotkin dealt with the generalization of a general set of clauses.

\subsection{Preference over the later mode declarations}
The search bias of the Imparo prefers the predicates that have been defined by the mode declarations later.

\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   policeman(+person),
   male(+person)
]).

person(jack).
person(sam).
person(john).
person(jane).

%Background knowldge
male(jack).
male(sam).
male(john).
policeman(jack).
policeman(sam).
policeman(john).

%Examples
man(jack).
man(sam).

:- man(jane).
\end{lstlisting}
learns a hypothesis
\begin{lstlisting}
man(A):-male(A)
\end{lstlisting}
However, changing the body mode declaration to
\begin{lstlisting}
body_modes([   
   male(+person),
   policeman(+person)
]).
\end{lstlisting}
results in learning the hypothesis
\begin{lstlisting}
man(A):-policeman(A)
\end{lstlisting}

This search bias in Imparo has a priority over the criterion of favouring a stronger or a weaker hypothesis. By adding to the background knowledge
\begin{lstlisting}
policeman(X) :- male(X).
\end{lstlisting}
or its converse
\begin{lstlisting}
male(X) :- policeman(X).
\end{lstlisting}
the hypothesis learnt remains the same.
Note that \tc{male(X) :- policeman(X).} says that every model of \tc{policeman(X)} has to be a model of \tc{male(X)} and with such background knowledge \tc{man(A):-policeman(A)} is true in fewer models than \tc{man(A):-male(A)} is.

\subsection{Other biases}
Imparo can learn only a conjunction of clauses as a hypothesis.
Imparo cannot explain the negative observations.

\section{Aleph's capabilities}

\subsection{Multi-clausal learning}
Aleph can learn several one-clausal hypotheses at one time.

\begin{lstlisting}
%background theory
:-modeh(*, woman(+person)).
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).
:-modeb(*, female(+person)).

:- determination(man/1,male/1).
:- determination(woman/1,female/1).

male(bob).
male(tom).

female(ann).
female(mary).

%positive examples
woman(ann).
woman(mary).

man(bob).
man(tom).

%negative examples
man(ann).
man(mary).

woman(bob).
woman(tom).
\end{lstlisting}

returns hypotheses

\begin{lstlisting}
woman(A) :- female(A).
man(A) :- male(A).
\end{lstlisting}

Note, this is possible in Imparo, but not in Toplog.

\subsection{Learnability of predicates of greater arity}
Aleph can induce hypotheses that contain predicates of arity greater than 1.
\begin{lstlisting}
%background theory
:-modeh(*, english(+person)).
:-modeb(*, english_couple(+person, -person)).
:-modeb(*, english(+person)).

:- determination(english/1, english_couple/2).

english_couple(adam, alice).
english_couple(bob, barbara).
english_couple(jack, jane).

%positive examples
english(adam).
english(jack).

%negative examples
english(budha).
\end{lstlisting}

returns back a generalized hypothesis
\begin{lstlisting}
english(A) :- english_couple(A,B).
\end{lstlisting}.

Note, that since the induce hypothesis does not use the variable \tc{B}, the variable had to be specified in a mode declaration with a minus sign as \tc{-person}.

Similarly, learning of hypotheses with polyadic predicate symbols in their head is possible.

\begin{lstlisting}
%background theory
:-modeh(*, english_couple(+person, +person)).

:-modeb(*, english(+person)).

:- determination(english_couple/2, english/1).

english_couple(adam, alice).
english_couple(bob, barbara).
english(alice).
english(jane).
english(barbara).
english(adam).
english(bob).
english(jack).

%positive examples
english_couple(adam, alice).
english_couple(bob, barbara).
english_couple(jack, jane).

%negative examples
english_couple(budha, karma).
english_couple(jack, shreedipta).
english_couple(amir, jane).
\end{lstlisting}

returns a hypothesis

\begin{lstlisting}
english_couple(A,B) :- english(B), english(A).
\end{lstlisting} which has in its head a predicate of arity 2.

\subsection{Term structure learnability}
Aleph can learn the hypotheses whose terms contain function symbols.
\begin{lstlisting}
:-modeh(*, woman(sister(+person))).
:-modeb(*, anybody(+person)).

:-determination(woman/1, anybody/1).

anybody(jane).
anybody(susan).
anybody(bob).

%positive examples
woman(sister(bob)).
woman(sister(jane)).
woman(sister(susan)).

%negative examples
woman(sister(frog)).
\end{lstlisting}
returns a hypothesis
\begin{lstlisting}
woman(sister(A)) :- anybody(A).
\end{lstlisting}
In comparison, Imparo can learn the term structure but Toplog cannot.

\subsection{Generalization downwards}
Aleph can learn the hypotheses of the form $P(s(x)) \objectImplies P(x)$.

\begin{lstlisting}
%background theory
:-modeh(*, even(+number)).
:-modeb(*, even(+number)).
:-modeb(*, even(s(+number))).
:-modeb(*, even(s(s(+number)))).

:- determination(even/1, even/1).

even(s(s(s(s(s(s(s(s(0))))))))).

%positive examples
even(0).
even(s(s(0))).
even(s(s(s(s(0))))).
even(s(s(s(s(s(s(0))))))).

%negative examples
even(s(0)).
even(s(s(s(0)))).
\end{lstlisting}
produces a hypothesis
\begin{lstlisting}
even(A) :- even(s(s(A))).
\end{lstlisting}
which comes as a surprise since neither Imparo nor Toplog can learn the hypotheses whose variable in head is wrapped by function symbols in its body literals.

\section{Aleph's assumed limitations}
\subsection{Unlearnability of negative examples}
Aleph learns positive examples, but cannot learn the negative ones.
\begin{lstlisting}
%background theory

:-modeb(*, woman(+person)).

%positive examples

%negative examples
woman(bob).
woman(tom).
\end{lstlisting}
does not return any hypothesis, even if we specify the hypothesis in the mode declaration by \tc{:- woman(+person)}.

\subsection{Determination declaration requirement}
The hypotheses space cannot be defined with the mode declarations alone, mode declarations have to be supplied with the determination declarations.
\begin{lstlisting}
%background theory

:-modeh(*, woman(+person)).
:-modeb(*, female(+person)).

%:- determination(woman/1,female/1).

female(ann).
female(mary).

%positive examples
woman(ann).
woman(mary).

%negative examples
woman(bob).
\end{lstlisting}

does not return a generalized hypothesis but the examples
\begin{lstlisting}
woman(ann).
woman(mary).
\end{lstlisting}.
After including the determination declaration
\begin{lstlisting}
:- determination(woman/1,female/1).
\end{lstlisting}
a more general hypothesis \tc{woman(A) :- female(A).} is learnt. To the author it is not clear why the hypothesis space has to be defined with two definitions. Systems like Imparo do not need determinations declarations.

\subsection{Assumption of consistency}
Aleph assumes the examples are consistent.
\begin{lstlisting}
%background theory

%positive examples
woman(ann).

%negative examples
woman(ann).
\end{lstlisting}
returns a hypothesis \tc{woman(ann).} which is inconsistent with the negative examples. Aleph assumes that the set of background knowledge union with examples is a consistent.

\subsection{Unlearnability of regular languages}
Although Aleph can learn a simple term structure, it cannot learn more complex concepts like a regular language represented by regular expression \tc{(ss)*}.

\begin{lstlisting}
%background theory
:-modeh(*, in_language(s(s(+word)))).
:-modeh(*, in_language(s(+word))).
:-modeb(*, in_language(+word)).

:- determination(in_language/1, in_language/1).

in_language(epsilon).
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).

%positive examples
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).

%negative examples
in_language(s(epsilon)).
in_language(s(s(s(epsilon)))).
\end{lstlisting}
returns back positive examples
\begin{lstlisting}
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).
\end{lstlisting}
A more general hypothesis representing the language is
\begin{lstlisting}
in_language(s(s(A)) :- in_language(A).
\end{lstlisting}
If our target hypothesis had only one function symbol in its predicate and its correspondent examples, then a simpler hypothesis
\begin{lstlisting}
in_language(s(A)) :- in_language(A).
\end{lstlisting}
could indeed be learnt.

\subsection{Unlearnability of multi-clausal concepts}
Aleph cannot learn a hypothesis that needs more that one clause to explain the examples.

\begin{lstlisting}
%background theory
:-modeh(*, woman(+person)).
:-modeh(*, man(+person)).

:-modeb(*, male(+person)).
:-modeb(*, female(+person)).

:- determination(woman/1, female/1).
:- determination(man/1, male/1).

female(jane).
female(susan).
female(eugenia).

couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).

male(X) :- couple(X,Y), woman(Y).

%positive examples
man(jack).
man(martin).

woman(jane).
woman(susan).

%negative examples
man(jane).
woman(sam).
\end{lstlisting}

produces a hypothesis
\begin{lstlisting}
man(jack).
man(martin).
woman(A) :- female(A).
\end{lstlisting}

However, if we put the induced hypothesis to the background knowledge, then a hypothesis generalizing \tc{man} examples would be produced
\begin{lstlisting}
man(A) :- male(A).
woman(A) :- female(A).
\end{lstlisting}

To explain the \tc{man} examples we needed to learn a two clausal hypothesis. This limitation is present in Toplog, however not in Imparo. The limitation not only demonstrates inability to learn more complex concepts, but also to make deductions from the observations such as \tc{woman} examples in order to deduce a hypothesis.

\subsection{Other assumed limitations}
Any hypothesis learnt in Aleph has to be a Horn theory. Aleph cannot learn second-order logic statements. Aleph cannot make deductions from the observations as it can from the background knowledge.

\section{Aleph's violations and biases}

\subsection{Default Example Bias}
Aleph includes examples in its bias even if these are not specified by mode declarations.

\begin{lstlisting}
%background theory

%:-modeh(*, woman(+person)).
%:-modeb(*, female(+person)).

%positive examples

woman(ann).

%negative examples
\end{lstlisting}

returns a hypothesis
\begin{lstlisting}
woman(ann).
\end{lstlisting}

Therefore the hypotheses space is not entirely defined by mode declarations and determination declarations.

\subsection{Weak head mode declaration}
A head mode declaration in Aleph allows only definitions with specific term structure as opposed to
the ability to substitute a variable or a type (e.g. \tc{+person}) for any term.

\begin{lstlisting}
%background theory
:-modeh(*, woman(+person)).
:-modeb(*, anybody(+person)).

:- determination(woman/1, anybody/1).

person(sister(A)).

anybody(jane).
anybody(jack).

%positive examples
woman(sister(jane)).
woman(sister(jack)).

%negative examples
woman(sister(frog)).
\end{lstlisting}

returns back the positive examples
\begin{lstlisting}
woman(sister(jane)).
woman(sister(jack)).
\end{lstlisting}

However, if we added the \tc{sister} function symbol in the mode declaration explicitly
\begin{lstlisting}
:-modeh(*, woman(sister(+person))).
\end{lstlisting}
then a more general hypothesis
\begin{lstlisting}
woman(sister(A)) :- anybody(A).
\end{lstlisting}
would be learnt. This constraint is present in Imparo as well. To the author the reason is not clear since \tc{woman(sister(+person))} is subsumed by
\tc{woman(+person)} which was already present in the mode declaration. Therefore unless specified in the mode declarations, Aleph can learn only the hypothesis whose terms do not contain the function symbols.

\subsection{Literal observation bias}
Aleph can accept only the examples in the form of literals. If presented with other clauses in the example file, it will not run

\begin{lstlisting}
%background theory
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).

:- determination(man/1, male/1).

male(jack).
male(sam).
male(john).
male(tristan).
female(glory).

%positive examples
man(jack) :- male(jack).
man(sam) :- male(sam).
man(john) :- male(john).

%negative examples
man(glory).
\end{lstlisting}

Expected hypothesis explaining the examples:
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}
In comparison systems like Imparo and Toplog do not accept examples of non-literal form either.

\subsection{Preference over earlier determinations}
Aleph prefers learning a hypothesis whose determination declaration has been defined earlier.

\begin{lstlisting}
%background theory
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).
:-modeb(*, bridegroom(+person)).

:- determination(man/1, bridegroom/1).
:- determination(man/1, male/1).

bridegroom(jack).
bridegroom(sam).
bridegroom(john).

male(jack).
male(sam).
male(john).

%positive examples
man(jack).
man(sam).
man(john).

%negative examples
man(susan).
\end{lstlisting}

returns a hypothesis
\begin{lstlisting}
man(A) :- bridegroom(A).
\end{lstlisting}

Changing the order of the determination declarations to
\begin{lstlisting}
:- determination(man/1, male/1).
:- determination(man/1, bridegroom/1).
\end{lstlisting}
results in a hypothesis
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}
In both cases, the induced hypothesis had a head atom declared in an earlier determination. This is an opposite search bias to the Imparo's preference over the later mode declarations.

\section{Tal's capabilities}

\subsection{Multiple solutions}
A hypothesis that can solve the problem of induction may be called a solution. Tal can output multiple solutions to a given learning problem with the corresponding scores.

\begin{lstlisting}
modeh(woman(+person), [name(wh)]).modeb(female(+person), [name(fb)]).
modeb(male(+person), [name(mb)]).
person(ann).person(susan).person(adam).person(bob).
%Background knowledge, female(ann).female(susan).male(adam).male(bob).
%Examples, example(woman(alice), 1).example(woman(ann), 1).
example(woman(susan), 1).example(woman(adam), -1).example(woman(bob), -1).
\end{lstlisting}
returns solutions
\begin{lstlisting}
1. woman(A). %score 0, 2. woman(A) :- female(A). %score -1
\end{lstlisting}

\subsection{Multi-clausal hypothesis}
Tal can learn a hypothesis that consists of multiple clauses.

\begin{lstlisting}
%Background knowledge, female(ann).female(susan).male(adam).male(bob). 
%Examples, example(woman(ann), 1). example(woman(susan), 1).
example(woman(adam), -1). example(woman(bob), -1).
example(man(adam), 1). example(man(bob), 1).
example(man(ann), -1). example(man(susan), -1).
\end{lstlisting}

returns solutions
\begin{lstlisting}
1. woman(_). 2. woman(A) :- female(A). 3. woman(A) :- female(A). man(_).
4. woman(A) :- female(A). man(A) :- male(A).
5. man(A) :- male(A). woman(A) :- female(A).
\end{lstlisting}

Particularly, we observe that the 5th solution consists of two clauses.

\subsection{Term structure learnability}
Tal can learn the hypotheses whose terms contain function symbols.
\begin{lstlisting}
modeh(woman(sister(+person)), [name(wh)]).modeb(anybody(+person), [name(wb)]).
person(jane).person(bob).person(susan).
%Background knowledge, anybody(jane).anybody(susan).anybody(bob).
%Examples, example(woman(sister(bob)), 1).example(woman(sister(jane)), 1).
example(woman(sister(susan)), 1).example(woman(sister(frog)), -1).
\end{lstlisting}
returns solutions
\begin{lstlisting}
1. woman(sister(_)). 2. woman(sister(A)) :- anybody(A).
3. woman(sister(_)).woman(sister(A)) :- anybody(A).
4. woman(sister(A)) :- anybody(A). woman(sister(_)).
\end{lstlisting}

\subsection{Multi-clausal concepts}
Tal can learn a hypothesis that needs more that one clause to explain the examples.
\begin{lstlisting}
%Background knowledge, female(jane). female(susan). female(eugenia).
couple(jack, jane).couple(sam, susan).couple(martin, eugenia).
male(X) :- couple(X,Y), woman(Y).
%Examples, example(man(jack),1).example(man(martin),1).example(woman(jane),1).
example(woman(susan),1).example(man(jane),-1).example(woman(sam),-1).
\end{lstlisting}
has amongst its solutions
\begin{lstlisting}
woman(A) :- female(A). man(A) :- male(A).
\end{lstlisting}
To explain the man examples we needed to learn a two clausal hypothesis. In comparison, Toplog and Aleph cannot learn multi-clausal concepts, but Imparo can.

\subsection{Other capabilities}
Tal can impose the bias on the hypotheses space by user-specified integrity constraints. Tal has several hypothesis searching strategies specifying a score function on the criteria of heuristics, termination, solution score; and search algorithms, e.g. breadth first search. More information can be found in Tal's manual.

\section{Tal's assumed limitations}

\subsection{No example learning}
Tal can learn general hypotheses but it cannot learn their ground instances and ground consequences.
\begin{lstlisting}
modeh(woman(+person), [name(wh)]).modeb(female(+person), [name(fb)]).
%Background knowledge, female(alice).male(adam).male(bob).
%Examples
example(woman(alice), 1).example(woman(adam), -1).example(woman(bob), -1).
\end{lstlisting}
returns the solutions
\begin{lstlisting}
1. woman(_). 2. woman(A) :- female(A).
\end{lstlisting}
However, one would expect the hypothesis explaining positive examples to be the ground atom \tc{woman(alice).}. Consequently, Tal does not suffer from the default example bias present in the systems Toplog, Imparo and Aleph.

\subsection{Other assumed limitations}
Tal cannot learn the negative examples. It can learn only Horn theories. Tal assumes the consistency of the background knowlege, the consistency of the examples and the consistency of the background knowledge with the examples.

\section{Tal's violations and biases}

\subsection{Solution redundancy}
Tal returns duplicate hypotheses as solutions.
\begin{lstlisting}
modeh(woman(sister(+person)), [name(wh)]).modeb(anybody(+person), [name(wb)]).
person(jane).person(bob).person(susan).
%Background knowledge, anybody(jane).anybody(susan).anybody(bob).
%Examples, example(woman(sister(bob)), 1).example(woman(sister(jane)), 1).
example(woman(sister(susan)), 1).example(woman(sister(frog)), -1).
\end{lstlisting}
returns solutions
\begin{lstlisting}
1. woman(sister(_)). 2. woman(sister(A)) :- anybody(A).
3. woman(sister(_)).woman(sister(A)) :- anybody(A).
4. woman(sister(A)) :- anybody(A). woman(sister(_)).
\end{lstlisting}
Notice that the 3rd and the 4th solutions are equivalent, the only difference is the order of the hypotheses returned in the solution.  Moreover, \tc{woman(sister(\_))} subsumes the clause \tc{woman(sister(A)):-anybody(A).}. Hence the 3rd solution is equivalent to the 1st one.

\subsection{No generalization downwards}
Tal cannot learn the hypotheses of the form $P(s(x)) \metaImplies P (x)$.
\begin{lstlisting}
modeh(numeral(+number), [name(nh)]).modeb(numeral(+number), [name(nb)]).
modeb(numberal(s(+number)), [name(nsb)]).modeb(numeral(s(s(+number))), [name(nssb)]).
number(0).number(s(X)).
%Background knowledge, numeral(s(s(s(s(0))))).
%Examples, example(numeral(0),1). example(numeral(s(0)),1). 
example(numeral(s(s(0))),1).example(numeral(s(s(s(0)))),1).
example(numeral(s(not_number)),-1).example(numeral(s(s(s(not_number)))),-1).
\end{lstlisting}

returns solutions
\begin{lstlisting}
1. numeral(_). 2. numeral(A) :- numeral(s(s(A))). 3. numeral(A) :- numeral(A).
\end{lstlisting}
and then starts outputting a solution of the form
\begin{lstlisting}
[(numeral(s(s(s(s(s(s(s(s(...
\end{lstlisting}
getting into a loop outputting the successor symbols $s$. Clearly, our expected hypothesis \tc{numberal(X) :- numberal(s(X)).} was not learnt.

In cases of different downwards examples, Tal may not loop, however it would not produce the expected generalization either.

\begin{lstlisting}
modeh(even(+number), [name(eh)]).modeb(even(+number), [name(eb)]).
modeb(even(s(+number)), [name(esb)]).modeb(even(s(s(+number))), [name(essb)]).
number(N).
%Background knowledge, even(s(s(s(s(s(s(s(s(0))))))))).
%Examples,example(even(0),1).example(even(s(s(0))),1).
example(even(s(s(s(s(0))))),1).example(even(s(s(s(s(s(s(0))))))),1).
example(even(s(0)),-1).example(even(s(s(s(0)))),-1).
\end{lstlisting}
produces a hypothesis \tc{even(\_).} which is inconsistent with the negative examples. The target hypotheses \tc{even(A) :- even(s(s(A))).} was not learnt.

\subsection{Loop on learning regular languages}
Just as the generalization downwards example caused Tal looping, generalization forward, i.e. learning a hypothesis of the form $P(x) \objectImplies P(s(s(x))$ (a regular language \tc{(ss)*}) can cause Tal looping.
\begin{lstlisting}
modeh(in_language(s(s(+word))), [name(issh)]).modeh(in_language(s(+word)), [name(ish)]).
modeb(in_language(+word), [name(ib)]).
word(X).
in_language(epsilon).in_language(s(s(epsilon))).in_language(s(s(s(s(epsilon))))).
%Examples
example(in_language(s(s(epsilon))),1).example(in_language(s(s(s(s(epsilon))))),1).
example(in_language(s(epsilon)),-1).example(in_language(s(s(s(epsilon)))),-1).
\end{lstlisting}
returns solutions
\begin{lstlisting}
1. in_language(s(_)). in_language(s(s(A))) :- in_language(A).
2. in_language(s(A)) :- in_language(A).
\end{lstlisting}
and subsequently loops outputting \tc{[(in\_language(s(s(s(s...} as before.
Notice that a target hypothesis 2. was learnt, but Tal did not manage to terminate. One can imagine a situation in which a correct hypothesis would be learnt after the infinite loop completes which is impossible.

\chapter{MIL framework}

\chapter{Comparisons of ILP systems}

\chapter{Learning hypotheses of the least Kolmogorov complexity}

Given a set of observations $O$, the background knowledge $B$, if the theory $O \union B$ is not complete, i.e. there is more than one model of $O \union B$ up to isomorphism, then there are several hypotheses $H \in \mathcal{H}$ that can explain the observations from the background knowledge, i.e. $B \union H \models O$, and are consistent with the background knowledge, i.e. $B \union H \not\models false$.

What quantifiable properties hypothesis should have can be captured by a score function. Arguing which score function is more desirable is a problem in its own right. We explore the possibility of a score function to be Kolmogorov complexity measure. We would like to find out what ILP systems induce their hypotheses of the least Kolmogorov complexity. The problem proves to be difficult as due to complex grammatical structure of the first order sentences of a logic program. We therefore provide an abstraction where a sentence is represented by an element of a set in hope that understanding the problem in its relaxed version will shed more light into its original version.

\subsection{Problem of induction - computability setting}

\begin{defn}
The Kolmogorov complexity $K(S)$ of a set $S$ is the Kolmogorov complexity
of a formula $\psi$ with the least Kolmogorov complexity that defines $S$.
\end{defn}

Given a set $P \subseteq \mathbb{N}$ of positive examples,
a set $N \subseteq \mathbb{N}$ of negative examples,
find a computable set $S = \{n \in \mathbb{N} : \mathbb{N} \models \phi(n) \} \subseteq \mathbb{N}$ that has the least Kolmogorov complexity.

In a specialized version of the problem, the criterion of Kolmogorov complexity can be replaced by other property definable by a real-valued score function on a triple $\langle P, N, \phi \rangle$. Similarly, we may require weaker conditions on a set $S$, e.g. computable with respect to some oracle set (background knowledge) $B$ or being of other Turing (or enumeration) degree.

\begin{defn}
TODO Herbrand Interpretation, Hebrand Model.
\end{defn}

We can think of the model of an environment as a Hebrand model. Notice that the powerset of natural numbers is equinumerous with the set of Herbrand models. Therefore we can think of a natural number as a ground atom.

\begin{defn}
An \emph{inductive inference system} IIS is a computable function
$f: \powerset{\mathbb{N}} \times \powerset{\mathbb{N}} \times \powerset{\powerset{\mathbb{N}}}
\to \powerset{\mathbb{N}},
\langle P, N, \mathcal{H} \rangle \mapsto S$
satisfying the conditions:

\begin{enumerate}
\item $S$ is a computable set,
\item $S \in \mathcal{H}$,
\item $P \subseteq S$,
\item $N \cap S = \emptyset$.
\end{enumerate}
\end{defn}

We call $P$ a set of positive examples, $N$ a set of negative examples, $\mathcal{H}$ a bias, $S$ a solution (a hypothesis) to a problem of induction.

\section{Bottom and top theories}
The following definitions are motivated by a top theory of TDHD framework and a bottom clause of Prolog systems.
\begin{defn}
A top theory $\top$ with respect to $\langle P, N \rangle$ is
$\{x \in \mathbb{N} : \psi_\top(x)\}$,
a set definable by $\psi_\top$, or implicitly $\psi$ satisfying
$P \subseteq \top$.
A set $\mathcal{H}=\powerset{\top}$ is called a top theory bias.
\end{defn}

\begin{defn}
A bottom theory $\bot$ with respect to $\langle P, N \rangle$ is
$\{x \in \mathbb{N} : \psi_\bot(x)\}$,
a set definable by $\psi_\bot$, or implicitly $\psi$ satisfying
$N \cap \bot = \emptyset$.
A set $\mathcal{H}=\powerset{\bot}$ is called a bottom theory bias.
\end{defn}

\section{Generalization}
In order to define a notion of generalization in an abstracted setting we should understand what a generalization is in various ILP contexts.

Inoue in \cite{inoue2012} defines $\phi$ to be more general than $\psi$ iff
$M(\phi) \subseteq M(\psi)$ iff $\phi \models \psi$. An important observation is that as we generalize $\psi$ strictly the number of the possible models of $\phi$ shrinks, generalization increases certainty.

However, in systems like Toplog and Imparo whose logics use a Negation as Failure NAF, given a set of sentences $\Sigma$ it is complete since
$\forall \psi. \Sigma \models \psi \vee \Sigma \models \neg\psi$. Therefore every such consistent $\Sigma$ has only one Herbrand model. The notion of generalization cannot be defined in terms of models in logics with NAF. The intuition of a generalization comes from the $\theta$-subsumption.

\begin{defn}
Let a $C$, $D$ be sets of clauses, then $C$ $\theta$-subsumes $D$  written
$C \ge_\theta D$ iff $C \theta \subseteq D$.
\end{defn}

Notice that if $C \ge_\theta D$ then $C \models D$. Consider the case of $C=\{\neg female(x) \vee woman(x)\}$ and
$D=\{
\neg female(susan) \vee woman(susan),
\neg female(mary) \vee woman(mary),
\neg female(ann) \vee woman(ann) \}$.
Then $C$ $\theta$-subsumes $D$ with the substitution
$\theta=\{susan \backslash x, mary \backslash x, ann \backslash x\}$.
From the example we can see that generalization corresponds to deriving a more general rule from the specific instances of that rule. The theory $C$ is shorter than $D$ and less complex in a sense that it is easier to remember that every female is a woman than to remember that Susan is a woman, Mary is a woman, Ann is a woman given that we know that Susan, Mary, Ann are females.
Intuitively a set $S$ is simpler than a set $T$ if it can be defined in a simpler way:

\begin{defn}
Let $S$ and $T$ be subsets of $\mathbb{N}$, then we say that $S$ is more general than $T$ iff $K(S)<K(T)$ where $K(-)$ is the Kolmogorov complexity of its input set.
\end{defn}

\chapter{Model approximation}

\subsection{Approximation and error}
\begin{defn}
A theory $\Sigma$ \emph{approximates a theory $\Gamma$ by model} within the number $\epsilon$ called an error measure iff $\mu(M(\Sigma) \triangle M(\Gamma)) < \epsilon$ where $\mu:\{\mathcal{M}:\}\to [0,1]$ is a (probability) measure over the models and $[0,1] \subseteq \mathbb{R}$.
\end{defn}

\chapter{Score function}

\section{Axiomatization by score}
Find any axiomatization $A$ of the theory $O$ given $B$ with the greatest score $s(A,B,O)$ where $s$ is the \emph{score function}
$s:\mathcal{H} \times L \times L \to \mathbb{R}$.

\begin{exmp}
Define a score function $s$ by:
i. if $A$ infinite, then $s(A,B,O)=-1$,
ii. if $A \union B$ inconsistent, then $s(A,B,0)=-1$,
iii. otherwise $s(A,B,O)=\mu\{o \in O : A \union B \models o\}$.
\end{exmp}

\begin{exmp}
Define a score function $s:\mathcal{H} \times L \times L \to \mathbb{R}$ by $s(A,B,O)=1$ iff a theory $A \union B$ approximates a theory $O$ by model within a given error measure $\epsilon$, $s(A,B,O)=0$ otherwise.
\end{exmp}

\begin{note}
A score function is any total function taking into the consideration various criteria, e.g. minimum description length of the theory, finiteness of the theory, computational resources required to compute the theory. What a good score function is will be of our interest later.
\end{note}

\begin{exmp}
A Kolmogorov complexity with respect to the description language $L$ is a score function $K:L \to \mathbb{N}_0 \subseteq \mathbb{R}$.
\end{exmp}

\begin{note}
A Kolmogorov complexity $K$ can be thought of as a minimul description length with respect to the description language.
\end{note}
\begin{exmp}
Fix a description language to be a language of regular expressions. Let $L_1$ be a regular language given by its shortest description $0000000000$, $L_2$ given by its shortest description $10*$. Then $K(L_1)=10<K(L_2)=3$.
\end{exmp}

\chapter{Statistical learning}

\section{Incoherence of the generalization - Sawin-Demski paradox}
Consider the observations $P(0), \neg P(1), P(2)$ which are generalized by the rule $R1=\forall x. P(x)$ iff $x$ is even.
By inducing the $\Pi_1$ statement into the theory, it may be impossible for some true $\Pi_2$ statements to be part of the theory\cite{sawin2013}.
Therefore we limit ourselves to studying only the models where $\Pi_1$ statement true, $\Pi_2$ statement false.
