\chapter{Background}

\section{Prerequisites}
We assume the reader is familiar with basic concepts in several areas and consider the following references to be potentially useful:
\begin{enumerate}
\item Foundations of Inductive Logic Programming by Cheng and Wolf \cite{nienhuys1997foundations}
\item Model theory: An introduction by David Marker \cite{marker2002model}
\end{enumerate}
However, the usage of the concepts does not exceed its rudimentary application and the reader is encouraged to proceed further even if one may not be familiar with all the areas outlined, we suggest to use the literature when the need arises.
\section{A logic language}
\begin{defn}
An \emph{alphabet} is a set $\mathcal{A}$ of elements called \emph{letters} of an alphabet.
\end{defn}

\begin{defn}
A word over an alphabet $\mathcal{A}$ is a finite sequence (a string) of letters of the alphabet $\mathcal{A}$.
\end{defn}

\begin{defn}
A formal language $L$ is a set of words over the specified alphabet $\mathcal{A}$, i.e. $L \subseteq \powerset{\mathcal{A}}$.
\end{defn}

\begin{exmp}
Let $R$ be a regular expression $0001*$.
\begin{itemize}
\item The alphabet is the set $\mathcal{A}={\epsilon, 0,1,*}$. $0$, $1$, $*$ are called letters of $\mathcal{A}$.
\item The words over $\mathcal{A}$ are $000$.
\end{itemize}
\end{exmp}

Formal languages we are going to use are first-order languages:
\begin{defn}
A \emph{language} $L$ is a formal language given by the grammar of first-order logic and the additional data $\mathcal{L}$ called the signature of $L$:
\begin{enumerate}
\item a set $\mathcal{C}$ of letters called constant symbols,
\item a set $\mathcal{R}$ of letters called relation symbols and a positive integer (an arity) $n_R$ for each $R \in \mathcal{R}$,
\item a set $\mathcal{F}$ of letters called function symbols and a positive integer (an arity) $n_f$ for each $f \in \mathcal{F}$.
\end{enumerate}
\end{defn}

\begin{remark}
We will often talk about the language $L$ by referring to its signature $\mathcal{L}$. This should not cause a confusion as the signature $\mathcal{L}$ and the grammar of the first order logic uniquely determine the language $L$.
\end{remark}

\begin{exmp}
The language $\mathcal{L}_{EST}$ of elementary set theory is given by one constant symbol called an empty set, $\mathcal{C}=\{\emptyset\}$, one relation symbol called a set membership $\mathcal{R}=\{\in\}$ with a positive integer (arity) $n_{\in}=2$. The set of function symbols $\mathcal{F}$ are the set operations of a union, an intersection, each with an arity $2$.
\end{exmp}

\begin{defn}
Given a language $L$, $\phi$ is an $L$-formula iff $\phi \in L$.
\end{defn}

\begin{defn}
Let $\Sigma \subseteq L$, $\phi \in L$, then we say that $\Sigma$ \emph{equals} $\phi$ iff $\phi$ is a conjunction of the formulas $\psi \in \Sigma$, i.e. $\land \Sigma = \phi$. We abuse the symbol $=$ to denote the defined relation, writing $\Sigma=\phi$.
\end{defn}

\begin{remark}
If $\Sigma \subseteq L$, $\phi \in L$, $\Sigma=\phi$, then under the defined equality relation it is allowed to write both, $\Sigma \subseteq L$ and $\Sigma \in L$, for the later meaning $\Sigma = \phi \in L$.
\end{remark}

\section{Model theory\cite{marker2002model}}
Since the author to best of his knowledge considers the first-order model theory more developed as well as having better learning resources than model theory  of other logics, he will reason in first-order model-theory and will use the first-order definitions from Model Theory by Marker\cite{marker2002model}.

\begin{defn}
An \emph{$\mathcal{L}$-structure} (\emph{a model}) $\mathcal{M}$ is given by the following data:
\begin{enumerate}
\item a nonempty set $M$ called the universe, domain, or underlying set of $\mathcal{M}$;
\item a function $f^{\mathcal{M}} : M^{n_f} \to M$ for each $f \in F$;
\item a set $\mathcal{R}^{\mathcal{M}} \subseteq M^{n_R}$ for each $R \in \mathcal{R}$;
\item an element $c^\mathcal{M} \in M$ for each $c \in C$.
\end{enumerate}
We refer to $f^\mathcal{M}, R^\mathcal{M}, c^\mathcal{M}$ as the interpretations of the symbols $f ,R, c$.
\end{defn}

\begin{exmp}
$\mathcal{M}_{India}$ is a model given by
$M=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$TastesHot=\{milk^\mathcal{M}, curry^\mathcal{M}\}$,
$IsWhite=\{milk^\mathcal{M}\}$ with a canonical mapping of constants from
 $C=\{milk, curry\}$ to $M$. Therefore $\mathcal{M}$ is a model of a formula
$\phi=TastesHot(milk) \wedge \neg IsWhite(curry)$ denoting by
$\mathcal{M} \models \phi$ reading "a model $\mathcal{M}$ entails a formula $\phi$".
\end{exmp}

\begin{remark}
An $L$-structure is an $\mathcal{L}$-structure iff $\mathcal{L}$ is a signature of a language $L$.
\end{remark}

\begin{defn}
Given a set $T$ of logic sentences and a model $\mathcal{M}$. If $\forall \phi \in T. \mathcal{M} \models \phi$, then $\mathcal{M}$ is \emph{a model of $T$} and $T$ is \emph{a theory of $\mathcal{M}$}.
\end{defn}

\begin{defn}
$A$ is an axiomatization of the theory $T$ iff $M(A)=M(T)$.
\end{defn}

\begin{remark}
Typically we put further restrictions on the properties of the axiomatization $A$ that do not hold for $T$. E.g. $A$ must have finitely many axioms for $T$ with infinitely many axioms.
\end{remark}

\begin{defn}
$A$ is an axiomatization of the theory $O$ from the theory $B$ iff $M(A \union B)=M(O)$.
\end{defn}

\section{Logics\cite{sep-logic-nonmonotonic}}
We adapt definitions of consequence operators from \cite{sergot2005knowledgeRepresentationLectureNotes}.

\begin{defn}
A \emph{consequence operator} on a set $L$ is a function $Cn:\powerset{L} \to \powerset{L}$ satisfying the following conditions for all sets $X, Y \subseteq L$:\\
1) $X \subseteq cl(X)$ inclusion,\\
2) $cl(cl(X)) \subseteq cl(X)$ closure.\\
\end{defn}

\begin{defn}
A consequence operator $Cl:\mathcal{L} \to \mathcal{L}$ is a \emph{classical consequence operator} iff it satisfies \emph{monotony}:
$X \subseteq Y \implies Cl(X) \subseteq Cl(Y)$.
\end{defn}

\begin{defn}
A consequence operator $Cn:\mathcal{L} \to \mathcal{L}$ is a \emph{non-monotone consequence operator} iff it does not satisfy monotony, i.e.
$\exists X, Y \subseteq L, X \subseteq Y \land Cn(X) \not\subseteq Cn(Y)$.
\end{defn}

\begin{defn}
A logic satisfies a \emph{monotony} property iff its consequence operator $\models$ is monotone, i.e.
if $\Gamma \models \phi$ and $\Gamma \subseteq \Delta$ then $\Delta \models \phi$. A logic that satisfies a monotony property is called monotonic, otherwise non-monotonic.
\end{defn}

\begin{exmp}
First-order logic is monotonic.
\end{exmp}

Logics used in ILP are usually non-monotonic.

\section{Logic Programming}

\begin{defn}
A logic programming language has a \emph{negation on failure}\cite{clark1978negation} NoF property iff $\forall \phi, \forall \psi. \phi \not\vdash \psi \implies \phi \vdash \neg\psi$ where the $\vdash$ is a consequence operator.
\end{defn}

\begin{exmp}
In a logic programming language Prolog in a program $P$ with a single sentence:

$spicy(X) :- curry(X).$

the atom $spicy(X)$ is not provable, therefore $P \vdash \neg spicy(X)$ since Prolog has a NoF property.
\end{exmp}

Notice that NoF property on the consequence operator directly implies its monotony. Unless indicated the logic programming language we will reason will will have a NoF property.

The following definitions and concepts are adaptations from Dianhuan Lin's Master thesis\cite{lin2009efficient}.

\subsection{Basic concepts and notation of Logic Programming\cite{lin2009efficient}}

\begin{defn}
A term is a constant, variable, or the application of a function symbol to the appropriate number of terms. A ground term is a term not containing variables.
An atom is the application of a predicate symbol to the appropriate number of terms. A literal is an atom or the negation of an atom.
\end{defn}

\begin{defn}
A definite goal is a clause of the form
$\leftObjectImplies B_1 , ..., B_n$.
where $n > 0$ and each $B_i$ is an atom.
Each $B_i$ is called a subgoal of the goal.
\end{defn}

\begin{defn}
A definite clause is a clause of the form
$A \leftObjectImplies B_1 , ..., B_n$
which contains precisely one positive literal $A$.
$A$ is called the head and $B_1$ , ..., $B_n$ is called the body of the clause.
A Horn clause is either a definite clause or a definite goal.
A unit clause consists of a single literal.
\end{defn}

\begin{defn}
A logic program is a finite set of clauses representing their conjunction.
\end{defn}

\subsubsection{Resolution\cite{kimber2012learning}}
The resolution inference rule for a literal $\phi$ and clauses $\psi, \chi$ is
$(\phi \vee \psi) \wedge (\neg \phi \wedge \chi) \models \phi \vee \chi$.

\subsection{Representation of logic theories}\label{background_representation_of_logic_theories}
A \emph{logic theory} is a subset of a logic language $L$.
\emph{Clausal theories} allow sentences to be clauses, but one may restrict the theories to be \emph{extended logic programs}, \emph{normal logic programs}, 
\emph{Horn theories}, \emph{definite logic programs}, \emph{Datalog programs}, \emph{literals}, \emph{atoms}. For example, Imparo\cite{kimber2012learning} requires background knowledge and a hypothesis to be a definite logic programs and examples $E^{+}$ and $E^{-}$ to be ground atomic whereas Yamamoto et al. reason about the explanatory induction in \cite{yamamoto2012inverse} with any clausal theories $B, E, H$. This has an impact on the complexity of the learning problem as every definite theory can be expressed as a clausal theory, but not vice versa.

\section{Machine learning}
Machine learning a subdiscipline of AI that studies the construction of algorithms learning from the data.

\begin{defn}\cite{mitchell1997machine}
A computer program (a function, an algorithm, an ILP system) is said to \emph{learn (a function $f$) from experience} $E$ (input/output pairs of a function $f$)
with respect to some class of tasks $T$ (computing the output $f(I)$ from the input $I$) and performance measure $P$,
if its performance at tasks $T$ as measured by $P$ improves with the experience $E$.
\end{defn}

\begin{remark}
A function $f$ is a learning problem to be learnt by a computer program.
\end{remark}

\subsection{Types of problem}
Let $\mathcal{I}$, $\mathcal{O}$ be any sets of inputs and outputs.

\begin{defn}
A \emph{function problem} is a function $\mathcal{I} \to \mathcal{O}$.
\end{defn}

\begin{defn}
A \emph{decision problem} is a function problem $\mathcal{I} \to \{yes, no\}$.
\end{defn}

\begin{defn}
A mathematical object $f':\mathcal{I}' \to \mathcal{O}'$ \emph{solves a problem} $f:\mathcal{I} \to \mathcal{O}$ iff $\mathcal{I} \subseteq \mathcal{I}'$ and
$\forall I \in \mathcal{I}. f'(I)=f(I)$.
$f$ is called a \emph{subproblem} of $f'$.
\end{defn}

In machine learning a function problem $f:\mathcal{I} \to \mathcal{O}$ is called a \emph{learning problem} and a computer program $f'$ \emph{learns} a problem $f$ if $f'$ solves $f$. In ILP a learning problem is called an \emph{ILP task}, an input $I \in \mathcal{I}$ may consist of logical theories $B, E$ and an output of a logical theory $H$ explaining $E$ in terms of $B$, i.e. $E \subseteq Cn(B \cup H), false \not\in Cn(B \cup H)$ for some consequence operator $Cn$.