\chapter{Appendix - evaluation of ILP systems on examples}

\section{Toplog}
\subsection{Mode declarations order bias}
Consider the Toplog program:

\begin{minipage}[t]{.35\textwidth}
\begin{lstlisting}
:-modeh(r(+type)).
:-modeb(1, p1(+type)).
:-modeb(1, p2(+type)).
:-set(maximum_literals_in_hypothesis, 10).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
p1(a1).
p1(a2).
p1(a3).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
p2(a1).
p2(a2).
p2(a3).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
example(r(a1),1).
example(r(a2),1).
example(r(a3),1).
\end{lstlisting}
\end{minipage}


Then Toplog learns a hypothesis $r(A) :- p1(A).$ however if we change the mode declaration to the following:
\begin{lstlisting}
:-modeh(r(+type)).
:-modeb(1, p2(+type)).
:-modeb(1, p1(+type)).
\end{lstlisting}
then Toplog learns a hypothesis $r(A) :- p2(A).$ instead. This experiment therefore shows that Toplog's bias depends on the order of the mode declaration statements.

\subsection{Learning inconsistent hypothesis}
Toplog can learn inconsistent hypotheses:

\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeb(1, student(+person)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
student(ann).
student(tom).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}
\end{minipage}


gives an output hypothesis $woman(A) :- student(A)$ although $tom$ is not a woman as indicated by a negative example $example(woman(tom),-1)$.
But this is intentional, furthermore Toplog provides the information that the default accuracy of its hypothesis is 90\% as $example(woman(ann,9)$ corresponds to 9 positive examples correctly classified out of 10.

\subsection{One head predicate bias}
All the clauses in the hypotheses space of Toplog have to have the same predicate symbol in its head.

\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeb(1, female(+person)).
:-modeb(1, male(+person)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
male(tom).
female(ann).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}
\end{minipage}

produces a hypothesis \tc{woman(A) :- female(A)} but adding a second
head mode declaration \\
\tc{:-modeh(man(+person)).} after \tc{:-modeh(woman(+person)).} overwrites the first one.

\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeh(man(+person)).
:-modeb(1, female(+person)).
:-modeb(1, male(+person)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
male(tom).
female(ann).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
example(woman(ann),9).
example(woman(tom),-1).
\end{lstlisting}
\end{minipage}

produces no hypotheses.

\subsection{Unlearnability of the term structure}
Consider one would like to learn a concept of a Kleene star operator on the terms evident from the following examples:
\begin{lstlisting}
%target concept: in_language(s(A)) :- in_language(A).
:-modeh(in_language(s(+word))).
:-modeb(1, in_language(+word)).

example(in_language(s(epsilon)),1).
example(in_language(s(s(epsilon))),1).
example(in_language(s(s(s(epsilon)))),1).
example(in_language(s(s(s(s(epsilon))))),1).
\end{lstlisting}

However, this is not learnable since Toplog's mode declarations do not allow to specify\\
\tc{in\_language(s(A))} in a head neither in a body. Toplog outputs:
"Couldn't start model. (no problem defined?)".

\subsection{Clausal bias}
Since Toplog's hypotheses space consists of clauses, it cannot learn two concepts at one time.

\begin{lstlisting}
:-modeh(object(+type)).
:-modeb(10, blue(+type)).
:-modeb(10, green(+type)).
:-set(maximum_literals_in_hypothesis, 10).
\end{lstlisting}

\begin{minipage}[t]{.35\textwidth}
\begin{lstlisting}
blue(ball).
blue(pen).
blue(bag).
green(shirt).
green(grass).
green(tree).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
example(object(ball),1).
example(object(pen),1).
example(object(bag),1).
example(object(shirt),1).
example(object(grass),1).
example(object(tree),1).
\end{lstlisting}
\end{minipage}

will produce a hypothesis \tc{object(A) :- blue(A)} since 
\tc{:-modeb(10, blue(+type)).} was defined first instead of learning both
concepts in a hypothesis:
\tc{object(A) :- blue(A); green(A)} where the \tc{;} represents a disjunction.

\subsection{Inability to make deductions from observations}
Toplog does not learn any hypothesis from the following program:

\begin{lstlisting}
:-modeh(t(+type)).
:-modeb(1, p(+type)).
:-set(maximum_literals_in_hypothesis, 10).
\end{lstlisting}
\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
p(a1).
p(a2).
p(a3).
t(A) :- r(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
example(r(a1),1).
example(r(a2),1).
example(r(a3),1).
\end{lstlisting}
\end{minipage}

Although from the positive examples and the background knowledge included one may deduce examples:
\begin{lstlisting}
example(t(a1),1).
example(t(a2),1).
example(t(a3),1).
\end{lstlisting}
which if included in the Toplog program, then a hypothesis
\tc{tc(A) :- p(A)} would be learnt.
Therefore the application of the background knowledge to the observations in Toplog is limited.

Nevertheless, Toplog can still learn by making deductions from its background knowledge.

\begin{lstlisting}
:-modeh(t(+type)).
:-modeb(1, r(+type)).
:-set(maximum_literals_in_hypothesis, 10).
\end{lstlisting}
\begin{minipage}[t]{.35\textwidth}
\begin{lstlisting}
p(a1).
p(a2).
p(a3).
r(A) :- p(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
example(t(a1),1).
example(t(a2),1).
example(t(a3),1).
\end{lstlisting}
\end{minipage}

would give a hypothesis \tc{t(A) :- r(A).}

\subsection{Predicate generalization impossible}
Toplog cannot generalize over the predicates as this cannot be expressed in the mode declarations bias, consider the illustrative example.
\begin{lstlisting}
example(swims(magician),1).
example(flies(magician),1).
example(cooks(magician),1).
example(makes_fire(magician),1).
\end{lstlisting}
The hypothesis $\forall x. x(magician)$ cannot be induced. Depending on our language and the predicates it contains and the context of the problem, we may need to express hypotheses as second-order logic formulas.

\subsection{Ground atom example}
Toplog has a limitation that every example can be only a ground atom.

\section{Imparo's capabilities}
\subsection{A multiclausal learning}
Imparo is capable to learn a multi-clausal hypothesis at one time.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   woman(+person),
   man(+person)
]).

body_modes([
    female(+person),
    male(+person)
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jane).
person(susan).
person(jack).
person(sam).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).

male(jack).
male(sam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
woman(jane).
woman(susan).
man(jack).
man(sam).

:- woman(jack).
:- man(susan).
\end{lstlisting}
\end{minipage}


produces a hypothesis
\begin{lstlisting}
woman(A):-female(A)
man(A):-male(A)
\end{lstlisting}

Learning multiple hypotheses is not possible in all systems, e.g. Toplog. Nevertheless the clauses have to be Horn, the ones with at most one positive literal and therefore hypotheses of the form $s \vee p \leftObjectImplies r$ cannot be learnt.

\subsection{Learnability of a nested term structure}
Imparo is capable of learning a language constructed from the alphabetical symbols and a Kleene star operation. Observations below correspond to the language defined by the regular expression \tc{(sr)*}.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
head_modes([
   in_language(+word),
   in_language(s(+word)),  
   in_language(s(s(+word))),
   in_language(r(s(+word))),
   in_language(s(r(+word))),
   in_language(r(+word)),
   in_language(r(r(+word)))
]).

body_modes([
    in_language(+word),
    in_language(s(+word)),
    in_language(r(+word))
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
word(e).
word(s(X)).
word(r(X)).

%Examples
in_language(e).
in_language(r(s(e))).
in_language(r(s(r(s(e))))).
in_language(r(s(r(s(r(s(e))))))).

:- in_language(r(e)).
:- in_language(r(r(e))).
:- in_language(s(s(r(e)))).
:- in_language(s(s(s(e)))).
\end{lstlisting}
\end{minipage}


returns a hypothesis
\begin{lstlisting}
in_language(e):-true
in_language(r(s(A))):-true
\end{lstlisting}

Note, this was not possible in Toplog.

\subsection{Learnability of multi-clausal concepts}
Imparo can explain observations for which there does not exist a one-clausal explanation by inducing a multi-clausal hypothesis.

\begin{minipage}[t]{.26\textwidth}
\begin{lstlisting}
head_modes([
   man(+person),
   woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.22\textwidth}
\begin{lstlisting}
person(jane).
person(susan).
person(eugenia).
person(jack).
person(sam).
person(martin).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.34\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).
female(eugenia).

couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).

male(X) :- couple(X,Y), woman(Y).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
man(jack).
man(martin).

woman(jane).
woman(susan).

:-man(jane).
:-woman(sam).
\end{lstlisting}
\end{minipage}

produces the hypothesis
\begin{lstlisting}
man(A):-male(A)
woman(A):-female(A)
\end{lstlisting}.

To learn the hypothesis \tc{man(A):-male(A)} from the background knowledge and the observations we have to use the predicate \tc{male(X) :- couple(X,Y), woman(Y).}, but this requires the knowledge of who is a woman, which can be only acquired by inducing a second hypothesis \tc{woman(A):-female(A)}. Therefore, the concept learnt by Imparo requires at least two clauses.

\section{Imparo's assumed limitations}
Observations demonstrating the limits of the concept learnability from the system design assuptions are presented.

\subsection{Unlearnability of negative examples}
Note: Imparo uses a completion semantics.
In cases when a hypothesis could explain the negative examples, Imparo cannot learn such a clause.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   woman(+person)
]).

body_modes([
    woman(+person),
    female(+person),
    male(+person)
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jane).
person(susan).
person(jack).
person(sam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).

male(jack).
male(sam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
:- woman(jack).
:- woman(sam).
\end{lstlisting}
\end{minipage}

The hypothesis of the form $\neg male(x) \vee \neg woman(x)$ would explain the examples, however Imparo in this case outputs no hypothesis.

Adding further information to the background knowledge does not remove the limits:

\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}
not_man(X) :- woman(X).
not_woman(X) :- man(X).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
:- woman(X), man(X).
:- not_woman(X), not_man(X).
\end{lstlisting}
\end{minipage}

The background knowledge says that everybody has to be either a woman or a man. From our observations negative examples are not learnable by Imparo, however a hypothesis produced is consistent with the all the examples and the background knowledge.

This may be related to the existence of a definition of an ILP system where the produced hypothesis $H$ has to explain positive examples, but it is sufficient if negative examples are only consistent with the hypothesis, notationally the necessity condition says:
$H, B \models E^+$ and $H, B \not \models E^-$.

Favouring this definition results in a bias in which hypotheses space is biased towards positive examples.

\subsection{Assumption of consistency}
Imparo assumes that the set of observations is consistent.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   male(+person)
]).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jack).
person(sam).
person(john).
person(glory).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
:- man(glory).

man(glory).
\end{lstlisting}
\end{minipage}

produces a hypothesis
\begin{lstlisting}
man(glory):-true
\end{lstlisting}
although it is inconsistent with the observation
\begin{lstlisting}
:- man(glory).
\end{lstlisting}

Imparo still learns
\begin{lstlisting}
man(glory):- true
\end{lstlisting}
even if we move the negative observation
\begin{lstlisting}
:- man(glory).
\end{lstlisting}
to the background knowledge.

Systems like Progol check for inconsistencies before learning is started. However, in some definitions of an ILP problem, an assumption that the background knowledge is consistent with the observations is made.

\section{Imparo's violations and biases}
Limits of the learnability violating the system specification and not stated as assumptions are presented as observations.

\subsection{Default examples bias}
Imparo has examples in its default bias even if these are not declared in the mode declarations.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   %woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jane).
person(susan).
person(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).

male(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
woman(jane).
woman(susan).

:- woman(jack).
\end{lstlisting}
\end{minipage}


produces a hypothesis 
\begin{lstlisting}
woman(jane):-true
woman(susan):-true
\end{lstlisting}

in which a predicate \tc{woman} is a head symbol although it was not specified in the mode declaration. Once it is specified in a declaration as
\begin{lstlisting}    
head_modes([
   woman(+person)
]).
\end{lstlisting}

a more general hypothesis is learnt

\begin{lstlisting}
woman(A):-female(A)
\end{lstlisting}.

This demonstrates that in some cases mode declaration bias does not correspond to the actual bias of Imparo.

\subsection{Weak head mode declaration}
A head mode declaration in Imparo allows only definitions with specific term structure as opposed to the ability to substitute a variable for any term.

\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
head_modes([
   woman(+person)
]).

body_modes([
    female(+person),
    male(+person)
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
person(jane).
person(susan).
person(eugenia).
person(jack).
person(sam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).
female(eugenia).

%Examples
woman(sister(jane)).
woman(sister(eugenia)).
:- woman(jack).
\end{lstlisting}
\end{minipage}

produces a hypothesis 
\begin{lstlisting}
woman(sister(jane)):-true
woman(sister(eugenia)):-true
\end{lstlisting}.

If we would like generalize on the terms, we have to add them explicitly to the mode declaration, i.e.
\begin{lstlisting}
head_modes([
   woman(+person),
   woman(sister(+person))
]).
\end{lstlisting}
produces a more general hypothesis
\begin{lstlisting}
woman(sister(A)):-true
\end{lstlisting}

In this regard, Imparo treats function symbols as a syntactic sugar - a predicate with a function symbol is treated as a predicate symbol, one could simply replace \tc{woman(sister(x))} by \tc{woman\_sister(x)} in examples and mode declarations and add the following to the background knowledge:
\begin{lstlisting}
woman_sister(X) :- woman(sister(X)).
woman(sister(X)) :- woman_sister(X).
\end{lstlisting}
The advantage of a support of a term structure is a matter of convenience rather than an added expressivity of the problem description and produced hypotheses.

\subsection{No generalization downwards}
Imparo cannot learn the hypotheses of the form $P(s(x)) \objectImplies P(x)$ for all classes of applicable observations.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   even(+number)
]).

body_modes([
    even(+number),
    even(s(+number)),
    even(s(s(+number)))
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
number(0).
number(s(X)).

\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Background knowledge
even(s(s(s(s(s(s(s(s(0))))))))).

%Examples
even(0).
even(s(s(0))).
even(s(s(s(s(0))))).
even(s(s(s(s(s(s(0))))))).
:-even(s(0)).
:-even(s(s(s(0)))).
\end{lstlisting}
\end{minipage}


only learn the examples

\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}
even(0):-true
even(s(s(s(s(s(s(0))))))):-true
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
even(s(s(0))):-true
even(s(s(s(s(0))))):-true
\end{lstlisting}
\end{minipage}


where we may expect a more general shorter hypothesis

\begin{lstlisting}
even(A) :- even(s(s(A)).
\end{lstlisting}
This may be related to the mentioned limitation of how Imparo treats the terms. A translated instance of \tc{even(s(s(s(s(0)))))} would be
\tc{even\_s\_s\_s\_s\_s\_s(0)}, but in fact we want \tc{even\_s\_s(s(s(s(s(0))))} in order to be able to learn
\tc{even(A) :- even\_s\_s(A)}.

However, the generalization downwards does not work with a hypothesis having an argument with one function symbol in its body either.

\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
head_modes([
   numeral(+number)
]).

body_modes([
    numeral(+number),
    numberal(s(+number)),
    numeral(s(s(+number)))
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
number(0).
number(s(X)).

\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowledge
numeral(s(s(s(s(0))))).

%Examples
numeral(0).
numeral(s(0)).
numeral(s(s(0))).
numeral(s(s(s(0)))).
:-numeral(s(not_number)).
:-numeral(s(s(s(not_number)))).                                   
\end{lstlisting}
\end{minipage}


returns a hypothesis

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
numeral(0):-true
numeral(s(s(s(0)))):-true
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
numeral(s(0)):-true
numeral(s(s(0))):-true
\end{lstlisting}
\end{minipage}


however, a more general hypothesis \tc{numeral(A) :- numeral(s(A)).} would explain the examples.

\subsection{Literal observational bias}
Imparo can accept only the examples in the form of literals. If presented with other clauses in the example file, it will not run.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   male(+person)
]).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jack).
person(sam).
person(john).
person(glory).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Background
%knowledge
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
man(jack) :- male(jack).
man(sam) :- male(sam).
man(john) :- male(john).

:- man(glory).
\end{lstlisting}
\end{minipage}

Expected hypothesis explaining the examples:

\begin{lstlisting}
man(X) :- male(X).
\end{lstlisting}

To the author's knowledge, other ILP systems do not deal with the case of non-literal observations, however the works by Plotkin dealt with the generalization of a general set of clauses.

\subsection{Preference over the later mode declarations}
The search bias of the Imparo prefers the predicates that have been defined by the mode declarations later.

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
head_modes([
   man(+person)
]).

body_modes([
   policeman(+person),
   male(+person)
]).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jack).
person(sam).
person(john).
person(jane).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%Background knowldge
male(jack).
male(sam).
male(john).
policeman(jack).
policeman(sam).
policeman(john).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%Examples
man(jack).
man(sam).

:- man(jane).
\end{lstlisting}
\end{minipage}


learns a hypothesis
\begin{lstlisting}
man(A):-male(A)
\end{lstlisting}
However, changing the body mode declaration to
\begin{lstlisting}
body_modes([   
   male(+person),
   policeman(+person)
]).
\end{lstlisting}
results in learning the hypothesis
\begin{lstlisting}
man(A):-policeman(A)
\end{lstlisting}

This search bias in Imparo has a priority over the criterion of favouring a stronger or a weaker hypothesis. By adding to the background knowledge
\begin{lstlisting}
policeman(X) :- male(X).
\end{lstlisting}
or its converse
\begin{lstlisting}
male(X) :- policeman(X).
\end{lstlisting}
the hypothesis learnt remains the same.
Note that \tc{male(X) :- policeman(X).} says that every model of \tc{policeman(X)} has to be a model of \tc{male(X)} and with such background knowledge \tc{man(A):-policeman(A)} is true in fewer models than \tc{man(A):-male(A)} is.

\subsection{Other biases}
Imparo can learn only a conjunction of clauses as a hypothesis.
Imparo cannot explain the negative observations.

\section{Aleph's capabilities}

\subsection{Multi-clausal learning}
Aleph can learn several one-clausal hypotheses at one time.

\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person)).
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).
:-modeb(*, female(+person)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
:- determination(man/1,male/1).
:- determination(woman/1,female/1).
\end{lstlisting}
\end{minipage}

\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%background theory
male(bob).
male(tom).

female(ann).
female(mary).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%positive examples
woman(ann).
woman(mary).
man(bob).
man(tom).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%negative examples
man(ann).
man(mary).
woman(bob).
woman(tom).
\end{lstlisting}
\end{minipage}

returns hypotheses

\begin{lstlisting}
woman(A) :- female(A).
man(A) :- male(A).
\end{lstlisting}

Note, this is possible in Imparo, but not in Toplog.

\subsection{Learnability of predicates of greater arity}
Aleph can induce hypotheses that contain predicates of arity greater than 1.
\begin{lstlisting}
%background theory
:-modeh(*, english(+person)).
:-modeb(*, english_couple(+person, -person)).
:-modeb(*, english(+person)).

:- determination(english/1, english_couple/2).
\end{lstlisting}
\begin{minipage}[t]{.40\textwidth}
\begin{lstlisting}
english_couple(adam, alice).
english_couple(bob, barbara).
english_couple(jack, jane).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.27\textwidth}
\begin{lstlisting}
%positive examples
english(adam).
english(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
%negative examples
english(budha).
\end{lstlisting}
\end{minipage}

returns back a generalized hypothesis
\begin{lstlisting}
english(A) :- english_couple(A,B).
\end{lstlisting}.

Note, that since the induce hypothesis does not use the variable \tc{B}, the variable had to be specified in a mode declaration with a minus sign as \tc{-person}.

Similarly, learning of hypotheses with polyadic predicate symbols in their head is possible.

\begin{lstlisting}
:-modeh(*, english_couple(+person, +person)).
:-modeb(*, english(+person)).
:- determination(english_couple/2, english/1).
\end{lstlisting}

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%background theory
english_couple(adam, alice).
english_couple(bob, barbara).
english(alice).
english(jane).
english(barbara).
english(adam).
english(bob).
english(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
english_couple(adam, alice).
english_couple(bob, barbara).
english_couple(jack, jane).

%negative examples
english_couple(budha, karma).
english_couple(jack, shreedipta).
english_couple(amir, jane).
\end{lstlisting}
\end{minipage}

returns a hypothesis

\begin{lstlisting}
english_couple(A,B) :- english(B), english(A).
\end{lstlisting} which has in its head a predicate of arity 2.

\subsection{Term structure learnability}
Aleph can learn the hypotheses whose terms contain function symbols.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeh(*, woman(sister(+person))).
:-modeb(*, anybody(+person)).

:-determination(woman/1, anybody/1).

anybody(jane).
anybody(susan).
anybody(bob).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
woman(sister(bob)).
woman(sister(jane)).
woman(sister(susan)).

%negative examples
woman(sister(frog)).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
woman(sister(A)) :- anybody(A).
\end{lstlisting}
In comparison, Imparo can learn the term structure but Toplog cannot.

\subsection{Generalization downwards}
Aleph can learn the hypotheses of the form $P(s(x)) \objectImplies P(x)$.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeh(*, even(+number)).
:-modeb(*, even(+number)).
:-modeb(*, even(s(+number))).
:-modeb(*, even(s(s(+number)))).
:- determination(even/1, even/1).

%background theory
even(s(s(s(s(s(s(s(s(0))))))))).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
even(0).
even(s(s(0))).
even(s(s(s(s(0))))).
even(s(s(s(s(s(s(0))))))).

%negative examples
even(s(0)).
even(s(s(s(0)))).
\end{lstlisting}
\end{minipage}

produces a hypothesis
\begin{lstlisting}
even(A) :- even(s(s(A))).
\end{lstlisting}
which comes as a surprise since neither Imparo nor Toplog can learn the hypotheses whose variable in head is wrapped by function symbols in its body literals.

\section{Aleph's assumed limitations}
\subsection{Unlearnability of negative examples}
Aleph learns positive examples, but cannot learn the negative ones.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeb(*, woman(+person)).
%background theory
%positive examples
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%negative examples
woman(bob).
woman(tom).
\end{lstlisting}
\end{minipage}

does not return any hypothesis, even if we specify the hypothesis in the mode declaration by \tc{:- woman(+person)}.

\subsection{Determination declaration requirement}
The hypotheses space cannot be defined with the mode declarations alone, mode declarations have to be supplied with the determination declarations.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person)).
:-modeb(*, female(+person)).
%:- determination(woman/1,female/1).

%background theory
female(ann).
female(mary).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%positive examples
woman(ann).
woman(mary).

%negative examples
woman(bob).
\end{lstlisting}
\end{minipage}

does not return a generalized hypothesis but the examples
\begin{lstlisting}
woman(ann).
woman(mary).
\end{lstlisting}.
After including the determination declaration
\begin{lstlisting}
:- determination(woman/1,female/1).
\end{lstlisting}
a more general hypothesis \tc{woman(A) :- female(A).} is learnt. To the author it is not clear why the hypothesis space has to be defined with two definitions. Systems like Imparo do not need determinations declarations.

\subsection{Assumption of consistency}
Aleph assumes the examples are consistent.

\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%background theory
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%positive examples
woman(ann).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%negative examples
woman(ann).
\end{lstlisting}
\end{minipage}

returns a hypothesis \tc{woman(ann).} which is inconsistent with the negative examples. Aleph assumes that the set of background knowledge union with examples is a consistent.

\subsection{Unlearnability of regular languages}
Although Aleph can learn a simple term structure, it cannot learn more complex concepts like a regular language represented by regular expression \tc{(ss)*}.

\begin{lstlisting}
:-modeh(*, in_language(s(s(+word)))).
:-modeh(*, in_language(s(+word))).
:-modeb(*, in_language(+word)).
:- determination(in_language/1, in_language/1).
\end{lstlisting}

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%background theory
in_language(epsilon).
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).

%negative examples
in_language(s(epsilon)).
in_language(s(s(s(epsilon)))).
\end{lstlisting}
\end{minipage}

returns back positive examples
\begin{lstlisting}
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).
\end{lstlisting}
A more general hypothesis representing the language is
\begin{lstlisting}
in_language(s(s(A)) :- in_language(A).
\end{lstlisting}
If our target hypothesis had only one function symbol in its predicate and its correspondent examples, then a simpler hypothesis
\begin{lstlisting}
in_language(s(A)) :- in_language(A).
\end{lstlisting}
could indeed be learnt.

\subsection{Unlearnability of multi-clausal concepts}
Aleph cannot learn a hypothesis that needs more that one clause to explain the examples.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person)).
:-modeh(*, man(+person)).

:-modeb(*, male(+person)).
:-modeb(*, female(+person)).

:- determination(woman/1, female/1).
:- determination(man/1, male/1).

%positive examples
man(jack).
man(martin).
woman(jane).
woman(susan).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%background theory
female(jane).
female(susan).
female(eugenia).

couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).

male(X) :- couple(X,Y), woman(Y).

%negative examples
man(jane).
woman(sam).
\end{lstlisting}
\end{minipage}

produces a hypothesis
\begin{lstlisting}
man(jack).
man(martin).
woman(A) :- female(A).
\end{lstlisting}

However, if we put the induced hypothesis to the background knowledge, then a hypothesis generalizing \tc{man} examples would be produced
\begin{lstlisting}
man(A) :- male(A).
woman(A) :- female(A).
\end{lstlisting}

To explain the \tc{man} examples we needed to learn a two clausal hypothesis. This limitation is present in Toplog, however not in Imparo. The limitation not only demonstrates inability to learn more complex concepts, but also to make deductions from the observations such as \tc{woman} examples in order to deduce a hypothesis.

\subsection{Other assumed limitations}
Any hypothesis learnt in Aleph has to be a Horn theory. Aleph cannot learn second-order logic statements. Aleph cannot make deductions from the observations as it can from the background knowledge.

\section{Aleph's violations and biases}

\subsection{Default Example Bias}
Aleph includes examples in its bias even if these are not specified by mode declarations.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%:-modeh(*, woman(+person)).
%:-modeb(*, female(+person)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
woman(ann).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
woman(ann).
\end{lstlisting}

Therefore the hypotheses space is not entirely defined by mode declarations and determination declarations.

\subsection{Weak head mode declaration}
A head mode declaration in Aleph allows only definitions with specific term structure as opposed to
the ability to substitute a variable or a type (e.g. \tc{+person}) for any term.

\begin{minipage}[t]{.55\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person)).
:-modeb(*, anybody(+person)).
:- determination(woman/1, anybody/1).
person(sister(A)).

%background theory
anybody(jane).
anybody(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
%positive examples
woman(sister(jane)).
woman(sister(jack)).

%negative examples
woman(sister(frog)).
\end{lstlisting}
\end{minipage}

returns back the positive examples
\begin{lstlisting}
woman(sister(jane)).
woman(sister(jack)).
\end{lstlisting}

However, if we added the \tc{sister} function symbol in the mode declaration explicitly
\begin{lstlisting}
:-modeh(*, woman(sister(+person))).
\end{lstlisting}
then a more general hypothesis
\begin{lstlisting}
woman(sister(A)) :- anybody(A).
\end{lstlisting}
would be learnt. This constraint is present in Imparo as well. To the author the reason is not clear since \tc{woman(sister(+person))} is subsumed by
\tc{woman(+person)} which was already present in the mode declaration. Therefore unless specified in the mode declarations, Aleph can learn only the hypothesis whose terms do not contain the function symbols.

\subsection{Literal observation bias}
Aleph can accept only the examples in the form of literals. If presented with other clauses in the example file, it will not run

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).
:- determination(man/1, male/1).

%background theory
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
man(jack) :- male(jack).
man(sam) :- male(sam).
man(john) :- male(john).

%negative examples
man(glory).
\end{lstlisting}
\end{minipage}

Expected hypothesis explaining the examples:
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}
In comparison systems like Imparo and Toplog do not accept examples of non-literal form either.

\subsection{Preference over earlier determinations}
Aleph prefers learning a hypothesis whose determination declaration has been defined earlier.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, man(+person)).
:-modeb(*, male(+person)).
:-modeb(*, bridegroom(+person)).

:- determination(man/1, bridegroom/1).
:- determination(man/1, male/1).

bridegroom(jack).
bridegroom(sam).
bridegroom(john).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%background theory
male(jack).
male(sam).
male(john).

%positive examples
man(jack).
man(sam).
man(john).

%negative examples
man(susan).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
man(A) :- bridegroom(A).
\end{lstlisting}

Changing the order of the determination declarations to
\begin{lstlisting}
:- determination(man/1, male/1).
:- determination(man/1, bridegroom/1).
\end{lstlisting}
results in a hypothesis
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}
In both cases, the induced hypothesis had a head atom declared in an earlier determination. This is an opposite search bias to the Imparo's preference over the later mode declarations.

\section{Tal's capabilities}

\subsection{Multiple solutions}
A hypothesis that can solve the problem of induction may be called a solution. Tal can output multiple solutions to a given learning problem with the corresponding scores.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(woman(+person), [name(wh)]).
modeb(female(+person), [name(fb)]).
modeb(male(+person), [name(mb)]).

%Examples
example(woman(alice), 1).
example(woman(ann), 1).
example(woman(susan), 1).
example(woman(adam), -1).
example(woman(bob), -1).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(ann).
person(susan).
person(adam).
person(bob).

%Background knowledge
female(ann).
female(susan).
male(adam).
male(bob).
\end{lstlisting}
\end{minipage}


returns solutions
\begin{lstlisting}
1. woman(A). %score 0
2. woman(A) :- female(A). %score -1
\end{lstlisting}

The score function is customizable, more can be found in Tal's documentation.

\subsection{Multi-clausal hypothesis}
Tal can learn a hypothesis that consists of multiple clauses.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%Background knowledge
female(ann).
female(susan).
male(adam).
male(bob). 
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(woman(ann), 1).
example(woman(susan), 1).
example(woman(adam), -1).
example(woman(bob), -1).
example(man(adam), 1).
example(man(bob), 1).
example(man(ann), -1).
example(man(susan), -1).
\end{lstlisting}
\end{minipage}

returns solutions

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
1. woman(_).
2. woman(A) :- female(A).
3. woman(A) :- female(A).
   man(_).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
4. woman(A) :- female(A).
   man(A) :- male(A).
5. man(A) :- male(A).
   woman(A) :- female(A).
\end{lstlisting}
\end{minipage}

\begin{lstlisting}
\end{lstlisting}

Particularly, we observe that the 5th solution consists of two clauses.

\subsection{Term structure learnability}
Tal can learn the hypotheses whose terms contain function symbols.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
modeh(woman(sister(+person)), [name(wh)]).
modeb(anybody(+person), [name(wb)]).

%Examples
example(woman(sister(bob)), 1).
example(woman(sister(jane)), 1).
example(woman(sister(susan)), 1).
example(woman(sister(frog)), -1).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jane).
person(bob).
person(susan).

%Background knowledge
anybody(jane).
anybody(susan).
anybody(bob).
\end{lstlisting}
\end{minipage}

returns solutions

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
1. woman(sister(_)).
2. woman(sister(A)) :- anybody(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
3. woman(sister(_)).
   woman(sister(A)) :- anybody(A).
4. woman(sister(A)) :- anybody(A).
   woman(sister(_)).
\end{lstlisting}
\end{minipage}

in which hypotheses contain a function symbol \tc{sister}.

\subsection{Multi-clausal concepts}
Tal can learn a hypothesis that needs more that one clause to explain the examples.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%Background knowledge
female(jane).
female(susan).
female(eugenia).
couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).
male(X) :- couple(X,Y), woman(Y).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(man(jack),1).
example(man(martin),1).
example(woman(jane),1).
example(woman(susan),1).
example(man(jane),-1).
example(woman(sam),-1).
\end{lstlisting}
\end{minipage}

has amongst its solutions a hypothesis
\begin{lstlisting}
woman(A) :- female(A).
man(A) :- male(A).
\end{lstlisting}
To explain the \tc{man} predicate examples we needed to learn a two clausal hypothesis. In comparison, Toplog and Aleph cannot learn multi-clausal concepts, but Imparo can.

\subsection{Specialization in arguments}
Tal can learn hypothesis which require ground terms to be in a head predicate.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(learns(+person, +subject)).
modeh(learns(#person, +subject)).

%background
male(adam).
male(bob).
female(alice).
female(mary).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
learns(polymath, mathematics).
learns(polymath, physics).
learns(polymath, chemistry).
learns(jack, mathematics).
learns(susan, physics).

%negative examples
:- learns(jack, physics).
:- learns(susan, chemistry).
\end{lstlisting}
\end{minipage}

has amongst its solutions
\begin{lstlisting}
(learns(polymath,_E):-true.
\end{lstlisting}
which has a constant \tc{polymath} as a first argument and a variable as a second argument.
\subsection{Other capabilities}
Tal can impose the bias on the hypotheses space by user-specified integrity constraints. Tal has several hypothesis searching strategies specifying a score function on the criteria of heuristics, termination, solution score; and search algorithms, e.g. breadth first search. More information can be found in Tal's manual.

\section{Tal's assumed limitations}

\subsection{Correct example bias}
Tal returns the examples as a hypothesis only if the predicate for the ground instances is specified in the mode declarations.

\begin{minipage}[t]{.55\textwidth}
\begin{lstlisting}
modeb(female(+person), [name(fb)]).

%Background knowledge
female(alice).
male(adam).male(bob).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(woman(alice), 1).
example(woman(adam), -1).
example(woman(bob), -1).
\end{lstlisting}
\end{minipage}

returns no solutions as required since the head mode declaration is empty. However, systems like Toplog and Imparo would violate the constrains imposed by defining the search space and would return the examples.
To accept examples as possible hypotheses in Tal, one can define constant symbols in the mode declarations with a \# symbol.

\begin{minipage}[t]{.55\textwidth}
\begin{lstlisting}
modeh(woman(#person), [name(wh)]).
modeb(female(+person), [name(fb)]).

%Background knowledge
female(alice).
male(adam).
male(bob).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(woman(alice), 1).
example(woman(adam), -1).
example(woman(bob), -1).
\end{lstlisting}
\end{minipage}

returns a solution \tc{woman(alice).} which is an original positive example. Consequently, Tal does not suffer from the default example bias present in the systems Toplog, Imparo and Aleph.

\subsection{Other assumed limitations}
Tal cannot learn the negative examples. It can learn only Horn theories. Tal assumes the consistency of the background knowlege, the consistency of the examples and the consistency of the background knowledge with the examples. Tal can accept only examples in the form of a literal, not a general clause.

\section{Tal's violations and biases}

\subsection{Solution redundancy}
Tal returns duplicate hypotheses as solutions.

\begin{minipage}[t]{.65\textwidth}
\begin{lstlisting}
modeh(woman(sister(+person)), [name(wh)]).
modeb(anybody(+person), [name(wb)]).

%Examples
example(woman(sister(bob)), 1).
example(woman(sister(jane)), 1).
example(woman(sister(susan)), 1).
example(woman(sister(frog)), -1).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
person(jane).
person(bob).
person(susan).

%Background knowledge
anybody(jane).
anybody(susan).
anybody(bob).
\end{lstlisting}
\end{minipage}

returns solutions

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
1. woman(sister(_)).
2. woman(sister(A)) :- anybody(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
3. woman(sister(_)).
   woman(sister(A)) :- anybody(A).
4. woman(sister(A)) :- anybody(A).
   woman(sister(_)).
\end{lstlisting}
\end{minipage}

Notice that the 3rd and the 4th solutions are equivalent, the only difference is the order of the hypotheses returned in the solution. Moreover, \tc{woman(sister(\_))} subsumes the clause\\
\tc{woman(sister(A)):-anybody(A).}. Hence the 3rd solution is equivalent to the 1st one.

\subsection{No generalization downwards}
Tal cannot learn the hypotheses of the form $P(s(x)) \metaImplies P (x)$.
\begin{lstlisting}

\end{lstlisting}

\begin{minipage}[t]{.65\textwidth}
\begin{lstlisting}
modeh(numeral(+number), [name(nh)]).
modeb(numeral(+number), [name(nb)]).
modeb(numberal(s(+number)), [name(nsb)]).
modeb(numeral(s(s(+number))), [name(nssb)]).

%Examples
example(numeral(0),1).
example(numeral(s(0)),1). 
example(numeral(s(s(0))),1).
example(numeral(s(s(s(0)))),1).
example(numeral(s(not_number)),-1).
example(numeral(s(s(s(not_number)))),-1).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
number(0).
number(s(X)).

%Background knowledge
numeral(s(s(s(s(0))))).
\end{lstlisting}
\end{minipage}

returns solutions
\begin{lstlisting}
1. numeral(_).
2. numeral(A) :- numeral(s(s(A))).
3. numeral(A) :- numeral(A).
\end{lstlisting}
and then starts outputting a solution of the form
\begin{lstlisting}
[(numeral(s(s(s(s(s(s(s(s(...
\end{lstlisting}
getting into a loop outputting the successor symbols $s$. Clearly, our expected hypothesis \tc{numberal(X) :- numberal(s(X)).} was not learnt.

In cases of different downwards examples, Tal may not loop, however it would not produce the expected generalization either.

\begin{lstlisting}
modeh(even(+number), [name(eh)]).
modeb(even(+number), [name(eb)]).
modeb(even(s(+number)), [name(esb)]).
modeb(even(s(s(+number))), [name(essb)]).

number(N).

%Background knowledge
even(s(s(s(s(s(s(s(s(0))))))))).

%Examples
example(even(0),1).
example(even(s(s(0))),1).
example(even(s(s(s(s(0))))),1).
example(even(s(s(s(s(s(s(0))))))),1).
example(even(s(0)),-1).
example(even(s(s(s(0)))),-1).
\end{lstlisting}

produces a hypothesis \tc{even(\_).} which is inconsistent with the negative examples. The target hypotheses \tc{even(A) :- even(s(s(A))).} was not learnt.

\subsection{Loop on learning regular languages}
Just as the generalization downwards example caused Tal looping, generalization forward, i.e. learning a hypothesis of the form $P(x) \objectImplies P(s(s(x))$ (a regular language \tc{(ss)*}) can cause Tal looping.
\begin{lstlisting}
modeh(in_language(s(s(+word))), [name(issh)]).
modeh(in_language(s(+word)), [name(ish)]).
modeb(in_language(+word), [name(ib)]).

word(X).

%Background
in_language(epsilon).
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).

%Examples
example(in_language(s(s(epsilon))),1).
example(in_language(s(s(s(s(epsilon))))),1).
example(in_language(s(epsilon)),-1).
example(in_language(s(s(s(epsilon)))),-1).
\end{lstlisting}

returns solutions
\begin{lstlisting}
1. in_language(s(_)).
   in_language(s(s(A))) :- in_language(A).
2. in_language(s(A)) :- in_language(A).
\end{lstlisting}
and subsequently loops outputting \tc{[(in\_language(s(s(s(s...} as before.
Notice that a target hypothesis 2. was learnt, but Tal did not manage to terminate. One can imagine a situation in which a correct hypothesis would be learnt after the infinite loop completes which is impossible.

\subsection{Weak head mode declaration}
As in Aleph and Imparo, a head mode declaration in Tal allows only definitions with specific term structure as opposed to the ability to substitute a variable for any term.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(woman(+person), [name(wh)]).
modeb(anybody(+person),[name(ab)]).

%Background theory
anybody(jane).
anybody(jack).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Example
example(woman(sister(jane)),1).
example(woman(sister(jack)),1).
example(woman(sister(frog)),-1).
example(woman(sister(cat)),-1).
\end{lstlisting}
\end{minipage}

returns a solution \tc{woman(\_).}, however one would require the solution \tc{woman(sister(A)) :- anybody(A).} with the predicate symbol \tc{sister} included to be returned since the later solution correctly explains the positive examples and is consistent with the negative ones, the earlier one is not. But this hypothesis can be only learnt by adding the function symbol \tc{sister} explicitly in the head mode declaration \tc{modeh(woman(sister(+person)), [name(wsh)]).}.

\subsection{Alphabetical term bias}
Tal search is biased on the alphabetical order of the terms present in the predicates.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(woman(+person), [name(wh)]).
modeh(man(+person), [name(mh)]).
modeb(female(+person), [name(fb)]).
modeb(male(+person), [name(mb)]).

%Background
male(adam).
female(alice).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(woman(alice), 1).
example(man(adam), 1).
example(woman(adam), -1).
example(man(alice), -1).
\end{lstlisting}
\end{minipage}

returns solutions

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
1. man(_).
2. man(A) :- male(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
3. man(A) :- male(A).
   woman(_).
4. man(A) :- male(A).
   woman(A) :- female(A).
\end{lstlisting}
\end{minipage}

However, if we rename the term \tc{adam} to a term that is alphabetically greater than \tc{alice} then a predicate \tc{female} occurs in a greater proportion of solutions than in the previous ones.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%Background
male(zygo).
female(alice).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Examples
example(woman(alice), 1).
example(man(zygo), 1).
example(woman(zygo), -1).
example(man(alice), -1).
\end{lstlisting}
\end{minipage}

produces solutions

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
0. woman(_).
1. woman(A) :- female(A).
2. woman(_).
   man(_).
3. woman(A) :- female(A).
   man(_).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
4. woman(_).
   man(A) :- male(A).
5. woman(A) :- female(A).
   man(A) :- male(A).
\end{lstlisting}
\end{minipage}

Other interesting change is the increase in the number of the solutions from 4 to 5. In the author's opinion the hypotheses produced should be independent of the description language chosen and therefore alphabetical term bias represents a violation of the ILP problem.

\subsection{Other violations and biases}
One may argue that returning multiple solutions does not solve the inductive learning problem if the definition allows only one such hypothesis to be learnt. We could think of solutions as their disjunction, however such a disjunction does not have a short description, a frequent requeriment of a produced hypothesis. As mentioned earlier, Tal learns hypotheses inconsistent with the background knowledge and the observations, therefore Tal is not sound.

\section{Xhail's capabilities}

\subsection{Background knowledge generalization}
Like Progol, Xhail does not distinguish between the examples and the background knowledge. It tries to generalize the background knowledge to learn a hypothesis specified by the mode declarations criteria.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,1,min,block("+a")).
modeb(1,1,neg,c("+a")).
modeb(1,1,pos,c("+a")).
modeb(1,1,pos,d("+a")).
modeb(1,1,neg,d("+a")).
modeb(1,1,pos,eql("+a","#a")).
modeb(1,1,neg,eql("+a","#a")).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
a(0 ; 1).
c(0).
d(1).
p(X) :- a(X), not block(X).
g :- p(0), not p(1).
goal(g).
eql(X,Y) :- X==Y,a(X),a(Y).
\end{lstlisting}
\end{minipage}

produces hypotheses
\begin{lstlisting}
1. block(X1) :- not c(X1),d(X1),eql(X1,1),not eql(X1,0),a(X1). ([X1/1])
2. block(X1) :- not eql(X1,0),a(X1).
3. block(X1) :- not c(X1),a(X1).
4. block(X1) :- eql(X1,1),a(X1).
5. block(X1) :- d(X1),a(X1).
\end{lstlisting}
where the head of the hypotheses is \tc{block}, however, we can notice that there are no examples in the background knowledge with \tc{block} predicate. Moreover, the only occurance of \tc{block} is in the body as a negation as failure literal \tc{not block(X)}.

If one wanted to translate learning from examples problem into the Xhail's learning problem, positive and negative examples could be placed in a goal:

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,10,max,woman("+person")).
modeb(0,10,pos,female("+person")).

person(susan; adam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
female(susan).
male(adam).
goal(g).
g:- woman(susan), not woman(adam).
\end{lstlisting}
\end{minipage}

where \tc{woman(susan)} is a positive example and a \tc{woman(adam)} is a negative example. The hypothesis learnt is
\tc{woman(X1) :- female(X1), person(X1).}.

\subsection{Multiple hypotheses}
Like Tal, Xhail returns multiple possible hypotheses (or solutions) for a given learning problem.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,1,pos,e).
modeb(0,1,pos,a).
modeb(0,1,pos,b).
find(all).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%background
a.
b.
e.
\end{lstlisting}
\end{minipage}

returns the hypotheses

\begin{minipage}[t]{.25\textwidth}
\begin{lstlisting}
1. e :- true.
2. e :- b.
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
3. e :- a.
4. e :- a,b.
\end{lstlisting}
\end{minipage}

\subsection{Multi-clausal hypotheses}
Xhail can learn a hypothesis that consists of multiple clauses:

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,10,all,woman("+person")).
modeh(0,10,all,man("+person")).
modeb(0,10,pos,female("+person")).
modeb(0,10,pos,male("+person")).

g:- woman(susan), not woman(adam), man(adam), not man(susan).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
goal(g).
person(susan; adam).
female(susan).
male(adam).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
man(X1):-male(X1), person(X1).
woman(X1):-female(X1), person(X1).
\end{lstlisting}.
One clause would be insufficient to explain both \tc{man} and \tc{woman} examples.

\subsection{Fine search space control}
Xhail has extended mode declarations to refine its search space. Xhail's help reads:

\emph{Zero or more head declarations} are of the form
\tc{modeh(1,3,min,p("\#q","+r","-s")).} meaning between 1 and 3 ground atoms
 of the form $p(a,b,c)$ should be assumed such that $q(a), r(b), s(c)$ hold 
 and where $a, b, c$ are constant, input, output terms, respectively;
 the third flag is either min="attempt to minimize" or all="do not minimize".
 
\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,1,all,woman("+person")).
modeb(0,1,pos,female("+person")).
person(susan; ruth; adam).

goal(g).
g:- woman(susan), woman(ruth), not woman(adam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Background
female(susan).
female(ruth).male(adam).
\end{lstlisting}
\end{minipage}

returns no hypothesis. However, placing only one positive example in a goal
\tc{g:- woman(susan), not woman(adam).} or modifying the modeh declaration to cover the two positive examples\\
\tc{modeh(0,2,all,woman("+person")).} makes Xhail to learn a hypothesis\\
\tc{woman(X1):-female(X1),person(X1).}.

\emph{Zero or more body declarations} are of the form \tc{modeb(1,3,pos,p("\#q","+r","-s")).} meaning this scheme can be used between 
 depths 1 and 3.  The third flag is either pos="pos. literal" or neg="neg. literal" 

Apart from the mode declarations, additional control has been introduced with \tc{goal}, \tc{find}, \tc{task} statements:
\emph{Zero or more goal statement} of the form \tc{goal(a).} means to only compute models satisfying the ground atom \tc{a}.

\emph{Zero or one find statement} is of the form \tc{find(all)="all solutions"} or \tc{find(min)="minimal solutions"}.

\emph{Zero or one task declarations} are possible, e.g. \tc{task(abduce).} or \tc{task(induce).}.

\subsection{Learning by integrity constrains}
Xhail can learn from the background knowledge in a form of integrity constrains.

\begin{minipage}[t]{.30\textwidth}
\begin{lstlisting}
modeh(0,1,all,a).
modeh(0,1,all,r).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
goal(p).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
p :- r.
false :- p, not a.
\end{lstlisting}
\end{minipage}

returns a hypothesis \tc{a:-true. r:-true.} where in the learning problem
\tc{false :- p, not a.} represents an integrity constraint.

\subsection{Term structure learnability}
Xhail can learn the hypotheses whose terms contain function symbols.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
modeh(0,10,all,woman(sister("+a"))).
modeb(0,10,pos,anybody("+a")).

a(susan; adam; frog).
anybody(susan; adam).
goal(g).
g:- woman(sister(susan)), woman(sister(adam)), not woman(sister(frog)).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
female(susan).
male(adam).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\tc{woman(sister(X1)):-anybody(X1), a(X1).}.
\subsection{Other capabilities}
Xhail can learn a hypothesis which requires ground terms to be in a head predicate by specifying such a hypothesis with the constant type \tc{\#type} in mode declarations. Xhail supports hypotheses containing predicates of arities greater than 1.

\section{Xhail's assumed limitations}

\subsection{Partial explanations impossible}
Xhail cannot learn a hypothesis that explains some positive examples, but not all.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
modeh(0,10,all,woman("+person")).
modeb(0,10,pos,female("+person")).
person(susan; ruth; adam).
goal(g).
g:- woman(susan), woman(ruth), not woman(adam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
female(susan).
male(adam).
\end{lstlisting}
\end{minipage}

returns no hypothesis.Although a hypothesis
\tc{woman(X1):-female(X1),person(X1).} cannot explain the example \tc{woman(ruth).} it would be able to explain the example \tc{woman(susan)}.

In comparison, Aleph can learn partial hypotheses: from the background knowledge\\
\tc{female(alice).female(mary).}, positive examples \tc{woman(alice).woman(mary).woman(susan).}, negative examples \tc{woman(adam).} Aleph includes in its hypothesis a partial explanation
\tc{woman(A) :- female(A).}.

\subsection{Learning from clausal examples}
Since Xhail learns from the background knowledge like Progol does, we would expect it would be able to generalize from the clausal examples too. However, this is not the case (TODO verify Progol can learn from clauses without the female instances):

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
modeh(0,10,all,woman("+person")).
modeb(0,10,pos,female("+person")).
goal(g).
person(susan; ruth; adam).
g:- woman(susan), woman(ruth), not woman(adam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
woman(susan):-female(susan).
woman(ruth):-female(ruth).
male(adam).
\end{lstlisting}
\end{minipage}

does not produce any hypothesis, however a general hypothesis\\
\tc{woman(X1) :- female(X1), person(X1).} could have been induced to generalise its two ground instances present in the background knowledge.

\subsection{Inability to learn from unrestricted clauses}
Xhail requires that all its clauses are restricted by ground instances - a quantification over all possible ground instances in a domain is not possible.

An attempt to define that everybody in a domain is of type person fails. \tc{person(X1).} returns an error "a non-ground fact person(X1). All terms within a fact must be ground terms." For a clause \tc{person(X1) :- true.} an error message "Unrestricted variable X1." is produced. Therefore we always have to ground the clauses (containing variables) in Xhail, for example
\tc{grounded(susan; adam).person(X1) :- grounded(X1).} does not produce any complaints.

This has an impact that the learning space is finite - every possible inducible model is a finite set of ground instances. Therefore, multiple learning problems cannot be learnt: generalization downwards, generalization upwards, Kleene star learning, learning a concept of a natural number, etc. because for these the Hebrand models are infinite subsets of the Herbrand base of the Hebrand universe with the function symbols.

\section{Xhail's violations and biases}

\subsection{Implicit consistency check}
Xhail does not explicitly report that the learning problem is inconsistent, it only outputs "NO SOLUTIONS" message which is also applicable for consistent problems whose model is not in the specified search space.

\subsection{Redundant hypotheses}
Xhail returns multiple hypotheses even if they are the same.

\begin{minipage}[t]{.43\textwidth}
\begin{lstlisting}
modeh(1,3,min,fries("+food")).
modeb(1,3,neg,offer("+food")).
modeb(1,3,pos,offer("+food")).
modeb(1,3,neg,bistro("+food")).
modeb(1,3,pos,bistro("+food")).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
goal(g).
food(md ; bk ; rz).
bistro(md ; bk ; rz).
offer(md ; bk).
meal(X):- food(X),fries(X), burger(X).
burger(X):- food(X), fries(X), offer(X).
g:- meal(md), meal(bk), not meal(rz).
\end{lstlisting}
\end{minipage}

returns the hypotheses

\begin{lstlisting}
1. fries(X1) :- food(X1).
2. fries(X1) :- food(X1).
\end{lstlisting}
where the 1st and the 2nd hypotheses are the same. Notice, a general hypothesis has been induced for every example, both \tc{md} and \tc{bk}.

\subsection{Other violations and biases}
Since Xhail learns multiple solutions, the hypotheses space is not biased towards the order of the mode declarations.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(0,10,max,woman("+person")).
modeb(0,10,pos,female("+person")).
modeb(0,10,pos,cook("+person")).

g:- woman(susan), not woman(adam).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
goal(g).
person(susan; adam).
female(susan).
cook(susan).
male(adam).
\end{lstlisting}
\end{minipage}

returns two hypotheses
\tc{1. woman(X1):-cook(X1), person(X1). 2. woman(X1):-female(X1), person(X1).}. In other systems a preference over the hypotheses is induced based on the order of the hypotheses' predicates \tc{cook(X1), female(X1)} in their modeb and determination declarations.

\section{Progol's capabilities}

\subsection{Specialization in arguments}
Progol can learn hypothesis which require ground terms to be in a head predicate.

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
modeh(learns(+person, +subject)).
modeh(learns(#person, +subject)).

%background
male(adam).
male(bob).
female(alice).
female(mary).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
learns(polymath, mathematics).
learns(polymath, physics).
learns(polymath, chemistry).
learns(jack, mathematics).
learns(susan, physics).

%negative examples
:- learns(jack, physics).
:- learns(susan, chemistry).
\end{lstlisting}
\end{minipage}

returns hypotheses
\begin{lstlisting}
learns(polymath,A).
learns(jack,mathematics).
learns(susan,physics).
\end{lstlisting}
containing a general hypothesis \tc{learns(polymath,A)} that has a constant \tc{polymath} as a first argument and a variable as a second argument.

\subsection{Multi-clausal learning}
Progol can learn several one-clausal hypotheses at one time.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person))?
:-modeh(*, man(+person))?
:-modeb(*, male(+person))?
:-modeb(*, female(+person))?
:- determination(man/1,male/1)?
:- determination(woman/1,female/1)?

%background
male(bob).
male(tom).
female(ann).
female(mary).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
woman(ann).
woman(mary).
man(bob).
man(tom).

%negative examples
:-man(ann).
:-man(mary).
:-woman(bob).
:-woman(tom).
\end{lstlisting}
\end{minipage}

returns hypotheses

\begin{lstlisting}
woman(A) :- female(A).
man(A) :- male(A).
\end{lstlisting}

Note, this is possible in Imparo and in Aleph, but not in Toplog.

\subsection{Term structure learnability}
Progol can learn the hypotheses whose terms contain function symbols.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, woman(sister(+person)))?
:-modeb(*, anybody(+person))?
:-determination(woman/1, anybody/1)?

anybody(jane).
anybody(susan).
anybody(bob).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
woman(sister(bob)).
woman(sister(jane)).
woman(sister(susan)).

%negative examples
:-woman(sister(frog)).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
woman(sister(A)) :- anybody(A).
\end{lstlisting}
In comparison, Imparo and Aleph can learn the term structure but Toplog cannot.

\subsection{Learnability of multi-clausal concepts}
Progol can explain observations for which there does not exist a one-clausal explanation by inducing a multi-clausal hypothesis.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, woman(+person))?
:-modeh(*, man(+person))?
:-modeb(*, male(+person))?
:-modeb(*, female(+person))?
:- determination(woman/1, female/1)?
:- determination(man/1, male/1)?

female(jane).
female(susan).
female(eugenia).
couple(jack, jane).
couple(sam, susan).
couple(martin, eugenia).
male(X) :- couple(X,Y), woman(Y).\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
man(jack).
man(martin).
woman(jane).
woman(susan).

%negative examples
:-man(jane).
:-woman(sam).
\end{lstlisting}
\end{minipage}

produces the hypotheses
\begin{lstlisting}
woman(A):-female(A).
man(A):-male(A).
\end{lstlisting}.

To learn the hypothesis \tc{man(A):-male(A)} from the background knowledge and the observations we have to use the predicate \tc{male(X) :- couple(X,Y), woman(Y).}, but this requires the knowledge of who is a woman, which can be only acquired by inducing a second hypothesis \tc{woman(A):-female(A)}. Therefore, the concept learnt by Progol requires at least two clauses.

\subsection{Clausal examples}
Progol can learn from the observations that are general Horn clauses not limited to literals.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, man(+person))?
:-modeb(*, male(+person))?
:- determination(man/1, male/1)?

%positive examples
man(jack) :- male(jack).
man(sam) :- male(sam).
man(john) :- male(john).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%background
male(jack).
male(sam).
male(john).
male(tristan).
female(glory).

%negative examples
:- man(glory).
\end{lstlisting}
\end{minipage}

produces the expected general hypothesis
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}

Other systems like Aleph, Imparo, Tal, Toplog accept only examples in a literal form.

\subsection{Other capabilities}
Progol can induce hypotheses that contain predicates of arity greater than 1. Progol checks for inconsistency of the observations with the background knowledge and provides an appropriate warning about the contradiction that false is provable.

\section{Progol's assumed limitations}

\subsection{Other limitations}
Progol can learn positive examples, but cannot learn the negative ones. Like Aleph, Progol requires determinations to specify its hypotheses space in addition to the specification by mode declarations. Progol has a weak-head mode declaration, we have to explicitly specify the function symbol in the mode declarations, a specification of a general function symbol pattern is not possible. Progol has a correct example bias - it can learn examples only if these are specified in the mode declarations. Progol can learn only the Horn theories.

\section{Progol's violations and biases}
\subsection{No generalization downwards}
Progol cannot learn the hypotheses of the form $P(s(x)) \objectImplies P(x)$.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, even(+number))?
:-modeb(*, even(+number))?
:-modeb(*, even(s(+number)))?
:-modeb(*, even(s(s(+number))))?
:- determination(even/1, even/1)?

%background theory
even(s(s(s(s(s(s(s(s(0))))))))).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
even(0).
even(s(s(0))).
even(s(s(s(s(0))))).
even(s(s(s(s(s(s(0))))))).

%negative examples
:-even(s(0)).
:-even(s(s(s(0)))).
\end{lstlisting}
\end{minipage}

produces a hypothesis
\begin{lstlisting}
even(A).
\end{lstlisting}
which is inconsistent with the negative examples.

\subsection{Unlearnability of regular languages}
Although Progol can learn a simple term structure, it cannot learn more complex concepts like a regular language represented by regular expression \tc{(ss)*}.

\begin{lstlisting}
:-modeh(*, in_language(s(s(+word))))?
:-modeh(*, in_language(s(+word)))?
:-modeb(*, in_language(+word))?
:- determination(in_language/1, in_language/1)?

%background theory
in_language(epsilon).
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).
\end{lstlisting}

\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}
%positive examples
in_language(s(s(epsilon))).
in_language(s(s(s(s(epsilon))))).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%negative examples
:-in_language(s(epsilon)).
:-in_language(s(s(s(epsilon)))).
\end{lstlisting}
\end{minipage}

returns back a hypothesis
\begin{lstlisting}
in_language(s(s(A))).
\end{lstlisting}
which is inconsistent with the negative examples.

A general consistent hypothesis representing the language is
\begin{lstlisting}
in_language(s(s(A)) :- in_language(A).
\end{lstlisting}

\subsection{Preference over earlier mode declarations}
Progol prefers learning a hypothesis whose mode declaration has been defined earlier.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, man(+person))?
:-modeb(*, bridegroom(+person))?
:-modeb(*, male(+person))?
:- determination(man/1, bridegroom/1)?
:- determination(man/1, male/1)?

%positive examples
man(jack).
man(sam).
man(john).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%Background theory
bridegroom(jack).
bridegroom(sam).
bridegroom(john).
male(jack).
male(sam).
male(john).

%negative examples
:- man(susan).
\end{lstlisting}
\end{minipage}

returns a hypothesis
\begin{lstlisting}
man(A) :- bridegroom(A).
\end{lstlisting}

Changing the order of the mode declarations to
\begin{lstlisting}
:-modeb(*, male(+person))?
:-modeb(*, bridegroom(+person))?
\end{lstlisting}
results in a hypothesis
\begin{lstlisting}
man(A) :- male(A).
\end{lstlisting}
In both cases, the induced hypothesis had a body atom declared in an earlier mode declaration. This is an opposite search bias to the Imparo's preference over the later mode declarations.

\subsection{Background knowledge hypotheses}
Progol explains the examples with the background knowledge even if the mode declarations do not allow such explanations in the language bias.

\begin{minipage}[t]{.60\textwidth}
\begin{lstlisting}
:-modeh(*, female_person(+person))?
:-modeb(*, female(+person))?

%background theory
female(jane).
female(susan).
woman(A) :- female_person(A).
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{.20\textwidth}
\begin{lstlisting}
%positive examples
woman(jane).
woman(susan).
female_person(jane).
female_person(susan).

%negative examples
:-female_person(sam).
\end{lstlisting}
\end{minipage}

returns the hypotheses
\begin{lstlisting}
female_person(A) :- female(A).
woman(A) :- female_person(A).
\end{lstlisting}
But notice that \tc{woman(A) :- female\_person(A)} cannot be derived from the mode declarations. Therefore Progol has a default background knowledge bias.

\subsection{Other violations and biases}
If examples are allowed in a head mode declaration, then no general hypothesis is learnt, only examples.