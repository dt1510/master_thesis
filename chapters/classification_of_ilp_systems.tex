\chapter{Classification of ILP systems}\label{chap:classification_of_ilp_systems}

In the chapter \nameref{chap:issues_in_ilp} we analysed the central issues in ILP by providing a brief explanation of an importance of an issue and a list of the properties defining an issue. In this chapter we classify ILP systems and theoretical frameworks based on the use of the defining properties to approach solving a particar issue.

We will define an ILP task $I \mapsto O$ by its space of possible inputs $I$ and the decription of the desired output $O$. Thus an ILP task is a \emph{function problem} as opposed to a decision problem. We think of an ILP system solving such an ILP task as an \emph{algorithm} computing the function $I \mapsto O$.

\section{ILP task definition}
In \nameref{sec:ilp_task_definition} of the chapter \nameref{chap:issues_in_inductive_logic_programming} we presented machine learning problems: generalization and explanatory induction; together with the properties expressivity, positive examples, negative examples, semantics.

Although on the surface there may seem to be a standard definition of an ILP task, in this section we demonstrate that when specifying an ILP task completely, each ILP system classified solves a different learning problem. This mutual incompatibility has a major impact how we can assess, compare and classify ILP systems.

We explain the importance of defining an ILP task completely, present building blocks for a definition of an ILP task, construct an ILP definition for each ILP system, classify the ILP systems based on an ILP task they solve and lastly provide a generalized unifying definition of an ILP task for all assessed ILP systems to lay the ground for their comparisons and classification in the subsequent chapters.

\subsection{Importance of complete definitions}
Since an ILP task is a function problem $f:I \mapsto O$ for a specified input $I$ and a corresponding output $O$, its incomplete definition may not specify a \emph{unique deterministic function} $f$. An example of an incomplete definition is explanatory induction: given $I=\langle B, E \rangle$ find a correct $O=H$, i.e. satisfying
$E \in Cn(B \cup H)$ and $false \not\in Cn(B \cup H)$.
\begin{exmp}\label{explanatory_induction_definition_incompleteness}
Let $E=\{mortal(aristotle)\}$, $B=\{man(aristotle)\}$,
$H_1=E$, $H_2=\{mortal(aristotle) \leftObjectImplies man(aristotle)\}$.
Then both $H_1$, $H_2$ are correct hypotheses explaining $E$ from $B$. Therefore there are at least 2 different functions $\langle B, E \rangle \mapsto H_1$ and
$\langle B, E \rangle \mapsto H_2$ specifying the output $O=H$.
\end{exmp}

The importance of an issue of an incomplete definition becomes apparent when defining a non-ILP function problem as our mind is not biased towards the acceptance of the incompleteness of a definition encountered in the ILP literature.

\begin{exmp}
Define a function problem $f:I \mapsto O$ by given an odd number, find an even number. Then constant functions $f_2:I \mapsto 2$, $f_4:I \mapsto 4$, ..., functons $g_1:I \mapsto I+1$, $g_3:I \mapsto I+3$ and many others are compatible with an incomplete definition of a function $f$. However, when the definition of a function problem is completed to given an odd number $I$ to find smallest even number greater than $I$, then unambiguously $f=g_1$.
\end{exmp}

Not specifying an ILP task completely may result in designing an ILP system solving a different function problem than the one intended.

\subsection{Buildings blocks of ILP task definition}\label{subsec:building_blocks_of_ilp_task_definition}
In this subsection we define an ILP task definition, instantiate the definition with an ILP task of generalization, extend the definition of generalization by the notions encountered in ILP tasks of ILP systems we classify. The objective of this subsection is to enumerate the building blocks of an ILP task definition and the rules that make the definition more complete from which we can construct definitions of ILP tasks and classify their respective ILP systems later.

\begin{defn}\label{ilp_task_definition}
An \emph{ILP task definition} is a tuple $D=\langle f, dom(f), cod(f), R \rangle$ where a (possibly non-deterministic) function $f$ is called an \emph{ILP task}, $dom(f)$ is a set of \emph{inputs} vectors
$I=\langle \overrightarrow{i} \rangle$, $cod(f)$ is a set of \emph{output} vectors $O=\langle \overrightarrow{o} \rangle$ and $R$ is a set of rules (logical sentences) defining $f$,
i.e. $O \in f(I) \iff R \cup \{O \in f(I)\} \not\models false$ for a classical consequence operator $\models$. A vector component of an input(output) vector $\overrightarrow{i}$($\overrightarrow{o}$) is called an \emph{input component}(\emph{output component}) of an ILP task $f$. A \emph{structure component} of an ILP task is its input or output component. A \emph{rule} of an ILP task is a formula $\phi \in R$.
\end{defn}

\begin{remark}
We will often specify $R$ only by its subset of sentences and the rest will be specified informally or expected from the reader to be deduced from the context in order to avoid unnecessarily long specifications of $R$ and the lost of the focus. We may specify directly a possible input vector $I$ without specifying $dom(f)$ explicitly, it is be understood that $dom(f)$ is a set of all such input vectors $I$. Similarly, $cod(f)$ is a set of all possible output vectors $O$. The notation is abused for vectors with one element, e.g. $H=\langle H \rangle$.
\end{remark}

\begin{exmp}
The definition of explanatory induction is $D=\langle f, dom(f), cod(f), R \rangle$ where $I=\langle B, E \rangle$, $O=H$, $R=\{E \subseteq Cn(B \cup H), false \not\in Cn(B \cup H)\}$ for some consequence operator $Cn$. Input components of explanatory inductions are $B, E$. A hypothesis $H$ is an output component of explanatory induction.
\end{exmp}

\subsubsection{Completeness of definitions of ILP task}
By the example \fullref{explanatory_induction_definition_incompleteness} the definition of explanatory induction does not specify a unique deterministic ILP task, we say such a definition is incomplete.

\begin{defn}
A definition $D=\langle f, dom(f), cod(f), R \rangle$ is a \emph{complete ILP task definition} iff $f:I \mapsto O$ is deterministic. $D$ is \emph{incomplete} iff $D$ is not complete.
\end{defn}

Since an incomplete definition results in an ambiguous ILP task definition it will be in our interest to make the definitions more complete by introducing additional rules defining an ILP task.

\begin{defn}
Let $f:X \mapsto Y$ be a (possibly non-deterministic) function, we say that a (possibly non-deterministic) function $g:X \mapsto Y$ is a \emph{possible function} of $f$ iff
$\forall x \in X. g(x) \subseteq f(x)$. We denote the set of all possible functions of $f$ by $\Box f$.
\end{defn}

\begin{remark}
The only possible function of a deterministic function is the function itself, i.e. $\Box f = \{f\}$.
\end{remark}

\begin{defn}
A definition $D_1=\langle f_1, dom(f_2), cod(f_2), R \rangle$ is \emph{more complete} than the definition $D_2=\langle f_1, dom(f_2), cod(f_2), R \rangle$ iff
$f_2$ is a possible function of $f_1$.
\end{defn}

\begin{corollary}\label{corollary_more_complete_1}
Let $D_1=\langle f_1, \mathcal{I}, \mathcal{O}, R_1 \rangle$, $D_2=\langle f_2, \mathcal{I}, \mathcal{O}, R_2 \rangle$ be definitions of an ILP task.
If $R_2 \models R_1$, then $D_2$ is more complete than $D_1$.
\end{corollary}

\begin{proof}
Follows directly from the definitions.
\end{proof}

\subsubsection{Extension of ILP task definition}
To provide a more accurate and complete specification of an ILP task, its definition can be extended.

\begin{defn}\label{definition_ilp_task_definition_extension}
Let $D_1=\langle f_1, \mathcal{I}_1, \mathcal{O}_1, R_1 \rangle$ be a definition of an ILP task. A definition $D_2=\langle \mathcal{I}_2, \mathcal{O}_2, R_2 \rangle$ is an \emph{input component extension}(\emph{output component extension}) of a definition $D_1$ iff $\langle \overrightarrow{i_1} \rangle \subset \langle \overrightarrow{i_2} \rangle$. $D_2$ is a \emph{component extension} of $D_1$ iff $D_2$ is an input or output component extension of $D_1$. $D_2$ is a \emph{rule extension} $D_1$ iff $R_1 \subset D_2$. $D_2$ is an \emph{extension}(or an \emph{extended definition}) of $D_1$ iff $D_2$ is a component or rule extension of $D_1$.
A component $i \in \langle \overrightarrow{i_2} \rangle \setminus \langle \overrightarrow{i_1}$ is an \emph{extending input component} of $D_2$ for $D_1$.
A component $o \in \langle \overrightarrow{o_2} \rangle \setminus \langle \overrightarrow{o_1}$ is an \emph{extending output component} of $D_2$ for $D_1$.
A component is an \emph{extending component} iff it is an extending input component or an extending output component.
A rule $r \in R_2 \setminus R_1$ is an \emph{extending rule} of $D_2$ for $D_1$.
\end{defn}

\begin{remark}
An extension of an ILP task definition defines a different ILP task.
\end{remark}

A correspondence between an ILP task defined by $D$ and an ILP task defined by an extension of $D$ is shown.

\begin{corollary}
Let $D_2$, $D_1$ be ILP task definitions. If $D_2$ is a rule extension of $D_1$, then $D_2$ is more complete than $D_1$.
\end{corollary}
\begin{proof}
Follows from \fullref{definition_ilp_task_definition_extension} and \fullref{corollary_more_complete_1}.
\end{proof}

\begin{proposition}
Let $D_2=\langle f_2, dom(f_2), cod(f_2), R_2 \rangle$,
$D_1=\langle f_1, dom(f_1), cod(f_1), R_1 \rangle$ be ILP task definitions. Suppose that $D_2$ with an input $I_2$ is an input extension of $D_1$ with an input $I_1$, but not an output extension, not a rule extension. Then $f_2(I_2)=f_1(I_1)$.
\end{proposition}

\begin{proof}
$O \in f_1(I_1) \iff R_1 \cup \{O \in f_1(I_1)\} \not\models false \iff  R_2 \cup \{O \in f_2(I_2)\} \not\models false \iff O \in f_2(I_2)$ since $O \in f_2(I_2)$ is defined in terms of $I_1 \subseteq I_2$ and for the defining rules $R_1(f_1 \mapsto f_2) = R_2$, $R_2(f_2 \mapsto f_1)=R_1$ for substitutions $f_1 \mapsto f_2$, $f_2 \mapsto f_1$.
\end{proof}

\subsubsection{Generalization}
Recall \fullref{generalization}.
\begin{defn}
An ILP task of \emph{generalization} is defined by $D=\langle f, L, L, R \rangle$ where $R=\{\forall I \in L. Cn(I) \subseteq Cn(f(I))\}$ for some logic language $L$ and a consequence operator $Cn:L \to L$.
\end{defn}

An example of an ILP system that puts background knowledge and examples into one theory which is then generalized is Progol\cite{muggleton1995inverse}. An interested reader should consult Progol implementation referenced in the cited paper.

\subsubsection{Hypothesis}
The properties arising from an ILP task with a hypothesis provide significant means of comparison. A hypothesis is part of the definition of explanatory induction, but it is not present in the definition of generalisation. To be able to compare ILP systems like Progol whose ILP task is an extension of generalisation with ILP systems like Toplog, Imparo, Tal whose ILP task is an extension of explanatory induction we define a hypothesis for the definition of generalization.

\begin{defn}
Let $D=\langle f, L, L, R \rangle$ be a definition of generalization.
Then $H \in L$ is a \emph{hypothesis} for $I \in dom(f)$ iff $\exists O \in f(I). H=O \setminus I$.
\end{defn}

\begin{exmp}
Let $B, E, H$ be background knowledge, examples, a correct hypothesis wrt $B, E$ such that $E \cap H=\emptyset$.
Then $Cn(B \cup E) \subseteq Cn(B \cup H)$, hence $O=B \cup H$ is a generalization of $I=B \cup E$.
$I, O$ define the hypothesis $H'=O \setminus I=(B \cup H) \setminus (B \cup E)=H \setminus E=H$ which is the original hypothesis we started with.
\end{exmp}

\subsubsection{Explanatory induction}
Most of the ILP systems solve an ILP task of an extended form of explanatory induction.\cite{kimber2012learning}\cite{aleph2007}\cite{nienhuys1997foundations}

\begin{defn}
An ILP task of \emph{explanatory induction} is defined by $D=\langle f, dom(f), cod(f), R \rangle$ where $I=\langle B, E \rangle$, $O=H$,
$R=\{Cn(B \cup E) \subseteq Cn(B \cup H), false \not\in Cn(B \cup H)\}$ for some consequence operator $Cn$.
\end{defn}
A division of examples $E=E^{+} \cup \neg E^{-}$ into positive examples $E^{+}$ and negative examples $E^{-}$ results in an alternative definition.

\begin{defn}
An ILP task of \emph{explanatory induction} is defined by $D=\langle f, dom(f), cod(f), R \rangle$ where $I=\langle B, E^{+}, E^{-} \rangle$, $O=H$,
$R=\{Cn(B \cup E^{+}) \subseteq Cn(B \cup H), E^{-} \not\in Cn(B \cup H)\}$ for some consequence operator $Cn$.
\end{defn}

See an example \fullref{explanatory_induction_example}.

\subsubsection{Hypothesis bias}
The non-determinism of an ILP task is reduced by an introduction of additional constrains. A set of the constrains on a hypothesis for an ILP task are a hypothesis bias.

\begin{defn}
An ILP task of \emph{explanatory induction with a hypothesis bias} is defined by $D=\langle f, dom(f), cod(f), R \rangle$ where $I=\langle B, E, \mathcal{H}\rangle$, $O=H$,
$R=\{Cn(B \cup E) \subseteq Cn(B \cup H), false \not\in Cn(B \cup H), H \in \mathcal{H}\}$ for some consequence operator $Cn$. A set $\mathcal{H} \subseteq \powerset{L}$ for a logic language $L$ is called a \emph{hypothesis bias}.
\end{defn}

\begin{exmp}\label{explanatory_induction_hypothesis_bias}
Let $B = \{cook(alice), female(alice)\}$, $E=\{woman(alice)\}$,
$H_1=\{woman(alice) \leftObjectImplies cook(alice)\}$,
$H_2=\{woman(alice) \leftObjectImplies female(alice)\}$,
$\mathcal{H}=\{H_1\}$.
Then $H_1$ and $H_2$ are possible outputs for an input $I=\langle B, E\rangle$ of explanatory induction. However, only $H_2$ is an output for an input $I'=\langle B, E, \mathcal{H}\rangle$ of explanatory induction with a hypothesis bias.
\end{exmp}

\begin{exmp}
Let $\mathcal{H} \subseteq \powerset{L}$ be a set of definite clauses. Then $\mathcal{H}$ is a hypothesis bias.
\end{exmp}

\subsubsection{Preferential bias}
Instead of introducing constrains on a hypothesis, one may introduce constrains as a relation on pairs of hypotheses.

\begin{defn}
An ILP task of \emph{explanatory induction with a preferential hypothesis bias} is defined by $D=\langle f, dom(f), cod(f), R \rangle$ where $I=\langle B, E, <_H\rangle$, $O=H$,
$R=\{Cn(B \cup E) \subseteq Cn(B \cup H), false \not\in Cn(B \cup H), \forall H_2. (Cn(B \cup E) \subseteq Cn(B \cup H_2), false \not\in Cn(B \cup H_2) \implies H_2 <_H H \lor H_2 =_H H \}$ for some consequence operator $Cn$. A relation $<_H \subseteq \powerset{L} \times \powerset{L}$ is called a \emph{preferential hypothesis bias}.
\end{defn}

\begin{exmp}
Let $B, E, H_1, H_2$ be as in an example \fullref{explanatory_induction_hypothesis_bias}.
Let $<_H=\{(H_1, H_2)\}$ be a preferential hypothesis bias.
Then $H_2$ is a possible output for an input $I=\langle B, E, <_H \rangle$ of explanatory induction with a preferential hypothesis bias, but $H_1$ is not.
\end{exmp}

\subsubsection{Mode declarations}
One may define a hypothesis bias $\mathcal{H}$ by enumerating all the hypotheses $H \in \mathcal{H}$. If $\#\mathcal{H}$ is large, it may be impractical. ILP systems specify constrains on a hypothesis space with alternative constructions. A mode declaration\cite{muggleton1995inverse} specifies the predicates allowed in a hypothesis.

\paragraph{Xhail2}
\begin{lstlisting}
modeh(1,3,min,fries("+bistro")).
modeb(1,3,pos,offer("+bistro")).
\end{lstlisting}

\paragraph{Toplog}
\begin{lstlisting}
:-modeh(append(+list,+list,-list)).
:-modet(2, l2ht(+list/[H|T], -any/H, -list/T)).
:-modeb(append(+list,+list,-list)).
\end{lstlisting}

\subsubsection{Determinations}

\subsubsection{Top theory}

\subsubsection{Integrity constraints}

\subsubsection{Meta-constrains}

\paragraph{Toplog}
\begin{lstlisting}
:-set(maximum_literals_in_hypothesis)
:-set(example_inflation, 10).
\end{lstlisting}

\paragraph{Imparo}
\begin{lstlisting}
:-set_max_clause_length(5).
:-set_max_clauses(1).
:-set_verbose(1).
:-set_connected(1).
:-set_max_var_depth(3).
\end{lstlisting}

\paragraph{Tal}
\begin{lstlisting}
%Maximum number of body literals
option(max_body_literals, 5).

%Maximum number of rules
option(max_num_rules, 5).

%Maximum depth of the proof
%option(max_depth, 400).
option(strategy, breadth).
option(ic_check, true).
\end{lstlisting}

\subsubsection{Probabilistic setting}

\subsubsection{Approximating requirements}
Toplog - hypothesis.

\subsubsection{Score function}

\subsubsection{Semantics}

\subsubsection{Other constructions}
The building blocks and the rules we have considered are:
\begin{itemize}
\item types in 
\item episodes in metalearning framework.
\end{itemize}

\subsubsection{Summary of ILP task definitions}

\subsection{Classification ILP systems by an ILP task definition}
The objective of this subsection is to summarise ILP task definitions for each ILP system classified from the building blocks of an ILP task definition in the preceeding subsection \fullref{building_blocks_of_ilp_task_definition} and to classify ILP systems by their correspondent ILP task definition.

\subsubsection{Definitions of an ILP task for classified ILP systems}

\subsubsection{Comparisons of ILP systems based on their ILP task definition}

\subsection{A unified definition of ILP task}
We are interested in comparing the ILP systems, considering the specifics of ILP systems, each does not try to solve the same ILP problem. We search a way to compare these mutually incompatible systems. One way to establish the possibility of the comparison would be to unify these incopabilities by generalizing and abstracting. However, this means we may lose some of the information about the specifics of each system. First we provide the problem settings for each ILP system.

Let $E$ denote examples, $E^{+}$ positive examples, $E^{-}$ negative examples, $B$ the background knowledge, $\mathcal{H} \subseteq \powerset{L}$ the language bias. Let $Cl:\powerset{L} \to \powerset{L}$ be the classical monotonic consequence operator, $\models$ a non-monotonic consequence operator. Here by the overline on negative examples $\overline{E^{-}}$ we denote the set of the negated sentences of $E^{-}$. When specifying the consistency condition for the negative examples by $B \cup H \not\models E^{-}$ we mean that no example $e^{-} \in E^{-}$ should be implied by $B \cup H$, therefore $E^{-}$ is meant to be a disjunction (rather than a conjunction like $E^{+}$) of examples. Therefore, $\overline{E^{-}} \equiv \neg E^{-}$.

\begin{center}
    \begin{tabular}{ | l | p{15cm} | l | p{5cm} |}
    \hline
    ILP system & \\ \hline
    Aleph & Given $E^{+}$, $E^{-}$, $B$, $\mathcal{H}$, $B \land E^{+} \land E^{-} \not\models false$, find $H \in \mathcal{H}. B \land H \models E^{+}, B \land E^{-} \not\models false$\\ \hline
    Progol & Given $B$, $\mathcal{H}$, find the most general $B_2 = B' \land H$ where $B' \subseteq B$, $H \in \mathcal{H}$, $B_2 \models B, B_2 \not\models false$\\ \hline
    Toplog & Given $E^{+}, E^{-}, B, \mathcal{H}, B \land E^{+} \land E^{-} \not\models false$, find $H \in \mathcal{H}. B \land H \models E^{+}, B \land E^{-} \not\models false$ \\ \hline
    Imparo & Given $E^{+}, E^{-}, B, \mathcal{H}, B \land E^{+} \land E^{-} \not\models false$, find $H \in \mathcal{H}. B \land H \models E^{+}, B \land E^{-} \not\models false$ \\ \hline
    Tal & Given $E^{+}, E^{-}, B, \mathcal{H}, B \land E^{+} \land E^{-} \not\models false$, find $\mathcal{H}_2 \subset \mathcal{H}. \forall H \in \mathcal{H}_2. B \land H \models E^{+}, B \land E^{-} \not\models false$ \\ \hline
    Xhail & Given $E^{+}$, $E^{-}$, $B$, $\mathcal{H}$, find $H \in \mathcal{H}$. $E^{+} \land \overline{E^{-}} \subseteq Cl(B \land H), false \not\in Cl(B \land H)$\\ \hline
    \hline
    \end{tabular}
\end{center}

Aleph, Toplog and Imparo aim to solve the same ILP problem called \emph{explanatory induction}:
given $E^{+}, E^{-}, B, \mathcal{H}, B \land E^{+} \land E^{-} \not\models false$, find $H \in \mathcal{H}. B \land H \models E^{+}, B \land E^{-} \not\models false$

The Progol ILP problem is a generalization of the explanatory induction: given $E^{+}, E^{-}, B, \mathcal{H}, B \land E^{+} \land E^{-} \not\models false$,
let $B_P=E^{+} \land \overline{E^{-}} \land B$ be the Progol background knowledge. Then Progol finds the most general $B_2 = B' \union H_P$ where $B' \subseteq B_P, H_P \in \mathcal{H}, B_2 \models B_P, B_2 \not\models false$.
Then $(B' \union H_P) \backslash B=E'^{+} \land \overline{E'^-} \land H_P = H$ where $E'^+ \subseteq E^+, E'^- \subseteq E^-$. Then $H$ is the solution of the problem of the explanatory induction since $B \land H \models E^{+}, B \land H \not\models E^{-}, B \land H \not\models false$. We could generalize the problem to Progol ILP problem level, however, as Progol is the only system with so significantly differing problem system, we rather proceed in the reverse direction, we specialize the Progol ILP problem to the level of the explanatory induction as explained above. Hence we will think of Progol as producing a hypothesis explaning the examples from the background knowledge. Some information about the true nature of the Progol will become invisible in the comparisons, on the other hand, more information about the other systems will remain available.

Let $Cn:\powerset{L} \to \powerset{L}$ be a consequence operator, then generalize the definition of an ILP problem for Aleph, Toplog, Imparo, Tal and Xhail:
given $E^{+}, E^{-}, B, \mathcal{H}, false \not\in Cn(B \land E^{+} \land E^{-})$,
find $\mathcal{H}_2 \subset \mathcal{H}. \forall H \in \mathcal{H}_2. E^{+} \land \overline{E^{-}} \subseteq Cn(B \land H), false \not\in Cn(B \land H)$. Call this generalization of the explanatory induction, Tal ILP problem, Xhail ILP problem to be \emph{multi-explanatory induction} as it provides possible several epxlanations $\mathcal{H}_2$ for the observations. Clearly, multi-explanatory induction encompasses the specialization of the Progol problem. For systems other than Tal, $\#\mathcal{H}_2=1$. For Xhail, $Cn=Cl$, for others $Cn=\models$.

\section{Hypothesis selection}

\section{Hypothesis search}

\section{Language bias}
One of the strategies ILP systems use for solving the problems of the hypothesis selection and hypothesis search is the introduction of a language bias.

\begin{defn}
Given a language $L$, the \emph{language bias} is a property (a boolean valued function) $P$ defined on all words of $L$.
\end{defn}

\begin{exmp}
Define the property $P$ by $\forall w \in L. P(w) \iff w \in L_h$. Then $P$ is a language bias of the hypotheses language $L_h$ in its superlanguage of enquiry $L$.
\end{exmp}

\begin{exmp}
The signature of $L$ is
$\mathcal{L}=\{TastesHot, IsWhite, ContainsSpice, ContainsSugar\}$,
the signature of $L_h$ is
$\mathcal{L}_h=\{TastesHot, IsWhite, ContainsSpice\}$.
Let $P(w) \iff w$ does not contain $ContainsSugar$. $P$ is the language bias of $L_h$ in $L$.
\end{exmp}

\begin{remark}
We will often think of a bias on $L$ as a subset $P$ of $L$ rather than a property on $L$ and use the notation interchangeably:
$P=\{w \in L : P(w)\} \subseteq L$.
\end{remark}

\begin{defn}
A bias $P$ of the language $L$ is \emph{sufficiently weak} with respect to the theory $T$ iff there exists an axiomatization $A$ of the theory $T$ such that $A \subseteq P$. If $P$ is not sufficiently weak with respect to the theory $T$ we say that $P$ is \emph{too strong} with respect to the theory $T$.
\end{defn}

\begin{defn}
Let $P_1$, $P_2$ be biases on the language $L$. $P_1$ is \emph{weaker} than $P_2$ and $P_2$ is \emph{stronger} than $P_1$ iff $P_2 \subseteq P_1$.
\end{defn}

\begin{exmp}
Define biases $P_k$ for $k \in \mathbb{Z}_{\ge 0}$ by $P_k(\phi)$ iff $\phi$ consists of at most $k$ distinct characters. Let $T$ be the theory of the elementary class of the partial orders. Let $A=\{\phi_1, \phi_2, \phi_3\}$ where

$\phi_1=\forall a. a \le a$,

$\phi_2=\forall a \forall b. a \le b \wedge b \le a \objectImplies a=b$,

$\phi_3=\forall a \forall b. a \le b \wedge b \le c \objectImplies a \le c$.

$A$ is an axiomatization of the theory $T$. Note $\forall \phi \in A. P_8(\phi)$ as every axiom of $A$ consists of less than $8$ distinct characters. Therefore $P_8$ is a sufficiently weak bias of the language $L$ with respect to the theory $T$. However there does not exist an axiomatization of the theory $T$ where every axiom consists of at most $3$ distinct characters, therefore $P_3$ is a too strong bias with respect to the theory $T$. The set of the biases is ordered by their strength:
$P_0 \subseteq P_1 \subseteq P_2 \subseteq P_3 \subseteq ... \subseteq P_8 \subseteq ...$. Thus $P_3$ is stronger than $P_8$.
\end{exmp}

\begin{remark}
Let $L$ be the language, $\mathcal{P}$ be the set of all the biases on $L$. Then $\mathcal{P}$ is a lattice ordered by the subset inclusion $\subseteq$ with its join operator the set union $\union$ and its meet operator the set intersection $\cap$.
\end{remark}

\subsection{Language bias benefits}
\begin{itemize}
\item Biases reduce the hypotheses space to focus on the relevant hypotheses,
\item the problem of finding the hypothesis $H$ can be solved by applying successively a stronger and stronger bias.
\end{itemize}
We want our hypothesis to have a specific syntactic form:
\begin{itemize}
\item If a hypothesis is a clause with a head $h$ we learn sufficient conditions for $h$ to be implied,
\item by specifying conditions in a body of a clause of a hypothesis we learn what concepts can be implied,
\item restricting a head $h$ of an implication $b \objectImplies h$ not to be a disjunction but only a conjuction, we avoid learning the rules implying uncertain facts.
\end{itemize}

\subsection{Language bias problems}
Consider the hypotheses space $\mathcal{H} \subseteq \powerset{L}$. An ILP problem is to find the axiomatization $A \in \mathcal{H}$ of $O$ given $B$ of the maximal score $s(A,B,O)$ where $O$ is a set of the observations, $B$ is the background knowledge.
A simple brute force algorithm may go over all $H \in \mathcal{H}$ and check if $H=A$. This poses problems:
1. $\mathcal{H}$ may not be finite,
2. determining if $H=A$ may not be decidable.
In order to disect the problem more closesly the score function will need to be given a more specific form.

\subsection{Language bias in ILP}
Different biases may be applied to each of the languages $L, L_o, L_h$. 

\subsection{Syntactic biases}

\begin{defn}
A bias $P$ on $L$ is syntactic iff there exists a computable function $f:L \to \{0,1\}$ such that $\forall x \in L.P(x) \iff f(x)=1$.
\end{defn}

\begin{remark}
A syntactic bias is computable from the language $L$ alone, no other information is available on its input.
\end{remark}

\begin{defn}
$P$ is a \emph{size bound bias} iff there exist numbers $min, max \in \mathbb{Z}$ such that $\forall \phi \in L. P(\phi) \iff min \le size(\phi) \le max$ where $size(\phi)$ is a length of a word $\phi \in L$.
\end{defn}

\begin{remark}
ILP systems with a score function involving a minimum compression length have size bound bias since they do not consider hypotheses of size greater than $\#B \union O$.
\end{remark}

\begin{remark}
Similarly, with a syntactic bias we could bound the number of the clauses in their conjunction $\phi \in L$ if necessary.
\end{remark}

\begin{defn}
A formula $\phi$ is $k$-adic iff its all predicate symbols (including an equals sign) and function symbols translated to predicate symbols are of the arity at most $k$. A formula $\phi$ is monadic iff $\phi$ is $1$-adic. A set or a theory is $k$-adic iff all its formulas are $k$-adic. The property of a formula $\phi$ being $k-adic$ is computable from $\phi$ and therefore it is a \emph{$k-adic$ bias}.
\end{defn}

\begin{defn}
A formula $\phi$ is a Horn formula iff $\phi$ is a clause with at most one positive literal. The property of a formula $\phi$ being a Horn formula is computable from $\phi$ and therefore it is a \emph{Horn bias}.
\end{defn}

\begin{defn}
A formula $\phi$ is a definite clause iff $\phi$ is a clause with exactly one positive literal. The property of a formula $\phi$ being a definite clause is computable from $\phi$ and therefore it is a \emph{definite clause bias}.
\end{defn}

The following definitions, an example and a remark of a mode declaration are due to Muggleton, Inverse Entailment and Progol\cite{muggleton1995inverse}.
\begin{defn}\cite{muggleton1995inverse}
A \emph{mode declaration} has either the form
$modeh(n,atom)$ or $modeb(n,atom)$ where $n$, the recall, is either an integer, $n > 1$,
or `*' and atom is a ground atom. Terms in the atom are either normal or placemarker. A normal term is either a constant or a function symbol followed by a
bracketed tuple of terms. A placemarker is either $+type$, $-type$ or $\#type$, where
type is a constant. If $m$ is a mode declaration then $a(m)$ denotes the atom of $m$
with placemarkers replaced by distinct variables. The sign of $m$ is positive if $m$ is a modeh and negative if $m$ is a modeb.
\end{defn}

\begin{exmp}
\cite{muggleton1995inverse}
\begin{lstlisting}
modeh(1,plus(+int,+int,-int))
modeb(*,append(-list,+list,+list)
modeb(1,append(+list,[+any],-list))
modeb(4,(+int > \#int))
\end{lstlisting}
\end{exmp}

\begin{remark}
\cite{muggleton1995inverse}
The recall is used to bound the number of alternative solutions for instantiating
the atom. For simplicity, we assume in the following that all the modes have the
recall `*', meaning all solutions. The following defines when a clause is within
Progol's definite mode language $L$.
\end{remark}

\begin{defn}
\cite{muggleton1995inverse}
\emph{Definite mode language}. Let $C$ be a definite clause with a
defined total ordering over the literals and $M$ be a set of mode declarations. $C = b_1, ..., b_n \objectImplies h$ is in the definite mode language $L_{mode}$ (a \emph{mode declaration bias}) if and only if
1) h is the atom
of a modeh declaration in $M$ with every placemarker $+type$ and $-type$ replaced by
variables and every placemarker $\#type$ replaced by a ground term and 2) every
atom $b_i$ in the body of $C$ is the atom of a modeb declaration in $M$ with every
placemarker $+type$ and $-type$ replaced by variables and every placemarker $\#type$
replaced by a ground term and 3) every variable of $+type$ in any atom $b_i$ is either
of $+type$ in $h$ or of $-type$ in some atom $b_1, ..., b_{i-1}$.
\end{defn}

\begin{remark}
A mode declaration bias is syntactic since there exists a computable function $g:L \times \mathfrak{M} \to \{0, 1\}$ (e.g. implemented in Progol\cite{muggleton1995inverse}) such that given a mode declaration $M$, then
$\forall \phi \in L. g(\phi, M)=1 \iff \phi \in L_{mode}$.
\end{remark}

\subsubsection{Syntactic biases list}
\begin{itemize}
\item Size bound bias.
\item $k$-adic bias.
\item Horn bias.
\item Definite clause bias.
\item Mode declaration bias.
\end{itemize}

\subsection{Semantic biases}

\begin{defn}
A bias $P$ is semantic iff $\forall \phi, \psi \in L. \phi \equiv \psi \implies (P(\phi) \iff P(\psi))$, i.e. $P$ is independent of a syntax of a formula $\phi \in L$.
\end{defn}

\subsubsection{Toplog top theory bias\cite{muggleton2008toplog}}
A top theory $\top$ is an extension of the background knowledge $B$. One could convert any ILP system to a TDHD(top-directed hypothesis derivation) ILP system by providing the input background knowledge $B \union \top$ instead of $B$ with the assumptions that the input satisfies the conditions of a quadruple $\langle NT, \top, B, E \rangle$ stated later.

A top theory bias is a mixture of a syntactic bias - e.g. $\top$ has to consist of Horn clauses and semantic bias which is of our interest.
\begin{defn}
A predicate symbol is \emph{non-terminal} iff TODO
\end{defn}

\begin{defn}
A predicate symbol is a \emph{target} iff TODO
\end{defn}

The input to an TDHD system is the quadruple $\langle NT, \top, B, E \rangle$ where $NT$ is a set of non-terminal  predicate symbols. Therefore a top theory $\top$ is not constructed from the input but already is a part of an input. $\top$ satisflies the conditions:
1. $\top$ consists of Horn clauses,
2. each clause in $\top$
must contain at least one occurrence of an element of $NT$ while clauses in $B$
and $E$ must not contain any occurrences of elements of $NT$,
3. any predicate appearing in the head of some clause in $\top$ must not occur in th	e body of any clause in $B$,
4. the head of the first clause in $\top$ is the target predicate and
the head predicates for other clauses in must be in $NT$.

\subsubsection{Construction of a top theory from the mode declarations\cite{muggleton2008toplog}}
TODO - explain a construction of a top theory from an arbitrary set of mode declarations.
A top theory bias is more expressive than a mode declaration bias.
In a simplified way, given the mode declarations

$modeh(mammal(+animal)).$

$modeb(has milk(+animal)).$

$modeb(has eggs(+animal)).$

a top theory can be constructed to be $\top=\{\top_1, \top_2, \top_3, \top_4\}$:

$\top_1=mammal(X) \leftObjectImplies \$body(X).$

$\top_2=body(X) \leftObjectImplies .\%emptybody$

$\top_3=\$body(X) \leftObjectImplies has\_milk(X), \$body(X).$

$\top_4=\$body(X) \leftObjectImplies has\_eggs(X), \$body(X).$

The actual construction of a $\top$ theory has stricter control rules like: variables may only bind with others of the same type, a newly added literal must have its input variables already bound.

Both top theory bias and a mode declaration bias are specified at the input to an ILP system, for some input specifications as one above the biases are equal. Therefore one should distinguish further between a bias and a bias specification.

One could argue that a specification of a bias consists of an algorithm $A$ and an input $i$ where $A$ computes a bias $P$ from the given input $i$. As the input $i$ independent of an ILP system input $\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle$ may vary, an algorithm $A$ may compute (specify) multiple possible biases $P$. This can be seen from the ability to specify a mode declaration independent of the input
$\langle\mathcal{L}, \mathcal{L}_o, \mathcal{L}_h, O, B\rangle$.

\begin{exmp}
For the following sentence can be entailed by a top theory but there does not exist a mode declaration biased space that includes it:
TODO
\end{exmp}

\begin{itemize}
\item Bottom theory bias. An ILP system constructs a most specific hypothesis $\bot$ according to the bias criteria, then every possible hypothesis $H$ must entail $\bot$: $H \models \bot$.
\item Bottom theory subsumption bias. Every hypothesis must subsume the bottom theory.
\item Top theory subsumption bias. Every hypothesis must be subsumed by the top theory.
\item Solo-generalization bias. The hypotheses space $\mathcal{H}$ is restricted to the generalization of a single example. \cite{muggleton2012mc}
TODO: provide a formula of the restriction.
\item Solo-explanation bias. Every clause $h$ in a hypothesis $H$ has to explain at least \emph{one} example.
$\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$
\item Inverse entailment bias.
$B \union H \models E \iff B \union \neg H \models \neg E$.
\item Negation on failure bias. The lack of an observation $example(x)$
causes an illusion that $\neg example(x)$ is true as $example(x)$ not provable.

\subsubsection{Heuristic biases}
\begin{defn}
A boolean property $P$ is a heuristic bias iff $P$ is computable from $\mathcal{H}, B, O$.
\end{defn}
\item Score function bias. Having two correct hypotheses $H_1$, $H_2$ such that $B \union H_1 \models E$ and $B \union H_2 \models E$ choose the hypothesis with the greater score by the (computable) function $s:\mathcal{H} \to \mathbb{R}$.
\item Search algorithm bias. A search algorithm uses heauristics to navigate via the search space $\mathcal{H}$ in addition to the score function applied after the algorithmic hypotheses generation.
\end{itemize}

\section{Biases in ILP systems}

\iffalse
\subsection{Progol}
\begin{itemize}
\item Inverse Entailment,
\item a bias provided by mode declaration,
\end{itemize}
\fi

\subsection{Toplog\cite{muggleton2008toplog}}
\begin{defn}
$B$ a Horn theory, $E$ a Horn clause. The bottom clause of $B$ and $E$ is $\bot(B,E)$=$\vee\{L | L $ a ground literal, $B \union {\neg E} \models \neg L\}$.
\end{defn}
An ILP system implementation Toplog is based on the theoretical framework Top Directed Hypothesis Derivation (TDHD) with the hypothesis space bias called top theory $\top$:
\begin{itemize}
\item Horn theory bias,
\item Bottom theory bias $\bot = \bot(B,E)$,
\item Solo-generalization bias,
\item Score function bias,
\item top theory $\top$ is specified in the input to an ILP system,
\item top theory $\top$ can be constructed from the mode declarations,
\item not every top theory bias can be expressed with the mode declarations,
\item a top theory consists of literals: terminals (in hypothesis language) and non-terminals (not allowed in hypothesis language and background knowledge)
\item a hypothesis clause in a hypothesis space consists of terminals and is derivable from the top theory by SLD-resolution and substitution, $\top \models h$
\item restriction on the predicates in the head/body of a hypothesis clause,
\item every constructed hypothesis must be subsumed by a top theory $\top$. If $H$ is a set of candidate hypotheses, then: $\forall h \in H. \exists e \in E. \top \models h \& B, h \models e$.
\item inverse entailment bias.
\end{itemize}
Toplog violates the properties in our first definition of an ILP system:
\begin{itemize}
\item a produced theory may not be complete due to too strong default bias:
\begin{itemize}
\item only what is defined by mode declarations can be in theory,
\item theory can contain only one clause,
\item only one head clause definable with mode declarations unlike two clauses
\begin{lstlisting}
:-modeh(woman(+person)).
:-modeh(man(+person)).
\end{lstlisting}

\item restrictions on the top theory related to $NT$ (non-terminals), $B$, $E$; what literals can occur where. Details in TopLog: ILP Using a Logic Program Declarative Bias by Muggleton etal.
\end{itemize}
\item a produced theory need not be consistent with the observations: given observations $human(susan)$ and $human(jack)$ a final theory can contain the hypothesis $woman(X) :- human(X)$. The accuracy of a theory is computed, a score function allows a degree of inaccuracy.
\end{itemize}

\iffalse
\subsection{ProGolem}
\begin{itemize}
\item Inverse Entailment,
\item co-generalization, 
\end{itemize}
\fi

\subsection{Imparo\cite{kimber2009induction}}
Bias:
\begin{itemize}
\item Horn theory bias (not present in a IoF framework),
\item Bottom theory bias, $\bot=$ a connected theory for $B$ and $e$,
\item Solo-generalization bias,
\item Score function bias,
\item Mode declaration bias,
\item a bias specifiable in an input program:
\begin{lstlisting}
%a restriction on the length of a clause in a theory
:-set_max_clause_length(N1).
%a restriction on the number of clauses in a theory
:-set_max_clauses(N2).
%TODO - explain further two
:-set_connected(N3).
:-set_max_var_depth(N41).
\end{lstlisting}
\end{itemize}
TODO: an algorithm for a connected theory generation.

\subsection{Metagol}
TODO

%Bias:
%Algorithm:
%Violations:

\subsection{Comparison of biases in ILP systems}
$\mathcal{H}_{Toplog} \subseteq \mathcal{H}_{Imparo}$

$\mathcal{H}_{bottom\_clause} \subseteq \mathcal{H}_{kernel\_set} \subseteq \mathcal{H}_{connected\_theory}$

\section{Inverse Subsumption for Complete Explanatory Induction}\cite{yamamoto2012inverse}

\subsection{IE algorithm\cite{yamamoto2012inverse}}
Progol, Xhail, Imparo are based on the principle of the inverse entailment. By the principle of the inverse entailment $B \cup H \models E$ iff
$B \cup \neg E \models \neg H$. A hypothesis $H \in \mathcal{H}_2$ is a solution to the problem of the explanatory induction $(B,E^{+},E^{-},\mathcal{H})$ iff
$B \cup H \subseteq Cn(E^{+} \union \overline{E^{-}})$,
 $false \not\in Cn(E^{+} \cup E^{-})$, $\mathcal{H}_2 \subseteq \mathcal{H}$
iff
$B \cup H \subseteq Cn(E^{+} \union \overline{E^{-}})$,
 $false \not\in Cn(E^{+} \cup E^{-})$, $\mathcal{H}_2 \subseteq \mathcal{H}$
 
They compute the hypothesis $H$ in two steps:
1. constructing an intermediate theory, 2. generalizing its negation into the hypothesis with the inverse of the entailment relation.

The use of the inverse entailment in the computation of a hypothesis is an expensive operation as compared to the inverse subsumption. We classify the ILP systems based on whether the use of their induction technique with the inverse subsumption instead of the inverse entailment preserves the completeness for finding all the correct hypotheses.

\begin{lemma}\label{yamamoto2012inverseLemma2}\cite{yamamoto2012inverse}
Let $B$, $E$ and $I_H$ be a background theory, examples and an induction field,
respectively. Let $F$ be a bridge theory wrt $B$ and $E$. For every hypothesis $H$ wrt $I_H$ and $F$, $H$ satisfies the following condition:

$H \subsumes \tau(M(F \cup Taut(I_H))$.
\end{lemma}

\subsection{Imparo is complete in inverse subsumption}
We solve an open problem in \cite{yamamoto2012inverse} proving that for every correct hypothesis $H$ wrt $B, E^{+}, E^{-}$ there is a connected theory $T$ wrt $B, E^{+}, E^{-}$ subsumed by it.
\begin{defn}
Let $P=\langle B, U, I \rangle$ be an open definite program, $H$ be a correct hypothesis wrt $P$ and a ground example $E$, then $H$ is derivable by
\emph{connected theory inverse subsumption}
iff there exists a connected theory $T$ for $P$ and $E$ such that $H \subsumes T$.
We denote the statement by $P, E \vdash_{CTIS} H$.
\end{defn}

\begin{thm}\label{yamamoto2012inverseTheorem4}\cite{yamamoto2012inverse}
Let $S$ be a ground clausal theory. Then, $M^2(S) = \mu(S)$ holds.
\end{thm}

\begin{proposition}
Let $H \in I_H$ be an inductive solution for $P$ and $E$ such that $Taut(I_H)=\emptyset$, then $H$ is derivable by connected theory inverse subsumption from $P, E$.
\end{proposition}
\begin{proof}
By completeness of connected theory generalization\ref{completeness_ctg} there exists a connected theory $T$ such that $H \models T$. $M(T)$ is a bridge formula.
Hence by \ref{yam1amoto2012inverseLemma2}
$H \subsumes \tau(M(M(T) \cup Taut(I_H))$. From the definition of the connected theory $\tau(T)=T$ and $\mu (T)=T$.
Therefore $\tau(M(M(T) \cup Taut(I_H))=\tau(M(M(T))=\tau(T)=T$ using
\ref{yamamoto2012inverseTheorem4}. Therefore $H \subsumes T$ as required.
\end{proof}
\begin{remark}
The previous proposition is stated and proved only to provide an alternative proof of a statement superceded by the stronger result \ref{completeness_ctis}.
\end{remark}

\begin{thm}\label{implicationByGroundClauses}
(Implication by Ground Clauses \cite{nienhuys1997foundations}). Let $\Sigma$ be a non-empty set of clauses,
and $C$ be a ground clause. Then $\Sigma \models C$ if and only if there is a finite set $\Sigma_g$ of ground
instances of clauses from $\Sigma$, such that $\Sigma_g \models C$.
\end{thm}

\begin{thm}\label{completeness_ctg}
\emph{Completeness of connected theory generalization}(Theorem4.6 in \cite{kimber2012learning})
Let $\langle B, U, I \rangle$ be a definite open program,
let $H$ be a definite program, and let $e$ be an atom.
If $H$ is an inductive solution for $P$ and
$E = \{e\}$, then $H$ is derivable from $P$ and $E$ by connected theory generalisation.
\end{thm}
\begin{proof}\cite{kimber2012learning}
For the full proof, an interested reader is encouraged to read \cite{kimber2012learning}.
Since $H$ is a correct hypothesis for $P$ and $E$,
then $B \cup H \models E$ by definition.
Therefore, by \ref{implicationByGroundClauses}, there is a finite set $S$ of ground instances of clauses in $B \cup H$,
such that $S \models E$. Let $T = S \cap ground(H)$.
Since $T \subseteq S$, then $T$ is ground and finite, and
since $T \subseteq ground(H)$ then $H \models T$. 
Then Kimber proves that $T$ is a connected theory for $P$ and $E$.
\end{proof}

\begin{thm}
\emph{Completeness of connected theory inverse subsumption}.
\label{completeness_ctis}
Let $\langle B, U, I \rangle$ be a definite open program,
let $H$ be a definite program, and let $e$ be an atom.
If $H$ is an inductive solution for $P$ and
$E = \{e\}$, then $H$ is derivable from $P$ and $E$ by connected theory inverse subsumption.
\end{thm}
\begin{proof}
Construct a connected theory $T=S \cap ground(H)$ for $P$ and $E$ as in the proof of \ref{completeness_ctg}.
Then $H \subsumes ground(H) \subsumes S \cap ground(H) = T$,
hence $H \subsumes T$ by transitivity as required.
\end{proof}

\section{Summary}

\subsection{Completeness in generalization\cite{yamamoto2012inverse}}
\begin{center}
    \begin{tabular}{ | l | p{5cm} |}
    \hline
    ILP system &  Complete in generalization \\ \hline
    Aleph & no\\ \hline
    Progol & no\\ \hline
    Toplog & no\\ \hline
    Imparo & no\\ \hline
    Tal & no*\\ \hline
    Metagol & yes*\\ \hline
    Xhail & no\\ \hline
    Cf-induction & yes\\
    \hline
    \end{tabular}
\end{center}


\subsection{Example learning}
None of the tested ILP systems can explain the negative examples. All the systems can induce hypotheses that aim to explain the positive examples. All the tested ILP systems accept ground instances of literals for examples.
\begin{center}
    \begin{tabular}{ | l | p{5cm} |}
    \hline
    ILP system &  Clausal examples \\ \hline
    Aleph & no\\ \hline
    Progol & yes\\ \hline
    Toplog & no\\ \hline
    Imparo & no\\ \hline
    Tal & no\\ \hline
    Metagol & \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Hypotheses space}
All systems can learn only the Horn clauses.
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ILP system & Function symbols & Multi-clausal hypotheses & Infinite Herbrand models\\ \hline
    Aleph & yes & yes & yes\\ \hline
    Progol & yes & yes & yes*\\ \hline
    Toplog & no & no & *\\ \hline
    Imparo & yes & yes & yes\\ \hline
    Tal & yes & yes & yes\\ \hline
    Xhail & yes & yes & no\\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Completeness}
Double Kleene star test assesses the ability of an ILP system to learn a regular language \tc{(ss)*}.
\begin{center}
    \begin{tabular}{ | p{2cm} | p{2cm} | p{2cm} | p{2cm} | p{2cm} | p{2cm} |}
    \hline
    ILP system & Multi-clausal concepts & Generalization downwards &
    Double Kleene star & Argument Specialization &
    Non-observational concepts\\ \hline
    Aleph & no & yes & no & no & no\\ \hline
    Progol & yes & no & no & yes & no\\ \hline
    Toplog & no & no* & no* & no & no\\ \hline
    Imparo & yes & no & yes* & yes & no\\ \hline
    Tal & yes & no & no & yes & yes\\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Argument Specialization}
Argument specialization test assesses the ILP system's ability to learn a hypothesis which require ground terms to be in a head predicate.
\begin{lstlisting}
modeh(learns(+person, +subject)).modeh(learns(#person, +subject)).
%background,male(adam).male(bob).female(alice).female(mary).
%positive examples,learns(polymath, mathematics).learns(polymath, physics).
learns(polymath, chemistry).learns(jack, mathematics).learns(susan, physics).
%negative examples,:- learns(jack, physics).:- learns(susan, chemistry).
\end{lstlisting}
has its target concept
\begin{lstlisting}
learns(polymath,A).
\end{lstlisting}
which has a constant \tc{polymath} as a first argument and a variable as a second argument.

\subsection{Non-observational concepts}
The ILP systems were tested if they could learn hypotheses that require multiple hypotheses in order to explain an example, however these hypotheses are not learnable with the cover loop algorithm. A cover loop algorithm learns hypotheses, adds these hypotheses to the background knowledge and tries to learn new hypotheses with the extended background knowledge that would explain not yet covered examples. The cover loop terminates if no new hypothesis is learnt.

An adapted sibling example from Kimber's thesis was used.
\begin{lstlisting}
modeh(brother(+person,+person)).modeh(parent(+person,+person)).
modeb(sibling(+person,+person)).modeb(male(+person)).
modeb(father(+person,+person)).
determination(brother/2, sibling/2).determination(brother/2, male/1).
determination(parent/2, father/2).
%background knowledge
male(bart).male(rod).male(todd).parent(homer,bart).
parent(homer,maggie).father(ned,rod).father(ned,todd).father(homer,lisa).
male(bart2).male(rod2).male(todd2).parent(homer2,bart2).
parent(homer2,maggie2).father(ned2,rod2).father(ned2,todd2).father(homer2,lisa2).
male(bart3).male(rod3).male(todd3).parent(homer3,bart3).
parent(homer3,maggie3).father(ned3,rod3).father(ned3,todd3).father(homer3,lisa3).
sibling(X,Y):-parent(Z,X),parent(Z,Y).
%positive examples
brother(bart,lisa).brother(rod,todd).
brother(bart2,lisa2).brother(rod2,todd2).
brother(bart3,lisa3).brother(rod3,todd3).
%negative examples, brother(lisa,bart).brother(rod,bart).
brother(maggie, maggie).parent(lisa,bart).
\end{lstlisting}
where we expect to learn the hypothesis
\begin{lstlisting}
brother(X,Y):-sibling(X,Y), male(X).parent(X,Y):-father(X,Y).
\end{lstlisting}
The second hypothesis \tc{parent(X,Y):-father(X,Y).} generalizes the existing knowledge, however it does not explain any examples. Such learning is called a non-observational learning. In the case of this sibling problem, a general hypothesis consists of an observational part - the first hypothesis and a non-observational part - the second hypothesis.
Other solutions consisting of purely observational hypotheses are longer and hence depending on our definition of generality, arguably less general.

\subsubsection{Imparo}
Imparo could not learn the expected hypothesis of the example, it learnt instead
\begin{lstlisting}
brother(A,B):-sibling(A,A),male(A)
brother(rod,todd):-true
brother(rod3,todd3):-true
brother(rod2,todd2):-true
\end{lstlisting}

\subsubsection{Aleph}
Aleph produces the hypothesis
\begin{lstlisting}
brother(A,B) :- sibling(A,A), male(A).
brother(rod,todd).brother(rod2,todd2).brother(rod3,todd3).
\end{lstlisting}

\subsubsection{Other systems}
Progol produces an inconsistent hypothesis \tc{parent(A,B).}. Toplog does not produce any hypothesis. Tal has amongst its solutions the expected hypothesis. However, depending on the depth limit we set, Tal can produce an arbitrarily large number of hypotheses. Thefore, an important work on Tal includes hypothesis selection.

\subsection{Biases}
\begin{center}
    \begin{tabular}{ | l | l | l | l | p{5cm} |}
    \hline
    ILP system & Mode declarations & Determinations & Declaration order bias & Alphabetical bias \\ \hline
    Aleph & yes & yes & yes & no\\ \hline
    Progol & yes & yes & yes & no\\ \hline
    Toplog & yes & no & yes & no\\ \hline
    Imparo & yes & no & yes & no\\ \hline
    Tal & yes & no & no & yes\\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Violations}
All tested systems suffer from weak-head mode declaration bias.
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ILP system & Correct example bias\\ \hline
    Aleph & yes\\ \hline
    Progol & yes\\ \hline
    Toplog & no\\ \hline
    Imparo & no\\ \hline
    Tal & yes\\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Robustness}
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ILP system & Consistency check & Always terminated\\ \hline
    Aleph & no & yes\\ \hline
    Progol & yes & yes\\ \hline
    Toplog & no & yes\\ \hline
    Imparo & no & no\\ \hline
    Tal & no & no\\ \hline
    \hline
    \end{tabular}
\end{center}

\subsection{Completeness of theoretical frameworks}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ILP framework & General Clause Hypothesis\\ \hline
    Bottom Generalization & no\\ \hline
    Induction on Failure & no\\ \hline
    CF-induction & yes\\ \hline
    TDHD & no\\ \hline
    MIL & \\ \hline
    \hline
    \end{tabular}

\subsection{Other}
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ILP system & \\ \hline
    Aleph & \\ \hline
    Progol & \\ \hline
    Toplog & \\ \hline
    Imparo & \\ \hline
    Tal & \\ \hline
    \hline
    \end{tabular}
\end{center}