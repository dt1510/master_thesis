\chapter{Problems in inductive logic programming}

\section{ILP problem definition}
When reasoning about an ILP problem we will always mean by $B$ the background knowledge, by $E+$ the positive examples, $E-$ the negative examples.

\subsection{Learning problem}
Inductive logic programming is a subdiscipline of machine learning (subdiscipline of AI) and logic programming. The objective of AI is to construct a machine that capable of doing what requires an intelligence if done by a man. (citation needed). One of the properties of an intelligent entity is the ability to learn. The author would like to put into attention 2 types of learning:
1. memorization is the ability to record and retrieve the observed data.
2. pattern recognition is the ability to learn the rules generating the observations from the observed data and the ability to use the learnt rules to predict the unobserved data. The definition of a learning system by Mitchell suggests that machine learning concerns with the pattern recognition.

\begin{defn}\cite{mitchell1997machine}
A computer program (an ILP system) is said to learn from experience $E$
with respect some class of tasks $T$ and performance measure $P$,
if its performance at tasks $T$ as measured by $P$ improves with the experience $E$.
\end{defn}

\subsubsection{Predicting unobserved data}
Given background knowledge $B$, positive examples $E+$, negative examples $E-$, $E+$ is a hypothesis explaning the positive examples $E+$ from the background knowledge $B$, $B \cup E+ \models E+$.
However, if there is a new observation $e \in L_O$ to be made such that
$B \models E+ \not\models e$ and $e \not\in E-$, the hypothesis $E+$ does not predict the truth value (one should not have any specific semantics for $\models$ in mind yet) of $e$. The ability of the memorization is not sufficient to learn a rule $woman(X) \leftObjectImplies female(X)$ from the following observations and the background knowledge.
\begin{lstlisting}
%Background knowledge
female(alice). female(jane). female(mary).
%Observations
woman(alice). woman(jane). woman(mary).
\end{lstlisting}

Therefore in order to define the ILP problem completely we have to require learning of the hypotheses with a predicting power.

\begin{defn}
An ILP problem of learning in an environment is a tuple $\langle B, \mathcal{E} \rangle$ where
$\mathcal{E}$ is an environment
$\mathcal{E}=\langle L, L_O, \mathtt{O}, \mathcal{M} \rangle$
and 
$\mathtt{O}:L_O \to \{true, false\}$ is a partial function from which the positive examples $E+$ and the negative examples $E-$ are defined as follows:
$\forall x \in L_O$
1. $x \in E+ \implies \mathtt{O}(x)=true$,
2. $x \in E- \implies \mathtt{O}(x)=false$,
3. $x \in L_O \setminus (E+ \cup E-) \implies \mathtt{O}(x)=\uparrow$.
\end{defn}

\begin{defn}
A hypothesis $H$ is correct wrt $B$ and $\mathcal{E}$ iff
$H$ is correct wrt the defined $B, E+, E-$.
\end{defn}

\begin{defn}
A hypothesis $H$ has \emph{predictive power} iff there exists
$x \in L_O$ such that $x \not \in Cn(B \cup E+ \cup E-)$
and either 1. $x \in Cn(B \cup H)$, or
or 2. $\neg x \in Cn(B \cup H)$.
\end{defn}

\begin{defn}
Let $\mu:\powerset{L_O} \to \mathbb{R}$ be a measure.
Then the information content of $H$ wrt $B, \mathcal{E}, \mu$
is a real number defined by
$I_\mu(H)=\sum_{x \in L_O : \{x, \neg x\} \cap Cn(B \cup H) \not= \emptyset} \mu(x)$.
\end{defn}
In words, $I_\mu(H)$ measures the data that is explained by $H$ from the background knowledge $B$.

\begin{defn}
A hypothesis $H$ \emph{predicts correctly} iff
$\forall x in L_O. x \in Cn(B \cup H) \iff \mathcal{M} \models x$.
\end{defn}

\subsection{Learning objective}
\subsection{Learning new information from given data}
\subsection{Generalization}
\subsection{Negative examples}
An example $e \in L_O$ is negative iff $\mathtt{O}(e)=false$.
\subsection{Learning positive examples}
A simple form of an ILP problem does not involve learning with negative examples.
\begin{defn}
An ILP problem of an explanatory induction\cite{yamamoto2012inverse} is a tuple $\langle B, E+ \rangle$ where $B$ is the background knowledge, $E+$ are positive examples. A hypothesis $H$ is correct wrt $\langle B, E+\rangle$ iff
$B \cup H \models E+$ and $B \cup H \not\models false$.
\end{defn}
\subsection{Learning negative examples}
One could require to learn negative examples in the same way as positive examples.
\begin{defn}
An ILP problem of learning negative examples is a tuple $\langle B, E+, E- \rangle$ where $B$ is the background theory, $E+$ a conjunction of the positive examples and $E-$ a conjunction of negative examples. A solution to the ILP problem $\langle B, E+, E-$ is a hypothesis $H$ such that
$B \cup H \models E+ \cup E-$ and $B \cup H \not\models false$.
\end{defn}
If the negative examples define a different concept, then this type of the learning problem does not provide any advantage compared to the learning of the positive examples. Indeed one could learn the negations of the negative examples as positive examples.

However, if the positive and negative examples are the observations of the same learnt concept, then negative examples can be used to supervise the learning of the positive examples.

\begin{exmp}
TODO
\end{exmp}

\subsection{Learning with negative examples}
The requirement to learn the negative examples may be too strong. One could benefit from the supervision by the negative examples for the learning of the positive examples without requiring learning the negative examples.

\begin{defn}
An ILP problem is a tuple $\langle B, E+, E- \rangle$. $H$ is a correct hypothesis wrt $\angle B, E+, E- \rangle$ iff
$B \cup H \models E+$, $B \cup H \not\models E-$ and $B \cup H \not\models false$.
\end{defn}

\subsection{Sematics}
If one would like to deduce the observations $E$ from the background knowledge $B$ and the hypothesis $H$, in notation $E \subseteq Cn(B \cup H)$, one has to define the consequence operator $Cn$ in order to specify the ILP problem setting.

The choice of the consequence operator specifies the interpretation of the learning problem, impacts what concepts $H$ are learnable from the background knowledge $B$ and the observations $E$ and what algorithm should be used to solve a specified inductive learning problem.

\subsubsection{Allowing several possibilities}


\subsubsection{Expressing incompleteness of information}
Solving a learning problem may require that we make a distinction in our knowledge of information: what is true, what is false and what we do not know.
Solving certain learning problems requires dealing with the knowledge of the information we do not know.

\subsection{Assumption of the probable information}

\subsubsection{Ability to withdraw conclusions}


\section{Completeness by problem classes}
The task of a normal problem setting for inductive logic programming is given background knowledge $B$, positive examples $E+$, negative examples $E-$ to find a hypothesis $H$ such that $B \cup H \models E+$,
$B \cup H \not\models E-$,
$B \cup H \not\models false$.
The logical theories $B$, $E+$, $E-$ specify a learning problem and determine the solution space $\mathcal{H}$ of the correct hypotheses.

\begin{defn}
An \emph{ILP problem} is a tuple $\langle B, E+, E- \rangle$.
\end{defn}

We learn about the nature of the problem by extracting the properties from the given theories. Learning problems with the identical properties are put in a class. Consequently, we can classify the ILP systems and methods based on the ability to solve a well-defined class of learning problems.

\subsection{Learning concepts}
\begin{defn}
A \emph{concept} on a domain $M$ is a relation $R \subseteq M^n$ for some $n \ge 0$.
The number $n$ is called \emph{arity of a concept}.
$M^n$ and $\emptyset$ are \emph{trivial concepts}.
\end{defn}

\begin{exmp}
Let the domain $M$ be a human family $M=\{adam, eva, kain, abel\}$ then define the concepts $male, female, father, mother, parent$ by
$male=\{adam, kain, abel\}\subseteq{M}$,
$female=\{eva\}\subseteq{M}$,
$father=\{(adam,kain), (adam,abel)\}\subseteq{M^2}$,
$mother=\{(eva,kain), (eva,abel)\}\subseteq{M^2}$,
$parent=father \cup mother$.
\end{exmp}
\begin{defn}
A concept $R\subseteq M^n$ is definable from the concepts $\mathcal{C}$ iff there is a formula $\phi$ using only the concepts from $\mathcal{C}$ such that
$\forall (x_1, ..., x_n) \in M^n. R(x_1, ..., x_n) \iff \phi(x_1, ..., x_n)$.
\end{defn}
\begin{corollary}
If $P\subseteq{M^n}$, $Q\subseteq{M^n}$ are concepts, then
1. $P \setminus Q$, 2. $P \cup Q$, 3. $P \cap Q$ are concepts.
\end{corollary}
\begin{proof}
1. $\forall x_1, ..., x_n. (P \setminus Q)(x_1, ..., x_n) \iff
P(x_1, ..., x_n) \land \neg Q(x_1, ..., x_n)$.
2. $\forall x_1, ..., x_n. (P \cup Q)(x_1, ..., x_n) \iff
P(x_1, ..., x_n) \lor \neg Q(x_1, ..., x_n)$.
3. $\forall x_1, ..., x_n. (P \cap Q)(x_1, ..., x_n) \iff
P(x_1, ..., x_n) \land Q(x_1, ..., x_n)$.
\end{proof}

\begin{exmp}
The concept $father$ is definable from the concepts $male$ and $parent$ by:
$\forall x_1, x_2 \in M. father(x_1, x_2) \iff parent(x_1, x_2) \land male(x_1)$. In addition using the trivial concepts one could define
$father=parent \cap (male \times M)$.
\end{exmp}

\subsubsection{Single concept problems}


\subsection{Complexity of a learning problem}
\subsection{Learning syntactic representations}
\subsection{Learning up to logical equivalence}
\section{Hypothesis selection}
\subsection{Information content of a hypothesis}
\subsection{Inducing preferences over hypotheses space}
\subsection{Hypothesis sufficiency}
\subsection{Hypothesis approximation}
\section{Hypothesis search}
\subsection{Postulates of inductive inference}
\subsection{Inductive inference rules}
\subsection{Control}
\subsection{Automation}
\section{Research in ILP}
\section{Classification of ILP systems}