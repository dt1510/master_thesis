
\chapter{Introduction}

\section{Motivation and Objectives}
From the observations of the environment on Earth the reader knows that the sun has always been rising in the morning and setting in the evening. This does not imply that the sun would rise tomorrow in the morning, however from our statistical observations and assumptions on the environment it is extremely likely. Therefore the reader may induce a hypothesis: the sun rises in the morning, the sun sets in the evening. As an agent the reader can profit from making the decisions based on the induced hypothesis provided that it remains true during the course of the reader's life. For example if the reader would like to maximize the time spent on the daylight, then the reader goes to bed in the evening and wakes up in the morning.

However, an induction of hypotheses of certain forms tends to be statistically more successful than an induction of hypotheses of other forms. The problem is addressed as well in a wikipedia article on Problem of Induction \cite{wikipediaProblemOfInduction}.

\begin{quote}
Nelson Goodman presented a different description of the problem of induction  in the third chapter of "Fact, Fiction, and Forecast" entitled "The New Riddle of Induction" (1954). Goodman proposed a new predicate, "grue". Something is grue if and only if it has been observed to be green before a certain time or blue after that time. The "new" problem of induction is, since all emeralds we have ever seen are both green and grue, why do we suppose that after time T we will find green but not grue emeralds? The problem here raised is that two different inductions will be true and false under the same conditions. In other words:
- Given the observations of a lot of green emeralds, someone using a common language will inductively infer that all emeralds are green (therefore, he will believe that any emerald he will find will be green, even after T).
- Given the same set of observations of green emeralds, someone using the predicate "grue" will inductively infer that all emeralds, which will be observed after T, will be blue, despite the fact that he observed only green emeralds so far.
Goodman, however, points out that the predicate "grue" only appears more complex than the predicate "green" because we have defined grue in terms of blue and green. If we had always been brought up to think in terms of "grue" and "bleen" (where bleen is blue before time T, or green thereafter), we would intuitively consider "green" to be a crazy and complicated predicate. Goodman believed that which scientific hypotheses we favour depend on which predicates are "entrenched" in our language.
\end{quote}

Human and artificial agents interact with the environment. Learning the mechanism of the environment from the observations enables an agent to make prediction based on which one can make rational decisions. The abstraction of the complex interaction between an environment and an agent with its objectives gives a rise to learning problems of different forms.

\subsection{Utility maximization}
\subsection{Knowledge compression}
\subsection{Model learning}
\subsection{Verbatim memorization}
\subsection{Abstraction}
\subsubsection{Pattern Abstraction}
\subsubsection{Concept Abstraction}
\subsection{Information Search}
\subsubsection{Information Confirmation}
\subsubsection{Information Refutation}

learn most probable hypothesis vs learning the most useful hypothesis, from the observations we would like to learn what is the most relevant to us with respect to the circumstances.
ideas:
maximizing what you know - knowledge compression
learning the rules of a game
learning the postulates of the environment
trying the represent the model of the world most succintly
producing a Turing machine with an equivalent code
the ability to survive relies on the prediction
learning knowledge is a manifestation of a human curiosity
our decisions (and an exercise of a free will) can be made better if we understand their impact
\subsection{}

\section{Contributions}

Contributions here.


\section{Statement of Originality}

Statement here.