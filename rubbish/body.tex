
\section{The role of a language in learning the models}
Consider an empty language. It has one possible interpretation and one model up to an isomorphism.
By extending the language we can distinguish the models further. The problem of predicate invention is to invent a predicate so that the right distinction between models is made based on the language.
Questions:
1. How can we measure an expessivity and a complexity of a language?
2. How much information can be captured by a $\mathcal{L}$-theory given a language $\mathcal{L}$?
3. What is the maximal complexity of the language $\mathcal{L}$ for which the $\mathcal{L}$-theory is decidable?
4. Complexity of learning the equivalence class of the reality given a language.
5. Is there a language for which the task of learning the equivalence class of the reality is undecidable?
6. What percentage of the reality can we recover from observing and reasoning only with the statements in the restricted language?
7. Can a language be partitioned (or expressed as posets of sublanguages) into sublanguages and the theories of the sublanguages be learnt, then joint into a theory of the original language?

\chapter{Rationale ILP system}

\section{Properties of an ILP system}
We further seek properties of ILP systems upon which we could base our comparison of different ILP systems. Recall $L$ is a set of all logical sentences for a given signature $\mathcal{L}$ and $B, E+, E-, H \subseteq L$, $\mathcal{H}, \mathcal{H}_2 \subseteq \powerset{L}$.

We ask:
\begin{enumerate}
\item On what inputs is $s$ defined?
\item What is the algorithm computing $s$?
\item What is the computational complexity of $s$?
\item On what inputs do different systems $s_1, s_2$ produce a different output?
\item If on a given input $i$ and $s_1(i) \not= s_2(i)$, is there a way to compare the systems based on their output solution set?
\item Is there a way to equip the input and the output with the semantics to provide an interpretation for the output produced from the input?
\end{enumerate}



\section{Algorithmic definition of an ILP system}
We provide a simplified algorithm for each of the systems in order to be able to extract properties of each system upon which a comparison could based.

\subsection{IE algorithm\cite{yamamoto2012inverse}}
Progol, Xhail, Imparo are based on the principle of the inverse entailment. By the principle of the inverse entailment $B \cup H \models E$ iff
$B \cup \neg E \models \neg H$. A hypothesis $H \in \mathcal{H}_2$ is a solution to the problem of the explanatory induction $(B,E+,E-,\mathcal{H})$ iff
$B \cup H \subseteq Cn(E+ \union \overline{E-})$,
 $false \not\in Cn(E+ \cup E-)$, $\mathcal{H}_2 \subseteq \mathcal{H}$
iff
$B \cup H \subseteq Cn(E+ \union \overline{E-})$,
 $false \not\in Cn(E+ \cup E-)$, $\mathcal{H}_2 \subseteq \mathcal{H}$
 
 They compute the hypothesis $H$ in two steps:
1. constructing an intermediate theory, 2. generalizing its negation into the hypothesis with the inverse of the entailment relation.


\subsection{Aleph}
\subsection{Progol}
\subsection{Toplog}
\subsubsection{Top theory construction}
\subsection{Imparo}
\subsection{Tal}
\subsection{Xhail}
    
\chapter{Definition of an ILP problem - notes}
For a given set of examples often multiple sets of hypotheses can explain such a set of examples. However, the common definition of an ILP problem does not convey which hypotheses should be chosen in such a case. This chapter presents an investigation of an definition of an ILP problem and critique of the incompleteness of the definition of an ILP problem.

Related to the definition of an ILP problem Cheng and Wolf say in \cite{nienhuys1997foundations}
"If E + is finite, then E = E -e will be a correct theory, but a rather unin-
teresting one. In this case, we would not have learned anything beyond the
given examples: the induced theory has no predictive power. To avoid this,
we can put some constraints on the theory. For instance, we might demand
that E contains less clauses than the number of given positive examples. In
that case, E = E + is ruled out. Since constraints like these mainly depend
on the particular application at hand, we will not devote much attention to
them."
They acknowledge that their definition of an ILP problem does not specify what explanation $H$ should explain the examples. However, to the author of this thesis it is unclear how one would complete the definition with respect to the particular application.

Muggleton in his Inverse Entailment and Progol \cite{muggleton1995inverse} says:
"the association of probability values with hypotheses requires the assumption of a prior probability distribution over the hypothesis language. Occam's razor can be taken as an instance of a distribution which assigns higher prior probability to simpler hypotheses. It has been shown [4] that without such distributional assumptions the class of all logic programs is not even PAC-predictable. On the other hand, it has recently been demonstrated [42] that the class of all time-bounded logic programs is polynomial-time learnable (U-learnable) under fairly broad families of prior probability distributions. Appendix B gives more details of the relationship between data, posterior probabilities and U-learnability."

\section{ILP theory and methods}
\subsection{Completeness}
From ILP theory and methods \cite{muggleton1994inductive}:
An ILP system with a bias $\mathcal{H}$ is complete iff for all $E+, E-,B$ there exists $H \in \mathcal{H}$ such that $B \cup H \models E+$ and $B \cup H \not \models E-$.
\subsection{Non-monotonic setting for ILP}
Validity: all $h \in H$ are true in $M+(B)$,
Completeness: if general clause $g$ is true in $M+(B)$, then $H \models g$,	
Minimality: there is no proper subset $G$ of $H$ which is valid and complete.
Question: is $H$ unique from given the minimality condition?

\chapter{Learning hypotheses of the least Kolmogorov complexity}

Given a set of observations $O$, the background knowledge $B$, if the theory $O \union B$ is not complete, i.e. there is more than one model of $O \union B$ up to isomorphism, then there are several hypotheses $H \in \mathcal{H}$ that can explain the observations from the background knowledge, i.e. $B \union H \models O$, and are consistent with the background knowledge, i.e. $B \union H \not\models false$.

What quantifiable properties hypothesis should have can be captured by a score function. Arguing which score function is more desirable is a problem in its own right. We explore the possibility of a score function to be Kolmogorov complexity measure. We would like to find out what ILP systems induce their hypotheses of the least Kolmogorov complexity. The problem proves to be difficult as due to complex grammatical structure of the first order sentences of a logic program. We therefore provide an abstraction where a sentence is represented by an element of a set in hope that understanding the problem in its relaxed version will shed more light into its original version.

\subsection{Problem of induction - computability setting}

\begin{defn}
The Kolmogorov complexity $K(S)$ of a set $S$ is the Kolmogorov complexity
of a formula $\psi$ with the least Kolmogorov complexity that defines $S$.
\end{defn}

Given a set $P \subseteq \mathbb{N}$ of positive examples,
a set $N \subseteq \mathbb{N}$ of negative examples,
find a computable set $S = \{n \in \mathbb{N} : \mathbb{N} \models \phi(n) \} \subseteq \mathbb{N}$ that has the least Kolmogorov complexity.

In a specialized version of the problem, the criterion of Kolmogorov complexity can be replaced by other property definable by a real-valued score function on a triple $\langle P, N, \phi \rangle$. Similarly, we may require weaker conditions on a set $S$, e.g. computable with respect to some oracle set (background knowledge) $B$ or being of other Turing (or enumeration) degree.

\begin{defn}
TODO Herbrand Interpretation, Hebrand Model.
\end{defn}

We can think of the model of an environment as a Hebrand model. Notice that the powerset of natural numbers is equinumerous with the set of Herbrand models. Therefore we can think of a natural number as a ground atom.

\begin{defn}
An \emph{inductive inference system} IIS is a computable function
$f: \powerset{\mathbb{N}} \times \powerset{\mathbb{N}} \times \powerset{\powerset{\mathbb{N}}}
\to \powerset{\mathbb{N}},
\langle P, N, \mathcal{H} \rangle \mapsto S$
satisfying the conditions:

\begin{enumerate}
\item $S$ is a computable set,
\item $S \in \mathcal{H}$,
\item $P \subseteq S$,
\item $N \cap S = \emptyset$.
\end{enumerate}
\end{defn}

We call $P$ a set of positive examples, $N$ a set of negative examples, $\mathcal{H}$ a bias, $S$ a solution (a hypothesis) to a problem of induction.

\section{Bottom and top theories}
The following definitions are motivated by a top theory of TDHD framework and a bottom clause of Prolog systems.
\begin{defn}
A top theory $\top$ with respect to $\langle P, N \rangle$ is
$\{x \in \mathbb{N} : \psi_\top(x)\}$,
a set definable by $\psi_\top$, or implicitly $\psi$ satisfying
$P \subseteq \top$.
A set $\mathcal{H}=\powerset{\top}$ is called a top theory bias.
\end{defn}

\begin{defn}
A bottom theory $\bot$ with respect to $\langle P, N \rangle$ is
$\{x \in \mathbb{N} : \psi_\bot(x)\}$,
a set definable by $\psi_\bot$, or implicitly $\psi$ satisfying
$N \cap \bot = \emptyset$.
A set $\mathcal{H}=\powerset{\bot}$ is called a bottom theory bias.
\end{defn}

\section{Generalization}
In order to define a notion of generalization in an abstracted setting we should understand what a generalization is in various ILP contexts.

Inoue in \cite{inoue2012dnf} defines $\phi$ to be more general than $\psi$ iff
$M(\phi) \subseteq M(\psi)$ iff $\phi \models \psi$. An important observation is that as we generalize $\psi$ strictly the number of the possible models of $\phi$ shrinks, generalization increases certainty.

However, in systems like Toplog and Imparo whose logics use a Negation as Failure NAF, given a set of sentences $\Sigma$ it is complete since
$\forall \psi. \Sigma \models \psi \vee \Sigma \models \neg\psi$. Therefore every such consistent $\Sigma$ has only one Herbrand model. The notion of generalization cannot be defined in terms of models in logics with NAF. The intuition of a generalization comes from the $\theta$-subsumption.

\begin{defn}
Let a $C$, $D$ be sets of clauses, then $C$ $\theta$-subsumes $D$  written
$C \ge_\theta D$ iff $C \theta \subseteq D$.
\end{defn}

Notice that if $C \ge_\theta D$ then $C \models D$. Consider the case of $C=\{\neg female(x) \vee woman(x)\}$ and
$D=\{
\neg female(susan) \vee woman(susan),
\neg female(mary) \vee woman(mary),
\neg female(ann) \vee woman(ann) \}$.
Then $C$ $\theta$-subsumes $D$ with the substitution
$\theta=\{susan \backslash x, mary \backslash x, ann \backslash x\}$.
From the example we can see that generalization corresponds to deriving a more general rule from the specific instances of that rule. The theory $C$ is shorter than $D$ and less complex in a sense that it is easier to remember that every female is a woman than to remember that Susan is a woman, Mary is a woman, Ann is a woman given that we know that Susan, Mary, Ann are females.
Intuitively a set $S$ is simpler than a set $T$ if it can be defined in a simpler way:

\begin{defn}
Let $S$ and $T$ be subsets of $\mathbb{N}$, then we say that $S$ is more general than $T$ iff $K(S)<K(T)$ where $K(-)$ is the Kolmogorov complexity of its input set.
\end{defn}

\chapter{Model approximation}

\subsection{Approximation and error}
\begin{defn}
A theory $\Sigma$ \emph{approximates a theory $\Gamma$ by model} within the number $\epsilon$ called an error measure iff $\mu(M(\Sigma) \triangle M(\Gamma)) < \epsilon$ where $\mu:\{\mathcal{M}:\}\to [0,1]$ is a (probability) measure over the models and $[0,1] \subseteq \mathbb{R}$.
\end{defn}

\chapter{Score function}

\section{Axiomatization by score}
Find any axiomatization $A$ of the theory $O$ given $B$ with the greatest score $s(A,B,O)$ where $s$ is the \emph{score function}
$s:\mathcal{H} \times L \times L \to \mathbb{R}$.

\begin{exmp}
Define a score function $s$ by:
i. if $A$ infinite, then $s(A,B,O)=-1$,
ii. if $A \union B$ inconsistent, then $s(A,B,0)=-1$,
iii. otherwise $s(A,B,O)=\mu\{o \in O : A \union B \models o\}$.
\end{exmp}

\begin{exmp}
Define a score function $s:\mathcal{H} \times L \times L \to \mathbb{R}$ by $s(A,B,O)=1$ iff a theory $A \union B$ approximates a theory $O$ by model within a given error measure $\epsilon$, $s(A,B,O)=0$ otherwise.
\end{exmp}

\begin{note}
A score function is any total function taking into the consideration various criteria, e.g. minimum description length of the theory, finiteness of the theory, computational resources required to compute the theory. What a good score function is will be of our interest later.
\end{note}

\begin{exmp}
A Kolmogorov complexity with respect to the description language $L$ is a score function $K:L \to \mathbb{N}_0 \subseteq \mathbb{R}$.
\end{exmp}

\begin{note}
A Kolmogorov complexity $K$ can be thought of as a minimul description length with respect to the description language.
\end{note}
\begin{exmp}
Fix a description language to be a language of regular expressions. Let $L_1$ be a regular language given by its shortest description $0000000000$, $L_2$ given by its shortest description $10*$. Then $K(L_1)=10<K(L_2)=3$.
\end{exmp}

\chapter{Statistical learning}

\section{Incoherence of the generalization - Sawin-Demski paradox}
Consider the observations $P(0), \neg P(1), P(2)$ which are generalized by the rule $R1=\forall x. P(x)$ iff $x$ is even.
By inducing the $\Pi_1$ statement into the theory, it may be impossible for some true $\Pi_2$ statements to be part of the theory\cite{sawin2013computable}.
Therefore we limit ourselves to studying only the models where $\Pi_1$ statement true, $\Pi_2$ statement false.
